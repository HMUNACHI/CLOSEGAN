{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA1zvV9YWeE2"
      },
      "source": [
        "# Link To Paper\n",
        "# First Author: Henry Ndubuaku\n",
        "# Supervisor: Prof Matthew Purver\n",
        "# 2nd Supervisor: Dr. Ravi Sherkhar\n",
        "https://drive.google.com/file/d/1OnKuNsiiasiN6TcL6bMvldQajZF04rj4/view?usp=sharing\n",
        "\n",
        "Please glance through to understand the code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzkpQG1fVouI"
      },
      "source": [
        "# Data (Run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZTHIvlFVVmW"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install rake-nltk\n",
        "!pip install tensorflow_text\n",
        "!pip install bert-score\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MKJVm1EhC5B"
      },
      "outputs": [],
      "source": [
        "########################################### LOAD DATA ######################################\n",
        "import numpy as np\n",
        "import tensorflow_text\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set variables\n",
        "maxlen = 30\n",
        "vocab_size = 9832\n",
        "\n",
        "# Load Data\n",
        "jokes = np.load(\"encoded_jokes.npy\", allow_pickle=True)\n",
        "\n",
        "# Create tokenizer from saved vocab file\n",
        "tokenizer = tensorflow_text.BertTokenizer('vocab.txt', **dict(lower_case=True))\n",
        "\n",
        "# Copy the first 30 tokens of each joke as the source\n",
        "source = jokes[:, :-1]\n",
        "# Insert the start token at the begining of each\n",
        "source = np.insert(source[:,:-1], 0, 2, axis=1)\n",
        "\n",
        "# For a reconstruction seq2seq, the source and target is the same\n",
        "target = source\n",
        "\n",
        "# Isolate the next token at each time step as labels\n",
        "labels = np.expand_dims(target[:, 1:],axis=2)\n",
        "\n",
        "# Zero-pad labels\n",
        "labels = pad_sequences(labels,\n",
        "                       value=0,\n",
        "                       padding='post',\n",
        "                       maxlen=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ07Ba8tUDeE",
        "outputId": "bc82d398-86d8-4260-b854-06748793d20f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/ragged/ragged_tensor.py:2053: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(rows)\n"
          ]
        }
      ],
      "source": [
        "################################### EXTRACT KEYWORDS #################################\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from rake_nltk import Rake\n",
        "# Tokenize jokes\n",
        "tokenized_jokes = tokenizer.detokenize(jokes)\n",
        "tokenized_jokes = list(tokenized_jokes.numpy())\n",
        "data = []\n",
        "\n",
        "# Convert jokes to string\n",
        "for x in tokenized_jokes:\n",
        "  x = [y.decode(\"utf-8\") for y in x]\n",
        "  x = \" \".join([y for y in x if y != '[PAD]'])\n",
        "  data.append(x)\n",
        "\n",
        "\n",
        "# Extract keywords\n",
        "r = Rake(max_length=1)\n",
        "kws = []\n",
        "\n",
        "for x in data:\n",
        "  kw = r.extract_keywords_from_text(x)\n",
        "  kw = r.get_ranked_phrases()\n",
        "  kws.append(kw)\n",
        "\n",
        "\n",
        "# Tokenize and encode keywords\n",
        "keywords_int = tf.ragged.constant(kws)\n",
        "keywords_int = tokenizer.tokenize(keywords_int)\n",
        "# Reshape\n",
        "keywords_int = keywords_int.merge_dims(-2,-1).to_list()\n",
        "\n",
        "# Squeeze list\n",
        "keywords = []\n",
        "for x in keywords_int:\n",
        "  x = [item for sublist in x for item in sublist]\n",
        "  keywords.append(x)\n",
        "\n",
        "# Pad sequences\n",
        "keywords = tf.keras.preprocessing.sequence.pad_sequences(keywords,\n",
        "                                            value=0,\n",
        "                                            padding='post',\n",
        "                                            maxlen=maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "se48GlgAWFqe"
      },
      "outputs": [],
      "source": [
        "######################################## SPLIT INTO TRAIN AND TEST ##########################\n",
        "idx = int(0.2 * len(source))\n",
        "test_seq = source[:idx]\n",
        "test_keywords = keywords[:idx]\n",
        "\n",
        "source = source[idx:]\n",
        "keywords = keywords[idx:]\n",
        "target = target[idx:]\n",
        "labels = labels [idx:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO6zhXozmKj3"
      },
      "source": [
        "# Utils (Run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQf-GWbXmrci"
      },
      "outputs": [],
      "source": [
        "########################## SEQUENCE RECONSTRUCTION ALGORITHM #######################\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def reconstruct(seq, kw, encoder, stepper, decoder, tokenizer, start=[2], top_k=1):\n",
        "    # Obtain the latent variable\n",
        "    e_h = encoder.predict(seq)\n",
        "    \n",
        "    # Use stepper to obtain the encoder outputs and cell state\n",
        "    e_out, e_c = stepper.predict([e_h, kw])\n",
        "\n",
        "    # Generate empty target sequence of length 1\n",
        "    target_seq = np.zeros((1, 1))\n",
        "\n",
        "    # Populate the first word of target sequence with the index of start token.\n",
        "    for i in range(len(start)):\n",
        "      target_seq[i, i] = start[i]\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    # Generate using top_k sampling\n",
        "    while not stop_condition:\n",
        "        (output_tokens, h, c) = decoder.predict([target_seq]\n",
        "                + [e_out, e_h, e_c])\n",
        "\n",
        "        # Get probabilities from the last sequence\n",
        "        probs = output_tokens[0, -1, :]\n",
        "        # Select top_k probabilities and convert to array\n",
        "        preds = tf.math.top_k(probs, k=top_k, sorted=True)\n",
        "        preds = np.array(preds)\n",
        "        # Get equivalent probabilities for the top_k probabilities\n",
        "        score = preds[0] / sum(preds[0])\n",
        "        # Convert indicies to array and probalistically select a choice\n",
        "        preds = np.asarray(preds[1]).astype(\"int32\")\n",
        "        sampled_token_index = np.random.choice(preds, p=score)\n",
        "\n",
        "        # Detokenize indices\n",
        "        sampled_token = tokenizer.detokenize([[sampled_token_index]]).to_list()\n",
        "        sampled_token = sampled_token[0][0].decode(\"utf-8\")\n",
        "\n",
        "        if sampled_token != '[PAD]':\n",
        "            decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find the stop word.\n",
        "        if sampled_token == '[PAD]' or len(decoded_sentence.split()) \\\n",
        "            >= maxlen - 1:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1)\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        (e_h, e_c) = (h, c)\n",
        "\n",
        "    return decoded_sentence.replace(\" ##\",'')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k08CYrBWngH2"
      },
      "outputs": [],
      "source": [
        "############################ DETOKENIZE FUNCTION #######################\n",
        "def detokenize(indices, tokenizer):\n",
        "  word_tokens = tokenizer.detokenize([indices]).to_list()\n",
        "  word_tokens = [x.decode(\"utf-8\") for x in word_tokens[0]]\n",
        "  return word_tokens\n",
        "  return \" \".join([x for x in word_tokens if x != '[PAD]'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUHgfIUCwvSg"
      },
      "outputs": [],
      "source": [
        "######################## WASSERSTEIN GRADIENT PENALTY ###################\n",
        "import torch\n",
        "import torch.autograd as autograd\n",
        "\n",
        "def compute_grad_penalty(critic, real_data, fake_data):\n",
        "    B = real_data.size(0)\n",
        "    alpha = torch.FloatTensor(np.random.random((B, 1)))\n",
        "    if cuda:\n",
        "        alpha = alpha.cuda()\n",
        "    sample = alpha*real_data + (1-alpha)*fake_data\n",
        "    sample.requires_grad_(True)\n",
        "    score = critic(sample)\n",
        "\n",
        "    outputs = torch.FloatTensor(B, latent_dim).fill_(1.0)\n",
        "    outputs.requires_grad_(False)\n",
        "    if cuda:\n",
        "        outputs = outputs.cuda()\n",
        "    grads = autograd.grad(\n",
        "        outputs=score,\n",
        "        inputs=sample,\n",
        "        grad_outputs=outputs,\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True\n",
        "    )[0]\n",
        "\n",
        "    grad_penalty = ((grads.norm(2, dim=1) - 1.) ** 2).mean()\n",
        "    return grad_penalty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSRi3CwGx0f7"
      },
      "outputs": [],
      "source": [
        "############################## GAN TRAINING ALGORITHM ############################\n",
        "def train_gan(epoch):\n",
        "    generator.train()\n",
        "    critic.train()\n",
        "    c_train_loss = 0.\n",
        "    g_train_loss = 0.\n",
        "    g_batches = 0\n",
        "    for i, x in enumerate(train_loader):\n",
        "        if cuda:\n",
        "            x = x.cuda()\n",
        "        \n",
        "        # train critic\n",
        "        B = x.size(0)\n",
        "        c_optimizer.zero_grad()\n",
        "        noise = torch.from_numpy(np.random.normal(0, 1, (B, latent_dim))).float()\n",
        "        if cuda:\n",
        "            noise = noise.cuda()\n",
        "        with torch.no_grad():\n",
        "            x = x.cpu()\n",
        "            x = x.numpy()\n",
        "            z_real = encoder(x)\n",
        "            z_real = z_real.numpy()\n",
        "            z_real = torch.FloatTensor(z_real).cuda()\n",
        "\n",
        "        z_fake = generator(noise)\n",
        "        real_score = critic(z_real)\n",
        "        fake_score = critic(z_fake)\n",
        "        grad_penalty = compute_grad_penalty(critic, z_real.data, z_fake.data)\n",
        "        c_loss = -torch.mean(real_score) + torch.mean(fake_score) + gp_lambda*grad_penalty\n",
        "        c_train_loss += c_loss.item()\n",
        "        c_loss.backward()\n",
        "        c_optimizer.step()\n",
        "\n",
        "        # train generator\n",
        "        if i % n_critic == 0:\n",
        "            g_batches += 1\n",
        "            g_optimizer.zero_grad()\n",
        "            fake_score = critic(generator(noise))\n",
        "            g_loss = -torch.mean(fake_score)\n",
        "            g_train_loss += g_loss.item()\n",
        "            g_loss.backward()\n",
        "            g_optimizer.step()\n",
        "        #'''\n",
        "        if interval > 0 and i % interval == 0:\n",
        "            print('Epoch: {} | Batch: {}/{} ({:.0f}%) | G Loss: {:.6f} | C Loss: {:.6f}'.format(\n",
        "                epoch, batch_size*i, len(train_loader.dataset),\n",
        "                100.*(batch_size*i)/len(train_loader.dataset),\n",
        "                g_loss.item(), c_loss.item()\n",
        "            ))\n",
        "        #'''\n",
        "    g_train_loss /= g_batches\n",
        "    c_train_loss /= len(train_loader)\n",
        "    print('* (Train) Epoch: {} | G Loss: {:.4f} | C Loss: {:.4f}'.format(\n",
        "        epoch, g_train_loss, c_train_loss\n",
        "    ))\n",
        "    return (g_train_loss, c_train_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxn2gckW2a_X"
      },
      "outputs": [],
      "source": [
        "################################# GENERATION ALGORITHM #############################\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def generate_joke(kw, generator, stepper, decoder, tokenizer, start=[2], latent_dim=100, top_k=1):\n",
        "    # Obtain the latent variable from a random noise\n",
        "    noise = torch.from_numpy(np.random.normal(0, 1, (1, latent_dim))).float()\n",
        "    z = generator(noise[None,:,:])\n",
        "    z = z.squeeze(dim=1)\n",
        "    z = z.cpu()\n",
        "    e_h = z.detach().numpy()\n",
        "    \n",
        "    # Use stepper to obtain the encoder outputs and cell state\n",
        "    (e_out, e_c) = stepper.predict([e_h, kw])\n",
        "\n",
        "    # Generate empty target sequence of length 1\n",
        "    target_seq = np.zeros((1, 1))\n",
        "\n",
        "    # Populate the first word of target sequence with the index of start token.\n",
        "    for i in range(len(start)):\n",
        "      target_seq[i, i] = start[i]\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "        (output_tokens, h, c) = decoder.predict([target_seq]\n",
        "                + [e_out, e_h, e_c])\n",
        "        \n",
        "        '''\n",
        "        # Top K Sampling\n",
        "        # Get probabilities from the last sequence\n",
        "        probs = output_tokens[0, -1, :]\n",
        "        # Select top_k probabilities and convert to array\n",
        "        preds = tf.math.top_k(probs, k=top_k, sorted=True)\n",
        "        preds = np.array(preds)\n",
        "        # Get equivalent probabilities for the top_k probabilities\n",
        "        score = preds[0] / sum(preds[0])\n",
        "        # Convert indicies to array and probalistically select a choice\n",
        "        preds = np.asarray(preds[1]).astype(\"int32\")\n",
        "        sampled_token_index = np.random.choice(preds, p=score)\n",
        "\n",
        "        # Detokenize indices\n",
        "        '''\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = tokenizer.detokenize([[sampled_token_index]]).to_list()\n",
        "        sampled_token = sampled_token[0][0].decode(\"utf-8\")\n",
        "\n",
        "        if sampled_token != '[PAD]':\n",
        "            decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find the stop word.\n",
        "        if sampled_token == '[PAD]' or len(decoded_sentence.split()) \\\n",
        "            >= maxlen - 1:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1)\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        (e_h, e_c) = (h, c)\n",
        "\n",
        "    return decoded_sentence.replace(\" ##\",'')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHbXfWlzO25m"
      },
      "outputs": [],
      "source": [
        "def decoder_decode(topic, encoder_model, decoder_model, tokenizer, start=[2], hidden_dim=100, top_k=1):\n",
        "\n",
        "    # Encode the input as state vectors.\n",
        "    (e_out, e_h, e_c) = encoder_model.predict(topic)\n",
        "\n",
        "    # Generate empty target sequence of length 1\n",
        "    target_seq = np.zeros((1, 1))\n",
        "\n",
        "    # Populate the first word of target sequence with the index of start token.\n",
        "    for i in range(len(start)):\n",
        "      target_seq[i, i] = start[i]\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "        (output_tokens, h, c) = decoder_model.predict([target_seq]\n",
        "                + [e_out, e_h, e_c])\n",
        "       \n",
        "        # Top-k Sampling\n",
        "        # Get probabilities from the last sequence\n",
        "        probs = output_tokens[0, -1, :]\n",
        "        # Select top_k probabilities and convert to array\n",
        "        preds = tf.math.top_k(probs, k=top_k, sorted=True)\n",
        "        preds = np.array(preds)\n",
        "        # Get equivalent probabilities for the top_k probabilities\n",
        "        score = preds[0] / sum(preds[0])\n",
        "        # Convert indicies to array and probalistically select a choice\n",
        "        preds = np.asarray(preds[1]).astype(\"int32\")\n",
        "        sampled_token_index = np.random.choice(preds, p=score)\n",
        "        \n",
        "        sampled_token = tokenizer.detokenize([[sampled_token_index]]).to_list()\n",
        "        sampled_token = sampled_token[0][0].decode(\"utf-8\")\n",
        "\n",
        "        if sampled_token != '[PAD]':\n",
        "            decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find the stop word.\n",
        "        if sampled_token == '[PAD]' or len(decoded_sentence.split()) \\\n",
        "            >= maxlen - 1:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1)\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        (e_h, e_c) = (h, c)\n",
        "\n",
        "    return decoded_sentence.replace(\" ##\",'')\n",
        "\n",
        "# Load models\n",
        "def load_model(model_filename, model_weights_filename):\n",
        "    with open(model_filename, 'r', encoding='utf8') as f:\n",
        "        model = keras.models.model_from_json(f.read())\n",
        "    model.load_weights(model_weights_filename)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC5eH6O3uB0m"
      },
      "source": [
        "# Models (Run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIBtOldsOeY5"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Layer\n",
        "######################################## SAMPLING LAYER ####################################\n",
        "class Sampling(Layer):\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = K.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "\n",
        "#################################### VAE LOSS ##############################\n",
        "def vae_loss(y_true, y_pred):\n",
        "    xent_loss = sparse_categorical_crossentropy(y_true, y_pred)\n",
        "    kl_loss =  -0.5 * (1 + sigma - tf.square(mu) - tf.exp(sigma))\n",
        "    kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "    return xent_loss + kl_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKmwOMFs4tfx"
      },
      "outputs": [],
      "source": [
        "###################################### LUONG ATTENTION LAYER #############################\n",
        "import numpy as np\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.layers import Layer\n",
        "\n",
        "class LuongAttentionLayer(Layer):\n",
        "  def compute_mask(self, inputs, mask=None):\n",
        "    if mask == None:\n",
        "      return None\n",
        "    return mask[1]\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    return (input_shape[1][0],input_shape[1][1],input_shape[1][2]*2)\n",
        "\n",
        "\n",
        "  def call(self, inputs, mask=None):\n",
        "    encoder_outputs, decoder_outputs = inputs\n",
        "\n",
        "    # transpose the dimensions of decoder outputs\n",
        "    decoder_outputs_t = K.permute_dimensions(decoder_outputs, (0,2,1))\n",
        "\n",
        "    # calculate luong score\n",
        "    luong_score = K.batch_dot(encoder_outputs,decoder_outputs_t)\n",
        "    luong_score = K.softmax(luong_score, axis=1) # along the 2nd axis\n",
        "\n",
        "    # expand the dimensions of luong score and encoded outputs to enable multiplication\n",
        "    luong_score = K.expand_dims(luong_score, axis=-1) # along last axis\n",
        "    encoder_outputs = K.expand_dims(encoder_outputs, axis=2) # along 2nd axis\n",
        "\n",
        "    # get encoded vector\n",
        "    encoder_vector = encoder_outputs * luong_score\n",
        "    encoder_vector = K.sum(encoder_vector, axis=1, keepdims=False)\n",
        "\n",
        "    # [batch,max_dec,2*emb]\n",
        "    new_decoder_outputs = K.concatenate([decoder_outputs, encoder_vector])\n",
        "\n",
        "    return new_decoder_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGD28NYdtVfl"
      },
      "outputs": [],
      "source": [
        "####################################### GPT-3 STYLE TRANSFORMER ####################################\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Layer, LayerNormalization, MultiHeadAttention, Dropout\n",
        "\n",
        "def causal_attention_mask(batch_size, n_dest, n_src, dtype):\n",
        "    \"\"\"\n",
        "    Mask the upper half of the dot product matrix in self attention.\n",
        "    This prevents flow of information from future tokens to current token.\n",
        "    1's in the lower triangle, counting from the lower right corner.\n",
        "    \"\"\"\n",
        "    i = tf.range(n_dest)[:, None]\n",
        "    j = tf.range(n_src)\n",
        "    m = i >= j - n_src + n_dest\n",
        "    mask = tf.cast(m, dtype)\n",
        "    mask = tf.reshape(mask, [1, n_dest, n_src])\n",
        "    mult = tf.concat(\n",
        "        [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
        "    )\n",
        "    return tf.tile(mask, mult)\n",
        "\n",
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, embed_dim=100, num_heads=3, ff_dim=100, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads, embed_dim)\n",
        "        self.ffn = Sequential(t\n",
        "            [Dense(ff_dim, activation=\"relu\"), Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size = input_shape[0]\n",
        "        seq_len = input_shape[1]\n",
        "        causal_mask = causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
        "        attention_output = self.att(inputs, inputs, attention_mask=causal_mask)\n",
        "        attention_output = self.dropout1(attention_output)\n",
        "        out1 = self.layernorm1(inputs + attention_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JthIKCf5oAnn"
      },
      "outputs": [],
      "source": [
        "#################################### SEQ2SEQ ##################################\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Embedding, TimeDistributed, RepeatVector\n",
        "from keras.layers import Bidirectional, LayerNormalization, GlobalAveragePooling1D, Concatenate\n",
        "\n",
        "def r_seq2seq(latent_dim = 100, embedding_dim = 200, r_drop = 0.0, d_drop = 0.4, \n",
        "            weights=False, maxlen=30, kw_len=10, vocab_size=9832):\n",
        "            \n",
        "  # Divide latent dim for Bidirectional\n",
        "  latent_dim_0 = int(latent_dim / 2)\n",
        "\n",
        "  ################################# TRAIN ENCODER ##################################\n",
        "  # Source input\n",
        "  encoder_inputs = Input(shape=(maxlen, ))\n",
        "\n",
        "  # Embedding layer\n",
        "  enc_emb_layer = Embedding(vocab_size, embedding_dim, trainable=True)\n",
        "  enc_emb = enc_emb_layer(encoder_inputs)\n",
        "\n",
        "  # Encoder BiLSTM\n",
        "  encoder_bilstm = Bidirectional(LSTM(latent_dim_0,\n",
        "                                      dropout=d_drop,\n",
        "                                      recurrent_dropout=r_drop))\n",
        "  \n",
        "  hidden = encoder_bilstm(enc_emb)\n",
        "\n",
        "\n",
        "  ################################# TRAIN STEPPER #####################################\n",
        "  # Keyword input\n",
        "  keyword_inputs = Input(shape=(maxlen, ))\n",
        "\n",
        "  # Keyword embedding\n",
        "  keyword_emb_layer = Embedding(vocab_size, latent_dim, trainable=True)\n",
        "  keyword_emb = keyword_emb_layer(keyword_inputs)\n",
        "\n",
        "  # Keyword Dense\n",
        "  keyword_dense_layer = Dense(latent_dim)\n",
        "  keyword_dense = keyword_dense_layer(keyword_emb)\n",
        "\n",
        "\n",
        "  # Repeat and rewight hidden variable\n",
        "  hidden_outputs = RepeatVector(maxlen)(hidden)\n",
        "  hidden_dense_layer = Dense(latent_dim)\n",
        "  hidden_dense = hidden_dense_layer(hidden_outputs)\n",
        "\n",
        "  # Add hidden layer and keywords\n",
        "  stepper_outputs = hidden_dense + keyword_dense\n",
        "\n",
        "  # Normalise\n",
        "  layer_norm_1 = LayerNormalization()\n",
        "  stepper_outputs = layer_norm_1(stepper_outputs)\n",
        "\n",
        "  # Cell\n",
        "  cell = GlobalAveragePooling1D()(keyword_emb)\n",
        "  cell = cell + hidden\n",
        "  \n",
        "\n",
        "\n",
        "  ################################# TRAIN DECODER #####################################\n",
        "  # Target inputs\n",
        "  decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "  # Embedding layer\n",
        "  dec_emb_layer = Embedding(vocab_size, latent_dim, trainable=True)\n",
        "  dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # Decoder LSTM\n",
        "  decoder_lstm = LSTM(latent_dim,\n",
        "                    return_sequences=True,\n",
        "                    return_state=True,\n",
        "                    dropout=d_drop,\n",
        "                    recurrent_dropout=r_drop)\n",
        "  (decoder_outputs, h, c) = decoder_lstm(dec_emb, initial_state=[hidden, cell])\n",
        "\n",
        "  # Decoder Layer Norm\n",
        "  layer_norm_2 = LayerNormalization()\n",
        "  decoder_outputs = layer_norm_2(decoder_outputs)\n",
        "\n",
        "  # Stepper-Decoder Luong Attention\n",
        "  decoder_attention = LuongAttentionLayer( )\n",
        "  decoder_outputs = decoder_attention([stepper_outputs,decoder_outputs])\n",
        "  \n",
        "  # Final Dense layer\n",
        "  decoder_dense = TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "  # Define the model\n",
        "  model = Model([encoder_inputs, keyword_inputs, decoder_inputs], decoder_outputs, name='Train_Model')\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "  # Load weights if available\n",
        "  if weights:\n",
        "    model.load_weights(weights)\n",
        "\n",
        "\n",
        "  ############################# INFERENCE ENCODER ##########################\n",
        "  encoder = Model(inputs=encoder_inputs, outputs=hidden, name='Encoder')\n",
        "\n",
        "\n",
        "  ############################# INFERENCE STEPPER ##########################\n",
        "  input_z = Input(shape=(latent_dim, ))\n",
        "\n",
        "  # Embed and reweight keyword\n",
        "  keyword_emb_s = keyword_emb_layer(keyword_inputs)\n",
        "  keyword_dense_s = keyword_dense_layer(keyword_emb_s)\n",
        "\n",
        "  # Repeat and reweight hidden variable\n",
        "  hidden_outputs_s = RepeatVector(maxlen)(input_z)\n",
        "  hidden_dense_s = hidden_dense_layer(hidden_outputs_s)\n",
        "\n",
        "  # Add and normalise\n",
        "  outputs_s = hidden_dense_s + keyword_dense_s\n",
        "  outputs_s = layer_norm_1(outputs_s)\n",
        "\n",
        "  # Cell\n",
        "  cell_s = GlobalAveragePooling1D()(keyword_emb_s)\n",
        "  cell_s = cell_s + input_z\n",
        "\n",
        "  # Build Model\n",
        "  stepper = Model(inputs=[input_z, keyword_inputs], outputs=[outputs_s, cell_s], name='Stepper')\n",
        "\n",
        "\n",
        "  ############################ INFERENCE DECODER ############################\n",
        "  # Below tensors will hold the states of the previous time step\n",
        "  input_h = Input(shape=(latent_dim, ))\n",
        "  input_c = Input(shape=(latent_dim, ))\n",
        "  input_s = Input(shape=(maxlen, latent_dim))\n",
        "\n",
        "  # Get the embeddings of the decoder sequence\n",
        "  dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # To predict the next word in the sequence, set the initial states to the states from previous time step\n",
        "  (decoder_outputs2, state_h2, state_c2) = decoder_lstm(dec_emb2, initial_state=[input_h, input_c])\n",
        "  decoder_outputs2 = layer_norm_2(decoder_outputs2)\n",
        "\n",
        "  # Attention\n",
        "  decoder_outputs2 = decoder_attention([input_s, decoder_outputs2])\n",
        "\n",
        "  # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "  # Final decoder model\n",
        "  decoder = Model([decoder_inputs] + [input_s, input_h, input_c],\n",
        "                  [decoder_outputs2] + [state_h2, state_c2],\n",
        "                      name='Decoder')\n",
        "\n",
        "  return (model, encoder, stepper, decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjy0Pc2Qv3BP"
      },
      "outputs": [],
      "source": [
        "############################## GENERATIVE ADVERSARIAL NETWORK ################\n",
        "import torch.nn as nn\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \n",
        "    def __init__(self, block_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(block_dim, block_dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(block_dim, block_dim),\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.net(x) + x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_layers, block_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            *[Block(block_dim) for _ in range(n_layers)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Critic(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_layers, block_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            *[Block(block_dim) for _ in range(n_layers)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuc-xfaaKAND"
      },
      "outputs": [],
      "source": [
        "###################################### SEQ2SEQ #####################################\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "def seq2seq(latent_dim = 100, embedding_dim = 200, r_drop = 0.0, d_drop = 0.4, \n",
        "            weights=False, maxlen=30, vocab_size=9832):\n",
        "  \n",
        "  #################################### ENCODER ##################################\n",
        "  # Encoder inputs\n",
        "  encoder_inputs = keras.Input(shape=(maxlen, ))\n",
        "\n",
        "  # Embedding layer\n",
        "  enc_emb = layers.Embedding(vocab_size, latent_dim, input_length=maxlen)(encoder_inputs)\n",
        "\n",
        "  # Sentence Average\n",
        "  enc_avg = layers.GlobalAveragePooling1D()(enc_emb)\n",
        "\n",
        "  # Hidden Dense\n",
        "  hidden_dense = layers.Dense(latent_dim)\n",
        "  hidden = hidden_dense(enc_avg)\n",
        "\n",
        "  # Encoder dense\n",
        "  enc_dense = layers.Dense(latent_dim)\n",
        "  encoder_outputs = enc_dense(enc_emb)\n",
        "\n",
        "\n",
        "  #################################### DECODER ####################################\n",
        "  # Decoder inputs\n",
        "  decoder_inputs = keras.Input(shape=(maxlen, ))\n",
        "\n",
        "  # Decoder embedding layer\n",
        "  dec_emb_layer = layers.Embedding(vocab_size, latent_dim, trainable=True)\n",
        "  dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  decoder_lstm = layers.LSTM(latent_dim, \n",
        "                    return_sequences=True,\n",
        "                    return_state=True, \n",
        "                    dropout=0.4,\n",
        "                    recurrent_dropout=0.0)\n",
        "\n",
        "  (decoder_outputs, decoder_fwd_state, decoder_back_state) = decoder_lstm(dec_emb, \n",
        "                                                           initial_state=[hidden, hidden])\n",
        "\n",
        "  # Add Luong attention\n",
        "  attention = LuongAttentionLayer()\n",
        "  decoder_outputs = attention([encoder_outputs,decoder_outputs])\n",
        "\n",
        "  # Dense layer\n",
        "  decoder_dense = layers.TimeDistributed(layers.Dense(vocab_size, activation='softmax'))\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "\n",
        "  #################################### MODEL ##############################\n",
        "  model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "  \n",
        "  # Load weights if available\n",
        "  if weights:\n",
        "    model.load_weights(weights)\n",
        "\n",
        "  #################################### INFERENCE ENCODER ################################\n",
        "  encoder_model = keras.Model(inputs=encoder_inputs, outputs=[encoder_outputs, hidden, hidden], name='encoder')\n",
        "\n",
        "  #################################### INFERENCE DECODER ################################\n",
        "  decoder_state_input_h = keras.Input(shape=(latent_dim, ))\n",
        "  decoder_state_input_c = keras.Input(shape=(latent_dim, ))\n",
        "  decoder_hidden_state_input = keras.Input(shape=(maxlen, latent_dim))\n",
        "\n",
        "  # Get the embeddings of the decoder sequence\n",
        "  dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "  (decoder_outputs2, state_h2, state_c2) = decoder_lstm(dec_emb2,\n",
        "        initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "  # Attention\n",
        "  decoder_outputs2 = attention([decoder_hidden_state_input,decoder_outputs2])\n",
        "\n",
        "  # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "  # Final decoder model\n",
        "  decoder_model = keras.Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                      decoder_state_input_h, decoder_state_input_c],\n",
        "                      [decoder_outputs2] + [state_h2, state_c2], name=\"decoder\")\n",
        "  return encoder_model, decoder_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrOCJz2jKAWn"
      },
      "outputs": [],
      "source": [
        "###################################### VAE #####################################\n",
        "import keras\n",
        "from keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "def vae(latent_dim = 100, embedding_dim = 200, r_drop = 0.0, d_drop = 0.4, \n",
        "            weights_e=False, weights_d=False, maxlen=30, vocab_size=9832):\n",
        "  # Hyper parameters\n",
        "  latent_dim = 100\n",
        "  embedding_dim = 200\n",
        "  maxlen = 30\n",
        "  vocab_size = 9832\n",
        "\n",
        "\n",
        "  #################################### ENCODER ##################################\n",
        "  # Encoder inputs\n",
        "  encoder_inputs = tf.keras.Input(shape=(maxlen, ))\n",
        "\n",
        "  # Embedding layer\n",
        "  enc_emb = tf.keras.layers.Embedding(vocab_size, latent_dim, input_length=maxlen)(encoder_inputs)\n",
        "\n",
        "  # Sentence Averaging Encoder\n",
        "  encoder_avg = tf.keras.layers.GlobalAveragePooling1D()(enc_emb)\n",
        "\n",
        "\n",
        "  ################################### SAMPLING ####################################\n",
        "  mu = tf.keras.layers.Dense(latent_dim)(encoder_avg)\n",
        "  sigma = tf.keras.layers.Dense(latent_dim)(encoder_avg)\n",
        "  z = Sampling()([mu, sigma])\n",
        "\n",
        "  # Hidden Dense\n",
        "  hidden_dense = tf.keras.layers.Dense(latent_dim)\n",
        "  hidden = hidden_dense(encoder_avg)\n",
        "\n",
        "  # Encoder dense\n",
        "  enc_dense = tf.keras.layers.Dense(latent_dim)\n",
        "  encoder_outputs = enc_dense(enc_emb)\n",
        "\n",
        "\n",
        "  #################################### DECODER ####################################\n",
        "  # Decoder inputs\n",
        "  decoder_inputs = tf.keras.Input(shape=(None, ))\n",
        "\n",
        "  # Decoder embedding layer\n",
        "  dec_emb_layer = tf.keras.layers.Embedding(vocab_size, latent_dim, trainable=True)\n",
        "  dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  decoder_lstm = tf.keras.layers.LSTM(latent_dim,\n",
        "                    return_sequences=True,\n",
        "                    return_state=True,\n",
        "                    dropout=0.4,\n",
        "                    recurrent_dropout=0.0)\n",
        "\n",
        "  (decoder_outputs, decoder_fwd_state, decoder_back_state) = decoder_lstm(dec_emb,\n",
        "                                                           initial_state=[hidden, hidden])\n",
        "\n",
        "  # Add Luong attention\n",
        "  attention = LuongAttentionLayer()\n",
        "  decoder_outputs = attention([encoder_outputs, decoder_outputs])\n",
        "\n",
        "  # Dense layer\n",
        "  decoder_dense = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(vocab_size, activation='softmax'))\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "  model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs, name=\"vae\")\n",
        "\n",
        "  #################################### INFERENCE ENCODER ################################\n",
        "  encoder_model = tf.keras.Model(inputs=encoder_inputs, outputs=[encoder_outputs, hidden, hidden], name='encoder')\n",
        "\n",
        "  #################################### INFERENCE DECODER ################################\n",
        "  decoder_state_input_h = tf.keras.Input(shape=(latent_dim, ))\n",
        "  decoder_state_input_c = tf.keras.Input(shape=(latent_dim, ))\n",
        "  decoder_hidden_state_input = tf.keras.Input(shape=(maxlen, latent_dim))\n",
        "\n",
        "  # Get the embeddings of the decoder sequence\n",
        "  dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "  # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "  (decoder_outputs2, state_h2, state_c2) = decoder_lstm(dec_emb2,\n",
        "        initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "  # Attention\n",
        "  decoder_outputs2 = attention([decoder_hidden_state_input,decoder_outputs2])\n",
        "\n",
        "  # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "  # Final decoder model\n",
        "  decoder_model = tf.keras.Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                      decoder_state_input_h, decoder_state_input_c],\n",
        "                      [decoder_outputs2] + [state_h2, state_c2], name=\"decoder\")\n",
        "  \n",
        "  if weights_e:\n",
        "    encoder_model.load_weights(weights_e)\n",
        "\n",
        "  if weights_d:\n",
        "    decoder_model.load_weights(weights_d)\n",
        "\n",
        "  return encoder_model, decoder_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAzPBHjdQZ1T"
      },
      "outputs": [],
      "source": [
        "################################ TRANSFORMER ######################################\n",
        "def transformer (embed_dim = 256, num_heads = 3, feed_forward_dim = 256, weights=False):\n",
        "  # GPT2 Style Transformer\n",
        "  inputs = layers.Input(shape=(maxlen,), dtype=tf.int32)\n",
        "  embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "  x = embedding_layer(inputs)\n",
        "  transformer_block1 = TransformerBlock(embed_dim, num_heads, feed_forward_dim)\n",
        "  x = transformer_block1(x)\n",
        "  transformer_block2 = TransformerBlock(embed_dim, num_heads, feed_forward_dim)\n",
        "  x = transformer_block2(x)\n",
        "  transformer_block3 = TransformerBlock(embed_dim, num_heads, feed_forward_dim)\n",
        "  x = transformer_block3(x)\n",
        "  transformer_block4 = TransformerBlock(embed_dim, num_heads, feed_forward_dim)\n",
        "  x = transformer_block4(x)\n",
        "  outputs = layers.Dense(vocab_size)(x)\n",
        "  model = keras.Model(inputs=inputs, outputs=[outputs, x])\n",
        "  loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  model.compile(\"adam\", loss=[loss_fn, None],)  # No loss and optimization based on word embeddings from transformer block\n",
        "\n",
        "  if weights:\n",
        "    model.load_weights(weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPMo2cdun6uO"
      },
      "source": [
        "# Reconstruction Pre-training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxRkMspMt3Uq",
        "outputId": "8b7dbe47-72e1-4362-e3c7-bd2ae277f7a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"Train_Model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_50 (InputLayer)           [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_29 (Embedding)        (None, 30, 200)      1966400     input_50[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_51 (InputLayer)           [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_10 (Bidirectional (None, 100)          100400      embedding_29[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "embedding_30 (Embedding)        (None, 30, 100)      983200      input_51[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_15 (RepeatVector) (None, 30, 100)      0           bidirectional_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "input_52 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_14 (Gl (None, 100)          0           embedding_30[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_62 (Dense)                (None, 30, 100)      10100       repeat_vector_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_61 (Dense)                (None, 30, 100)      10100       embedding_30[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "embedding_31 (Embedding)        (None, None, 100)    983200      input_52[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_30 (TFOpLa (None, 100)          0           global_average_pooling1d_14[0][0]\n",
            "                                                                 bidirectional_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_29 (TFOpLa (None, 30, 100)      0           dense_62[0][0]                   \n",
            "                                                                 dense_61[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_20 (LSTM)                  [(None, None, 100),  80400       embedding_31[0][0]               \n",
            "                                                                 bidirectional_10[0][0]           \n",
            "                                                                 tf.__operators__.add_30[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_51 (LayerNo (None, 30, 100)      200         tf.__operators__.add_29[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_52 (LayerNo (None, None, 100)    200         lstm_20[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "luong_attention_layer_9 (LuongA (None, None, 200)    0           layer_normalization_51[0][0]     \n",
            "                                                                 layer_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_9 (TimeDistrib (None, None, 9832)   1976232     luong_attention_layer_9[0][0]    \n",
            "==================================================================================================\n",
            "Total params: 6,110,432\n",
            "Trainable params: 6,110,432\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "\n",
            "Model: \"Encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_50 (InputLayer)        [(None, 30)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_29 (Embedding)     (None, 30, 200)           1966400   \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, 100)               100400    \n",
            "=================================================================\n",
            "Total params: 2,066,800\n",
            "Trainable params: 2,066,800\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "Model: \"Stepper\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_53 (InputLayer)           [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_51 (InputLayer)           [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_16 (RepeatVector) (None, 30, 100)      0           input_53[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_30 (Embedding)        (None, 30, 100)      983200      input_51[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_62 (Dense)                (None, 30, 100)      10100       repeat_vector_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_61 (Dense)                (None, 30, 100)      10100       embedding_30[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_31 (TFOpLa (None, 30, 100)      0           dense_62[1][0]                   \n",
            "                                                                 dense_61[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_15 (Gl (None, 100)          0           embedding_30[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_51 (LayerNo (None, 30, 100)      200         tf.__operators__.add_31[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_32 (TFOpLa (None, 100)          0           global_average_pooling1d_15[0][0]\n",
            "                                                                 input_53[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,003,600\n",
            "Trainable params: 1,003,600\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "\n",
            "Model: \"Decoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_52 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_31 (Embedding)        (None, None, 100)    983200      input_52[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_54 (InputLayer)           [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_55 (InputLayer)           [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_20 (LSTM)                  [(None, None, 100),  80400       embedding_31[1][0]               \n",
            "                                                                 input_54[0][0]                   \n",
            "                                                                 input_55[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_56 (InputLayer)           [(None, 30, 100)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_52 (LayerNo (None, None, 100)    200         lstm_20[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "luong_attention_layer_9 (LuongA (None, None, 200)    0           input_56[0][0]                   \n",
            "                                                                 layer_normalization_52[1][0]     \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_9 (TimeDistrib (None, None, 9832)   1976232     luong_attention_layer_9[1][0]    \n",
            "==================================================================================================\n",
            "Total params: 3,040,032\n",
            "Trainable params: 3,040,032\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "############################ BUILD MODELS #############################\n",
        "latent_dim = 100\n",
        "embedding_dim = 200\n",
        "r_drop = 0.0\n",
        "d_drop = 0.4\n",
        "\n",
        "model, encoder, stepper, decoder = r_seq2seq(latent_dim=latent_dim, \n",
        "                                           embedding_dim=embedding_dim, \n",
        "                                           r_drop=r_drop, \n",
        "                                           d_drop=d_drop)\n",
        "print(model.summary())\n",
        "print(\"\")\n",
        "\n",
        "print(encoder.summary())\n",
        "print(\"\")\n",
        "\n",
        "print(stepper.summary())\n",
        "print(\"\")\n",
        "\n",
        "print(decoder.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4j6ktQyUrXQn"
      },
      "outputs": [],
      "source": [
        "################################ TRAINING ###############################\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Setup early stopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', patience=10)\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 100\n",
        "val = 0.1\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy')\n",
        "history = model.fit([source, keywords, target],\n",
        "                   labels,\n",
        "                   batch_size=batch_size,\n",
        "                   validation_split=val,\n",
        "                   epochs=epochs,\n",
        "                   callbacks=[es])\n",
        "\n",
        "# Save model weights\n",
        "model.save_weights('reconstruction_weights.h5')\n",
        "\n",
        "# Plot History\n",
        "history_dict = history.history\n",
        "plt.plot(range(1,epochs+1), history_dict['loss'], 'r', label='Training loss')\n",
        "plt.plot(range(1,epochs+1), history_dict['val_loss'], 'g', label='Validation loss')\n",
        "plt.title('Seq2Seq Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2u90pTVSVfr2"
      },
      "outputs": [],
      "source": [
        "# Load model for testing\n",
        "model, encoder, stepper, decoder = r_seq2seq(weights='/content/reconstruction_weights.h5', latent_dim=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1h1trlmRgNa",
        "outputId": "d5e9574a-596e-4521-b336-6b94a35dbc05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KEYWORDS: switch light arguing\n",
            "TRUE: how do you end two deaf persons ' arguing ? switch off the light .\n",
            "RECONSTRUCTED:  how do you change two ' tiny legs ? a switcher off the .\n",
            "\n",
            "KEYWORDS: suckin lot lose hurricane house first common blowin blonde\n",
            "TRUE: what does a blonde have in common with a hurricane ? first there is a lot of suckin and blowin , then you lose your house .\n",
            "RECONSTRUCTED:  what does a blonde have in common ? if she moves a girl in the house , then if you lose your house and suckin ' .\n",
            "\n",
            "KEYWORDS: went floats day circles\n",
            "TRUE: i went to a white pride parade the other day . the floats just kept going around in circles about 200 miles per hour .\n",
            "RECONSTRUCTED:  i went to a native american the other day . they went around in circles . they are running around to the other day\n",
            "\n",
            "KEYWORDS: would neighbor joke home close\n",
            "TRUE: i would make a joke about my neighbor . but it would be too close to home\n",
            "RECONSTRUCTED:  i would a joke about a helicopter . but it would be too close to home .\n",
            "\n",
            "KEYWORDS: god everything difference\n",
            "TRUE: what is the difference between god and you ex wife ? god only wants 10 things . your ex wife wants half of everything .\n",
            "RECONSTRUCTED:  what is the difference between everything and god ? god knows everything everything ex exist . god only everything you have to be everything .\n",
            "\n",
            "KEYWORDS: swear castrate\n",
            "TRUE: i swear , i will castrate you do it , you won t . no balls bro .\n",
            "RECONSTRUCTED:  i swear , you will cast spell out , no , i won ' t castrate . .\n",
            "\n",
            "KEYWORDS: woman way tits looking eyes checks\n",
            "TRUE: the first thing a man notices about a woman is her eyes and when he made sure it is not looking his way , he checks out her\n",
            "RECONSTRUCTED:  the pope is a man who won a woman , and he is looking for her tits , he is a bit more than his own way it checks\n",
            "\n",
            "KEYWORDS: get dead\n",
            "TRUE: what is your favourite insult joke ? i will get it started 2090 called , you are dead and nobody misses you\n",
            "RECONSTRUCTED:  what is your momma joke about you get it ? you should probably be dead , and then you get your shit off\n",
            "\n",
            "KEYWORDS: way thought mall harsh\n",
            "TRUE: trump hows that mexican mall going ? mall ? we thought you said wall trump no way that is harsh , also hows that muslim band looking\n",
            "RECONSTRUCTED:  two trashs are you ? no one is that sugar , what instance ? no , which is how many sugar ? no , who have no way\n",
            "\n",
            "KEYWORDS: anyone\n",
            "TRUE: keanu reeves donates so much blood that anyone who has ever received donor blood is at least 6 keanu reeves .\n",
            "RECONSTRUCTED:  peta people banned from anyone who is about hearing aids happening . all of the following words are leaked following\n",
            "\n",
            "KEYWORDS: sneezes\n",
            "TRUE: what does a nut say when he sneezes ? ca shew\n",
            "RECONSTRUCTED:  what does a nut say when he sneezes ? ho ho ho ho\n",
            "\n",
            "KEYWORDS: nose man ejaculating arrested\n",
            "TRUE: a man was arrested for ejaculating out his nose but he did nutting wrong\n",
            "RECONSTRUCTED:  a man was arrested for ejaculating out he was really hungry for ejaculating\n",
            "\n",
            "KEYWORDS: write called\n",
            "TRUE: my girlfriend asked me to write an inspirational poem about our love life . i called it , the load less swallowed\n",
            "RECONSTRUCTED:  my girlfriend asked me to write an positive side of it loans . i called it to write me for the legal thon .\n",
            "\n",
            "KEYWORDS: understand talk heroin\n",
            "TRUE: my local police chief does a talk on heroin so you can ' t understand any of it .\n",
            "RECONSTRUCTED:  my local joke told me this joke on a toilet seat can ' t understand you canned it .\n",
            "\n",
            "KEYWORDS: used thought think telling look brain\n",
            "TRUE: i used to think the brain was the most important organ . then i thought , look what is telling me that .\n",
            "RECONSTRUCTED:  i used to think the brain was all that . i thought to look . then the look is then telling me\n",
            "\n",
            "KEYWORDS: tumblr trending saw dashboard\n",
            "TRUE: so i saw that princess diana is trending on tumblr . she is all over the dashboard\n",
            "RECONSTRUCTED:  so that is all over on exhausting on on the exhausting trend . i ' m .\n",
            "\n",
            "KEYWORDS: unless speed multiply light energy\n",
            "TRUE: unless you multiply yourself by the speed of light then you energy .\n",
            "RECONSTRUCTED:  you should multiply yourself by the speed of light then you .\n",
            "\n",
            "KEYWORDS: hollow hillary head\n",
            "TRUE: what is more hollow than donald trump is head ? hillary is diazepam pen .\n",
            "RECONSTRUCTED:  what is more than than violence ? jack is more than now a hollowon encomn .\n",
            "\n",
            "KEYWORDS: dog boat\n",
            "TRUE: why does a dog on a you boat have a deep bark ? because he is a sub woofer .\n",
            "RECONSTRUCTED:  why does a dog on a boat have a boat ? because he is a boat on the dog .\n",
            "\n",
            "KEYWORDS: reaction\n",
            "TRUE: why don ' t people tell chemistry jokes ? because they never get a reaction .\n",
            "RECONSTRUCTED:  why don ' t people never eat jokes ? because they have no reaction .\n",
            "\n",
            "KEYWORDS: yet woman w q infront cow back\n",
            "TRUE: q what is infront of the woman , yet , at the back of the cow ? a w\n",
            "RECONSTRUCTED:  q , what is the first part of a woman and the woman is ? a woman is a woman\n",
            "\n",
            "KEYWORDS: nazi followers coming\n",
            "TRUE: when hitler killed himself his followers did nazi that coming\n",
            "RECONSTRUCTED:  when hitler maninis he would nazi he coming\n",
            "\n",
            "KEYWORDS: \n",
            "TRUE: \n",
            "RECONSTRUCTED: \n",
            "\n",
            "KEYWORDS: sperm directions ask\n",
            "TRUE: why does it take millions of sperm to fertilize one egg ? because they won ' t ask for directions\n",
            "RECONSTRUCTED:  why does it take for directions for directions ? sperm to ask for directions they ask for directions for unoriginal for unoriginal joke\n",
            "\n",
            "KEYWORDS: experience belittling attacked\n",
            "TRUE: i was attacked by tiny bees . the experience was belittling .\n",
            "RECONSTRUCTED:  i was attacked by the more experience . belittling was .\n",
            "\n",
            "KEYWORDS: spent proud pays lot life brothels bills\n",
            "TRUE: i have spent a lot of my life in brothels . i am not proud of it , but it pays the bills .\n",
            "RECONSTRUCTED:  i have spent a lot of in my life . it would have only have a lot of waste of it , it is too proud .\n",
            "\n",
            "KEYWORDS: went tiers even cake\n",
            "TRUE: i went to a really depressing wedding recently . even the cake was in tiers .\n",
            "RECONSTRUCTED:  i went to a really emotional wedding . even the cake was in tiers .\n",
            "\n",
            "KEYWORDS: song catchy\n",
            "TRUE: a stormtrooper walks into a cantina stormtrooper damn this song is catchy\n",
            "RECONSTRUCTED:  a pessimist walks into a song this song edit this song is this song\n",
            "\n",
            "KEYWORDS: whens door ajar\n",
            "TRUE: whens a door not a door ? when its ajar .\n",
            "RECONSTRUCTED:  when a doors not a a not person ? ajar .\n",
            "\n",
            "KEYWORDS: little difference\n",
            "TRUE: what is the difference between ancient religious texts and fake news ? a little over 2000 years\n",
            "RECONSTRUCTED:  what is the difference between someone and a happy mexican ? the latter expects for a pc\n",
            "\n",
            "KEYWORDS: call\n",
            "TRUE: what do you call a graduated spider ? a web designer\n",
            "RECONSTRUCTED:  what do you call a spider ? a web designer\n",
            "\n",
            "KEYWORDS: see mother father beauty\n",
            "TRUE: a son asks his father . a son asks his father dad , what is beauty ? do you see your mother ? yes well that is not it\n",
            "RECONSTRUCTED:  a father asks me if she is a father . husband replies , because that is why ? because beauty is a father replies , i see her mother\n",
            "\n",
            "KEYWORDS: rapist predator call\n",
            "TRUE: what do you call an immigrant fighting a rapist ? alien vs . predator\n",
            "RECONSTRUCTED:  what do you call an illegal immigrant fighting ? a psychological . predator .\n",
            "\n",
            "KEYWORDS: groups even\n",
            "TRUE: why do white girls always walk in groups with odd numbers ? they can ' t even\n",
            "RECONSTRUCTED:  why do white girls always cross in groups groups with groups ? they can ' t even\n",
            "\n",
            "KEYWORDS: rest made funeral awkward\n",
            "TRUE: got caught sniffing my sisters panties yesterday it made the rest of her funeral very awkward .\n",
            "RECONSTRUCTED:  kid got made out of awkwardness today it made her funeral the rest of my funeral .\n",
            "\n",
            "KEYWORDS: want making joke hear\n",
            "TRUE: you want to hear a joke ? me making it on the front page .\n",
            "RECONSTRUCTED:  you want to hear a joke about the front page ? it was making me .\n",
            "\n",
            "KEYWORDS: week set 100\n",
            "TRUE: set your wifi password to 100 so when someone ask tell them it is how many times a week this gets reposted .\n",
            "RECONSTRUCTED:  set a week to set a week away this week is set up with you set it to 100 people ending them .\n",
            "\n",
            "KEYWORDS: fascist faggot call axe\n",
            "TRUE: what do you call a faggot with an axe ? a fascist\n",
            "RECONSTRUCTED:  what do you call a faggot when an axe ? a fascist\n",
            "\n",
            "KEYWORDS: vegetables thumbs people know fingers\n",
            "TRUE: you know how all thumbs are fingers , but not all fingers are thumbs ? some people can be vegetables , but vegetables can ' t be people .\n",
            "RECONSTRUCTED:  you know what has been saying , but people are not a good comedian ? you know , but people are not a good comedian , you are not\n",
            "\n",
            "KEYWORDS: marc homosexual group friends\n",
            "TRUE: they say one in ten men are homosexual in my group of friends i ' m pretty sure it is marc . he is really cute\n",
            "RECONSTRUCTED:  they say you are homosexual in my apartment and marcrcrcrcr . it is pretty funny and marc\n",
            "\n",
            "KEYWORDS: engineers\n",
            "TRUE: a good joke for the engineers out there free time\n",
            "RECONSTRUCTED:  a good way for the rob for being engineers for\n",
            "\n",
            "KEYWORDS: writing song getting end\n",
            "TRUE: i ' m writing a song about getting my front door lock replaced . there is a lovely key change at the end .\n",
            "RECONSTRUCTED:  i ' m writing a song about getting a song at the end of the end . i ' m called the end .\n",
            "\n",
            "KEYWORDS: charge\n",
            "TRUE: i gave away all of my dead batteries free of charge .\n",
            "RECONSTRUCTED:  i don t officially rid of dead batteries away all charge .\n",
            "\n",
            "KEYWORDS: point life diarrhea 80\n",
            "TRUE: studies show that 80 of redditors suffer from diarrhea at some point in life then why are the rest enjoying it ?\n",
            "RECONSTRUCTED:  studies show that of a hardware problem in the hardware store that acceptance are it ? it is hardware sense of\n",
            "\n",
            "KEYWORDS: someone makes cents call\n",
            "TRUE: what do you call a bad european banker that talks gibberish ? someone that makes no cents .\n",
            "RECONSTRUCTED:  what do you call a poor robot who makes no cents from someone ? someone with no one page . no\n",
            "\n",
            "KEYWORDS: win olympics logic chance\n",
            "TRUE: to win the olympics , you must go big or go home . by that logic , the refugee team never had a chance .\n",
            "RECONSTRUCTED:  to win the olympics , logic , logic from the olympics . or no one chance to win the nobel of the mission from the wrong logic .\n",
            "\n",
            "KEYWORDS: frank burn\n",
            "TRUE: why won ' t people let hitler go to the bar bq ? he ' ll just burn the frank ' s\n",
            "RECONSTRUCTED:  why won ' t the people go to the third reich ? because he ' ll burn the frank ' frank ' frank\n",
            "\n",
            "KEYWORDS: porn disabled\n",
            "TRUE: is all your porn here disabled ? no it is regular porn you sick fuck .\n",
            "RECONSTRUCTED:  is there is your porn not so disabled ? it is not disabled outside .\n",
            "\n",
            "KEYWORDS: lazy descirbe\n",
            "TRUE: i can descirbe myself in just two words . lazy .\n",
            "RECONSTRUCTED:  i can desciotion . just in the deruations\n",
            "\n",
            "KEYWORDS: wife tequila cliff\n",
            "TRUE: why did the mexican man throw his wife off of a cliff ? tequila\n",
            "RECONSTRUCTED:  why did the mexican guy throw his wife off a cliff ? tequila\n",
            "\n",
            "KEYWORDS: nuts heard guy glitter dipped\n",
            "TRUE: have you heard about the guy who dipped his nuts in glitter ? pretty ballsy\n",
            "RECONSTRUCTED:  have you heard about the guy who got in glitter ? pretty nuts in glitterped nuts\n",
            "\n",
            "KEYWORDS: reason politicians diapers common\n",
            "TRUE: politicians and diapers have one thing in common . they should both be changed regularly , and for the same reason .\n",
            "RECONSTRUCTED:  politicians and diapers have one thing . and diapers walk around for the same reason for some reason for the same reason .\n",
            "\n",
            "KEYWORDS: married friends\n",
            "TRUE: why couldn ' t stevie wonder see his friends ? because he was married\n",
            "RECONSTRUCTED:  why couldn ' t stevie wonder see his friends ? he was married\n",
            "\n",
            "KEYWORDS: sex problem given example\n",
            "TRUE: nsfw houston , we have a problem i feel like porn has me given such unrealistic expectations about sex for example , having it with another person .\n",
            "RECONSTRUCTED:  i once given a small problem for example , have given an example for example , it was given me for example , you have a problem .\n",
            "\n",
            "KEYWORDS: required president know duck\n",
            "TRUE: did you know the secret service is no longer allowed to say get down when the president is getting attacked ? now they are required to say donald ,\n",
            "RECONSTRUCTED:  did you know the secret service is a bitch to get back to the united airlines ? because you don ' t know because they are busy sending forever\n",
            "\n",
            "KEYWORDS: \n",
            "TRUE: whom did the boston strangler choke last ? the atlanta falcons .\n",
            "RECONSTRUCTED:  aryarg the twin did buy food ? the last air ate the food .\n",
            "\n",
            "KEYWORDS: got friend farm cieio\n",
            "TRUE: my friend just got a new job heading up old macdonald is farm . he is the cieio\n",
            "RECONSTRUCTED:  my friend just got into old macdonald is farm after the old mcdonald is a crumbie .\n",
            "\n",
            "KEYWORDS: want library hang\n",
            "TRUE: what is the best part of the library to hang out if you want to get laid ? adult friction .\n",
            "RECONSTRUCTED:  what is the quickest way to ask the librarian to hang out of the library ? you get aids out .\n",
            "\n",
            "KEYWORDS: wife pants morning happy got found\n",
            "TRUE: i got in my wife is pants this morning . she wasn ' t too happy once she found out .\n",
            "RECONSTRUCTED:  i found my wife in this morning . she is too happy she got an identical marriage in the morning .\n",
            "\n",
            "KEYWORDS: ex eat asshole\n",
            "TRUE: if you are what you eat then that would explain why my ex is such an asshole .\n",
            "RECONSTRUCTED:  if you are what you eat by ex ? then i ex ? ex ? ex .\n",
            "\n",
            "KEYWORDS: call\n",
            "TRUE: what do you call a testicle outside earth ? a space nut\n",
            "RECONSTRUCTED:  what do you call a nut november ? a nut november\n",
            "\n",
            "KEYWORDS: work used taking fired days couple\n",
            "TRUE: i used to work in a calender factory but i was fired for taking a couple of days off .\n",
            "RECONSTRUCTED:  i used to work in a school for days loss of days loss of it was been fired for days .\n",
            "\n",
            "KEYWORDS: plenty percs make\n",
            "TRUE: being a drug dealer is a tough job . but it has plenty of percs to make up for it .\n",
            "RECONSTRUCTED:  being a per clock taste out of percs . it is plenty of percs to make a percs .\n",
            "\n",
            "KEYWORDS: really insomniac hear dyslexic dog agnostic\n",
            "TRUE: did you hear about the dyslexic , agnostic , insomniac ? he was up all night wondering if there really was a dog .\n",
            "RECONSTRUCTED:  did you hear about the dyslexic agnostic , insomniac ? he really was dyslexic awake at night wondering if there really is a dog .\n",
            "\n",
            "KEYWORDS: mum found concieved\n",
            "TRUE: i found i out i was concieved at my grandmothers funeral appearently , my mum was trying comfort him . stupid mourning wood .\n",
            "RECONSTRUCTED:  i found out i found out of my mum , really cuteboys are conciement . i found out of her funeral , peasants\n",
            "\n",
            "KEYWORDS: ransomware know\n",
            "TRUE: hey officer , how did the hackers escape ? i don ' t know , they just ransomware .\n",
            "RECONSTRUCTED:  hey , do you know what i had the history ? they ransomware , i ransoware .\n",
            "\n",
            "KEYWORDS: ridiculous health even bad\n",
            "TRUE: it is ridiculous that there was such a long debate whether smoking would be bad for the health . even the nazis knew it is .\n",
            "RECONSTRUCTED:  it is called being a health report recently that is not ridiculous . even though it was the least shocking for the ' m ' health .\n",
            "\n",
            "KEYWORDS: works fertilizer entremanure call\n",
            "TRUE: what do you call a self employed individual who works with fertilizer ? an entremanure .\n",
            "RECONSTRUCTED:  what do you call a fertilizer that works in when an entreizer ? fertilizer in .\n",
            "\n",
            "KEYWORDS: tomorrow tell take ehh change\n",
            "TRUE: how many procrastinators does it take to change a light bulb ? ehh , i ' ll tell you tomorrow .\n",
            "RECONSTRUCTED:  how many drunks does it take to change a light bulb ? eh , eh , eh , eh ? eh .\n",
            "\n",
            "KEYWORDS: time\n",
            "TRUE: child psychologists hear touching stories from time to time .\n",
            "RECONSTRUCTED:  childs should be 12rasss to be 12 .\n",
            "\n",
            "KEYWORDS: laptop difference consultant butt\n",
            "TRUE: what is the difference between an it consultant and a catholic priest ? the it consultant is laptop has no butt .\n",
            "RECONSTRUCTED:  what is the difference between consultant and consultant it is a better state ? a butt are consultant .\n",
            "\n",
            "KEYWORDS: want sticking means meaning many lot figured\n",
            "TRUE: thanks everyone i want to thank everyone for sticking with me while i figured out the meaning of many . it means a lot .\n",
            "RECONSTRUCTED:  studies i figured out how many to me i want to be a sex life . it means the meaning of me me .\n",
            "\n",
            "KEYWORDS: exactly\n",
            "TRUE: me hey bro someone said you sound like an owl bro who ? me exactly\n",
            "RECONSTRUCTED:  me exactly exactly what you like milk ? exactly exactly exactly exactly exactly exactly exactly\n",
            "\n",
            "KEYWORDS: whey claims bodybuilder\n",
            "TRUE: does anyone believe the bodybuilder who claims he never used protein suppliments ? no whey .\n",
            "RECONSTRUCTED:  does the bodybuilders feel that whey out of protein ? because he will never be whey to whey .\n",
            "\n",
            "KEYWORDS: \n",
            "TRUE: what do you call 2000 mockingbirds ? 2kilo mocking birds .\n",
            "RECONSTRUCTED:  what do you call 2000 mockingbirds ? kgs for kart .\n",
            "\n",
            "KEYWORDS: masturbate hard easy choose\n",
            "TRUE: we choose to masturbate , not because it is easy , but because it is hard .\n",
            "RECONSTRUCTED:  we masturbate to masturbate , but it is not easy , because it is not easy .\n",
            "\n",
            "KEYWORDS: aula\n",
            "TRUE: knock knock who is there ? aula . aula who ? allah huakbar\n",
            "RECONSTRUCTED:  knock knock who is there ? aulauaur . who is hyavlaient ?\n",
            "\n",
            "KEYWORDS: suicide nevermind leave joke hanging ah\n",
            "TRUE: wanna hear a joke about suicide ? ah , nevermind , i ' ll leave you hanging\n",
            "RECONSTRUCTED:  wanna hear a joke about how do you nevermind ? i ' ll leave a joke , wind\n",
            "\n",
            "KEYWORDS: pirate charge arr\n",
            "TRUE: i ' m not often hired to be a pirate but when i am , i charge by the ' arr '\n",
            "RECONSTRUCTED:  i ' m not a love but i ' m arr but i ' m arr but that was arranged\n",
            "\n",
            "KEYWORDS: sleep saw money\n",
            "TRUE: was about to sleep when i saw the robber last night in my house searching for money . i immediately got up . and searched alongside with him\n",
            "RECONSTRUCTED:  was about michael jackson in the bed with my money to sleep with his money . i saw him with money to bed with the money and saw the\n",
            "\n",
            "KEYWORDS: road\n",
            "TRUE: why did the dinosaur cross the road ? what road ?\n",
            "RECONSTRUCTED:  why did the dinosaur cross the road ? ? ?\n",
            "\n",
            "KEYWORDS: vegan proud meals call\n",
            "TRUE: i am proud to call myself a vegan but only in between meals .\n",
            "RECONSTRUCTED:  i remember to a vegan and that but it is a vegan .\n",
            "\n",
            "KEYWORDS: trying transporting tell package messed mailman joke delivery\n",
            "TRUE: a mailman was trying to tell a joke while transporting a package but he messed up the delivery\n",
            "RECONSTRUCTED:  a mailman goes to a bar he was a joke but he is the delivery driver on delivery\n",
            "\n",
            "KEYWORDS: paint\n",
            "TRUE: who is this rorschach guy and why does he paint so many penises ?\n",
            "RECONSTRUCTED:  who is this paint and paint this paint ? dungures paint and paint\n",
            "\n",
            "KEYWORDS: \n",
            "TRUE: how does harry potter order tequila shots ? patron us\n",
            "RECONSTRUCTED:  how does harry potter speak ? rick astley with tequila mockingbird\n",
            "\n",
            "KEYWORDS: wet soft pink hard goes dry comes\n",
            "TRUE: what is pink ? ? ? goes in hard and dry and comes out soft and wet a bubble gum\n",
            "RECONSTRUCTED:  what is pink about and goes out and comes out ? a bubble gum cook and comes out of bubble gum\n",
            "\n",
            "KEYWORDS: urination pee land country\n",
            "TRUE: what did the un say to the land of pee when it officially became a country ? urination .\n",
            "RECONSTRUCTED:  what did the worst place to be the fastest to it ? it will be a crum pressing .\n",
            "\n",
            "KEYWORDS: understand told ex\n",
            "TRUE: i told the ambulance guys the wrong blood type for my ex now she should understand what rejection feels like .\n",
            "RECONSTRUCTED:  i told the therapist what excluence for the exclusively i told her she is now .\n",
            "\n",
            "KEYWORDS: thanks see guess booming\n",
            "TRUE: thanks to recent events i guess you could say the pressure cooker business is booming i ' ll see myself out now .\n",
            "RECONSTRUCTED:  thanks to see someone i guess you could say the latest trending is booming i guess i ' m a booming .\n",
            "\n",
            "KEYWORDS: women way stick like hot em dick\n",
            "TRUE: i like my coffee like i like my women not too hot . that way i can stick my dick in em .\n",
            "RECONSTRUCTED:  i like my coffee like i like my coffee . i like my coffee hot tub that explains why in the way .\n",
            "\n",
            "KEYWORDS: world see need guy collided anymore\n",
            "TRUE: ever since i had that car accident i see the world with different eyes shoutout to the guy i collided with who doesn ' t need them anymore\n",
            "RECONSTRUCTED:  ever since bill clinton hates me when the world with me i need to see anymore with the boss ? i ' ll see that the world anymore\n",
            "\n",
            "KEYWORDS: play get\n",
            "TRUE: what do you get when you play a country music record backwards ? you get your wife back , your dog back , your truck back\n",
            "RECONSTRUCTED:  what do you get when you play your country back doors ? your wife , if you play forwards , you get a play awayrier\n",
            "\n",
            "KEYWORDS: salad man\n",
            "TRUE: an italian man walks into a mental hospital with salad . man it is getting caprese in here\n",
            "RECONSTRUCTED:  an italian man walks into a man with salad poisoning . man is a man ineeeee .\n",
            "\n",
            "KEYWORDS: night dick black ass\n",
            "TRUE: what is 8 inches long , and black as the night ? the dick up your ass\n",
            "RECONSTRUCTED:  what is white black , black and the night ? the night , as your ass\n",
            "\n",
            "KEYWORDS: shot bird\n",
            "TRUE: what did the awkward adolescent say when he shot a bird ? pew birdy puberty\n",
            "RECONSTRUCTED:  what did the bird fly say when he shot a bird ? honk when he shot the bird\n",
            "\n",
            "KEYWORDS: turned around addicted\n",
            "TRUE: i was addicted to the hokey pokey but , i turned myself around .\n",
            "RECONSTRUCTED:  i was addicted to the hokey pokey but i turned myself around .\n",
            "\n",
            "KEYWORDS: hell feedback\n",
            "TRUE: what brand microphone did kurt cobain use ? remingtoni head the feedback was hell .\n",
            "RECONSTRUCTED:  what videoback did machock cube ? the feedback company with the hellback ? fake .\n",
            "\n",
            "KEYWORDS: see\n",
            "TRUE: at your next helloween party expect to see the typical costumes . the sexy nurse , the sexy nun and the sexist judge .\n",
            "RECONSTRUCTED:  at a classic womans standing down the bar . you see , and says to see your sexy woman , you see a woman standing next door .\n",
            "\n",
            "KEYWORDS: allowed\n",
            "TRUE: i envy women they are allowed to have big titties and i ' m not\n",
            "RECONSTRUCTED:  i enquate me they are allowed to me and they ' m not allowed\n",
            "\n",
            "KEYWORDS: great alright\n",
            "TRUE: i think greta thunberg is alright but dyslexics think she is great\n",
            "RECONSTRUCTED:  i think christmas sex is great but now it is alright now me alright\n",
            "\n"
          ]
        }
      ],
      "source": [
        "############################### TEST WITH KEYWORDS ################################\n",
        "for i in range(100):\n",
        "  input = test_seq[i]\n",
        "  kw = test_keywords[i]\n",
        "  true = detokenize(input, tokenizer)\n",
        "  kw2 = detokenize(kw, tokenizer)\n",
        "  print(\"KEYWORDS:\", ' '.join([x for x in kw2 if x != '[PAD]' and x != '[START]']))\n",
        "  print(\"TRUE:\", ' '.join([x for x in true if x != '[PAD]' and x != '[START]']))\n",
        "  generated = reconstruct(input.reshape(1, maxlen), kw.reshape(1, maxlen), encoder, stepper, decoder, tokenizer, top_k=1)\n",
        "  print(\"RECONSTRUCTED:\", generated)\n",
        "  print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUj7THBpvliP"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GrCnT2rvuaY",
        "outputId": "d250fc5d-fb2a-463f-80e4-e0bd85ef5532"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (net): Sequential(\n",
            "    (0): Block(\n",
            "      (net): Sequential(\n",
            "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Block(\n",
            "      (net): Sequential(\n",
            "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (2): Block(\n",
            "      (net): Sequential(\n",
            "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (3): Block(\n",
            "      (net): Sequential(\n",
            "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (4): Block(\n",
            "      (net): Sequential(\n",
            "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "Critic(\n",
            "  (net): Sequential(\n",
            "    (0): Block(\n",
            "      (net): Sequential(\n",
            "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Block(\n",
            "      (net): Sequential(\n",
            "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (2): Block(\n",
            "      (net): Sequential(\n",
            "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (3): Block(\n",
            "      (net): Sequential(\n",
            "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (4): Block(\n",
            "      (net): Sequential(\n",
            "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "###################################### CREATE MODELS ############################\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Initialise variables\n",
        "batch_size = 128\n",
        "embedding_dim = 200\n",
        "latent_dim = 100\n",
        "vocab_size = 9832\n",
        "maxlen = 30\n",
        "seed=0\n",
        "n_layers = 5\n",
        "block_dim = 100\n",
        "\n",
        "# Load Data\n",
        "data = torch.tensor(source, dtype=torch.long)\n",
        "train_loader = DataLoader(data, batch_size, shuffle=True)\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Set up models\n",
        "generator = Generator(n_layers, block_dim)\n",
        "critic = Critic(n_layers, block_dim)\n",
        "\n",
        "# Load reconstructor model\n",
        "model, encoder, stepper, decoder = r_seq2seq(weights='/content/reconstruction_weights.h5')\n",
        "\n",
        "print(generator)\n",
        "print(\"\")\n",
        "print(critic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_PboSR3Gvul0",
        "outputId": "5219a008-2190-4677-c64f-1edbab069888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "G Parameters: 101000\n",
            "C Parameters: 101000\n",
            "Epoch: 1 | Batch: 0/100728 (0%) | G Loss: 0.050628 | C Loss: 2070.787354\n",
            "Epoch: 1 | Batch: 1280/100728 (1%) | G Loss: 0.011402 | C Loss: 231.502975\n",
            "Epoch: 1 | Batch: 2560/100728 (3%) | G Loss: 0.008513 | C Loss: 77.711006\n",
            "Epoch: 1 | Batch: 3840/100728 (4%) | G Loss: -0.001041 | C Loss: 40.342201\n",
            "Epoch: 1 | Batch: 5120/100728 (5%) | G Loss: -0.004943 | C Loss: 26.632645\n",
            "Epoch: 1 | Batch: 6400/100728 (6%) | G Loss: -0.006173 | C Loss: 18.942375\n",
            "Epoch: 1 | Batch: 7680/100728 (8%) | G Loss: -0.011125 | C Loss: 13.658883\n",
            "Epoch: 1 | Batch: 8960/100728 (9%) | G Loss: -0.011113 | C Loss: 10.272558\n",
            "Epoch: 1 | Batch: 10240/100728 (10%) | G Loss: -0.015191 | C Loss: 7.115499\n",
            "Epoch: 1 | Batch: 11520/100728 (11%) | G Loss: -0.019886 | C Loss: 6.406360\n",
            "Epoch: 1 | Batch: 12800/100728 (13%) | G Loss: -0.022254 | C Loss: 3.902177\n",
            "Epoch: 1 | Batch: 14080/100728 (14%) | G Loss: -0.028201 | C Loss: 3.665812\n",
            "Epoch: 1 | Batch: 15360/100728 (15%) | G Loss: -0.029135 | C Loss: 2.683629\n",
            "Epoch: 1 | Batch: 16640/100728 (17%) | G Loss: -0.031580 | C Loss: 2.022089\n",
            "Epoch: 1 | Batch: 17920/100728 (18%) | G Loss: -0.039078 | C Loss: 1.417495\n",
            "Epoch: 1 | Batch: 19200/100728 (19%) | G Loss: -0.041722 | C Loss: 1.006106\n",
            "Epoch: 1 | Batch: 20480/100728 (20%) | G Loss: -0.052611 | C Loss: 0.853766\n",
            "Epoch: 1 | Batch: 21760/100728 (22%) | G Loss: -0.064943 | C Loss: 0.594389\n",
            "Epoch: 1 | Batch: 23040/100728 (23%) | G Loss: -0.090601 | C Loss: 0.567189\n",
            "Epoch: 1 | Batch: 24320/100728 (24%) | G Loss: -0.127395 | C Loss: 0.366571\n",
            "Epoch: 1 | Batch: 25600/100728 (25%) | G Loss: -0.166005 | C Loss: 0.364803\n",
            "Epoch: 1 | Batch: 26880/100728 (27%) | G Loss: -0.219567 | C Loss: 0.563656\n",
            "Epoch: 1 | Batch: 28160/100728 (28%) | G Loss: -0.236824 | C Loss: 0.404527\n",
            "Epoch: 1 | Batch: 29440/100728 (29%) | G Loss: -0.114383 | C Loss: 0.425569\n",
            "Epoch: 1 | Batch: 30720/100728 (30%) | G Loss: 0.343810 | C Loss: -0.079807\n",
            "Epoch: 1 | Batch: 32000/100728 (32%) | G Loss: 0.915587 | C Loss: -0.360101\n",
            "Epoch: 1 | Batch: 33280/100728 (33%) | G Loss: 1.104691 | C Loss: -0.556213\n",
            "Epoch: 1 | Batch: 34560/100728 (34%) | G Loss: 0.957217 | C Loss: -0.259353\n",
            "Epoch: 1 | Batch: 35840/100728 (36%) | G Loss: 0.670442 | C Loss: 0.004676\n",
            "Epoch: 1 | Batch: 37120/100728 (37%) | G Loss: 0.429140 | C Loss: 0.341404\n",
            "Epoch: 1 | Batch: 38400/100728 (38%) | G Loss: 0.232212 | C Loss: 0.597791\n",
            "Epoch: 1 | Batch: 39680/100728 (39%) | G Loss: 0.108143 | C Loss: 0.966916\n",
            "Epoch: 1 | Batch: 40960/100728 (41%) | G Loss: 0.034587 | C Loss: 0.797091\n",
            "Epoch: 1 | Batch: 42240/100728 (42%) | G Loss: 0.002132 | C Loss: 0.667860\n",
            "Epoch: 1 | Batch: 43520/100728 (43%) | G Loss: -0.011687 | C Loss: 0.966944\n",
            "Epoch: 1 | Batch: 44800/100728 (44%) | G Loss: -0.015418 | C Loss: 0.923166\n",
            "Epoch: 1 | Batch: 46080/100728 (46%) | G Loss: -0.021652 | C Loss: 0.667209\n",
            "Epoch: 1 | Batch: 47360/100728 (47%) | G Loss: -0.021300 | C Loss: 0.573609\n",
            "Epoch: 1 | Batch: 48640/100728 (48%) | G Loss: -0.020455 | C Loss: 0.515240\n",
            "Epoch: 1 | Batch: 49920/100728 (50%) | G Loss: -0.020858 | C Loss: 0.377681\n",
            "Epoch: 1 | Batch: 51200/100728 (51%) | G Loss: -0.021961 | C Loss: 0.326656\n",
            "Epoch: 1 | Batch: 52480/100728 (52%) | G Loss: -0.021287 | C Loss: 0.304385\n",
            "Epoch: 1 | Batch: 53760/100728 (53%) | G Loss: -0.021887 | C Loss: 0.193454\n",
            "Epoch: 1 | Batch: 55040/100728 (55%) | G Loss: -0.021281 | C Loss: 0.205164\n",
            "Epoch: 1 | Batch: 56320/100728 (56%) | G Loss: -0.023382 | C Loss: 0.240760\n",
            "Epoch: 1 | Batch: 57600/100728 (57%) | G Loss: -0.022171 | C Loss: 0.176572\n",
            "Epoch: 1 | Batch: 58880/100728 (58%) | G Loss: -0.026306 | C Loss: 0.207131\n",
            "Epoch: 1 | Batch: 60160/100728 (60%) | G Loss: -0.031887 | C Loss: 0.101469\n",
            "Epoch: 1 | Batch: 61440/100728 (61%) | G Loss: -0.033773 | C Loss: 0.170959\n",
            "Epoch: 1 | Batch: 62720/100728 (62%) | G Loss: -0.033482 | C Loss: 0.093783\n",
            "Epoch: 1 | Batch: 64000/100728 (64%) | G Loss: -0.030701 | C Loss: 0.160517\n",
            "Epoch: 1 | Batch: 65280/100728 (65%) | G Loss: -0.031731 | C Loss: 0.103992\n",
            "Epoch: 1 | Batch: 66560/100728 (66%) | G Loss: -0.028630 | C Loss: 0.106112\n",
            "Epoch: 1 | Batch: 67840/100728 (67%) | G Loss: -0.017475 | C Loss: 0.092852\n",
            "Epoch: 1 | Batch: 69120/100728 (69%) | G Loss: -0.010855 | C Loss: 0.102475\n",
            "Epoch: 1 | Batch: 70400/100728 (70%) | G Loss: 0.012036 | C Loss: 0.114622\n",
            "Epoch: 1 | Batch: 71680/100728 (71%) | G Loss: 0.054914 | C Loss: 0.115879\n",
            "Epoch: 1 | Batch: 72960/100728 (72%) | G Loss: 0.101859 | C Loss: 0.129657\n",
            "Epoch: 1 | Batch: 74240/100728 (74%) | G Loss: 0.176427 | C Loss: 0.111316\n",
            "Epoch: 1 | Batch: 75520/100728 (75%) | G Loss: 0.202785 | C Loss: 0.036777\n",
            "Epoch: 1 | Batch: 76800/100728 (76%) | G Loss: 0.214679 | C Loss: 0.091414\n",
            "Epoch: 1 | Batch: 78080/100728 (78%) | G Loss: 0.178682 | C Loss: 0.138553\n",
            "Epoch: 1 | Batch: 79360/100728 (79%) | G Loss: 0.143019 | C Loss: 0.129365\n",
            "Epoch: 1 | Batch: 80640/100728 (80%) | G Loss: 0.115466 | C Loss: 0.068558\n",
            "Epoch: 1 | Batch: 81920/100728 (81%) | G Loss: 0.078154 | C Loss: 0.152387\n",
            "Epoch: 1 | Batch: 83200/100728 (83%) | G Loss: 0.055179 | C Loss: 0.051457\n",
            "Epoch: 1 | Batch: 84480/100728 (84%) | G Loss: 0.041825 | C Loss: 0.062346\n",
            "Epoch: 1 | Batch: 85760/100728 (85%) | G Loss: 0.030141 | C Loss: 0.129703\n",
            "Epoch: 1 | Batch: 87040/100728 (86%) | G Loss: 0.010899 | C Loss: 0.196170\n",
            "Epoch: 1 | Batch: 88320/100728 (88%) | G Loss: 0.004825 | C Loss: 0.137001\n",
            "Epoch: 1 | Batch: 89600/100728 (89%) | G Loss: 0.002395 | C Loss: 0.128110\n",
            "Epoch: 1 | Batch: 90880/100728 (90%) | G Loss: -0.010918 | C Loss: 0.135385\n",
            "Epoch: 1 | Batch: 92160/100728 (91%) | G Loss: -0.014190 | C Loss: 0.158909\n",
            "Epoch: 1 | Batch: 93440/100728 (93%) | G Loss: -0.010688 | C Loss: 0.275771\n",
            "Epoch: 1 | Batch: 94720/100728 (94%) | G Loss: -0.014680 | C Loss: 0.142346\n",
            "Epoch: 1 | Batch: 96000/100728 (95%) | G Loss: -0.018943 | C Loss: 0.111953\n",
            "Epoch: 1 | Batch: 97280/100728 (97%) | G Loss: -0.025258 | C Loss: 0.123693\n",
            "Epoch: 1 | Batch: 98560/100728 (98%) | G Loss: -0.033660 | C Loss: 0.212165\n",
            "Epoch: 1 | Batch: 99840/100728 (99%) | G Loss: -0.049143 | C Loss: 0.121299\n",
            "* (Train) Epoch: 1 | G Loss: 0.0529 | C Loss: 15.3148\n",
            "* Saved\n",
            " ow testicle eye eye testicle weak those eye baiter other other other other other other other other other other other other other other other other other other other other\n",
            " roulette pickle is eye enters those other other other other other other other other other other other other other other other other other other other other other other other\n",
            " vision is any other pickle other any weak those i like is spouse i enters other other other other other other other other other other other other other other\n",
            " pickle enters any eye eye other those other other other other other other other other other other other other other other other other other other other other other other\n",
            " german pickle is pickle is eye good eye ow other those eye ow other other other other other other other other other other other other other other other other\n",
            " anal one is spouse that other eye any other other other other other other other other other other other other other other other eye eye eye eye eye eye\n",
            " pickle enters any other other those eye ow other other other other other other other other other other other other other other other other other other other other other\n",
            " anal is amazing those other other other other eye any other other eye\n",
            " pickle enters other those eye eye any other other other other other other other other other other other other other other other other other other otherbby i vision\n",
            " regular pornstars is any eye other weak any other other other other other other other other other other other other other other other other other eye eye eye eye\n",
            "\n",
            "Epoch: 2 | Batch: 0/100728 (0%) | G Loss: -0.059680 | C Loss: 0.139803\n",
            "Epoch: 2 | Batch: 1280/100728 (1%) | G Loss: -0.046949 | C Loss: 0.105737\n",
            "Epoch: 2 | Batch: 2560/100728 (3%) | G Loss: -0.018951 | C Loss: 0.073587\n",
            "Epoch: 2 | Batch: 3840/100728 (4%) | G Loss: 0.009678 | C Loss: 0.016681\n",
            "Epoch: 2 | Batch: 5120/100728 (5%) | G Loss: 0.077412 | C Loss: 0.025804\n",
            "Epoch: 2 | Batch: 6400/100728 (6%) | G Loss: 0.149824 | C Loss: -0.058026\n",
            "Epoch: 2 | Batch: 7680/100728 (8%) | G Loss: 0.209525 | C Loss: -0.115869\n",
            "Epoch: 2 | Batch: 8960/100728 (9%) | G Loss: 0.195674 | C Loss: -0.067984\n",
            "Epoch: 2 | Batch: 10240/100728 (10%) | G Loss: 0.180298 | C Loss: -0.131499\n",
            "Epoch: 2 | Batch: 11520/100728 (11%) | G Loss: 0.164237 | C Loss: -0.044546\n",
            "Epoch: 2 | Batch: 12800/100728 (13%) | G Loss: 0.116607 | C Loss: -0.062644\n",
            "Epoch: 2 | Batch: 14080/100728 (14%) | G Loss: 0.082816 | C Loss: -0.014654\n",
            "Epoch: 2 | Batch: 15360/100728 (15%) | G Loss: 0.057323 | C Loss: -0.042598\n",
            "Epoch: 2 | Batch: 16640/100728 (17%) | G Loss: 0.030167 | C Loss: -0.022829\n",
            "Epoch: 2 | Batch: 17920/100728 (18%) | G Loss: 0.020427 | C Loss: -0.000991\n",
            "Epoch: 2 | Batch: 19200/100728 (19%) | G Loss: 0.001853 | C Loss: 0.003112\n",
            "Epoch: 2 | Batch: 20480/100728 (20%) | G Loss: -0.015254 | C Loss: 0.034154\n",
            "Epoch: 2 | Batch: 21760/100728 (22%) | G Loss: -0.024245 | C Loss: 0.057031\n",
            "Epoch: 2 | Batch: 23040/100728 (23%) | G Loss: -0.029746 | C Loss: 0.030237\n",
            "Epoch: 2 | Batch: 24320/100728 (24%) | G Loss: -0.039806 | C Loss: 0.042531\n",
            "Epoch: 2 | Batch: 25600/100728 (25%) | G Loss: -0.047565 | C Loss: 0.066963\n",
            "Epoch: 2 | Batch: 26880/100728 (27%) | G Loss: -0.053177 | C Loss: 0.105410\n",
            "Epoch: 2 | Batch: 28160/100728 (28%) | G Loss: -0.059450 | C Loss: 0.168127\n",
            "Epoch: 2 | Batch: 29440/100728 (29%) | G Loss: -0.066376 | C Loss: 0.109397\n",
            "Epoch: 2 | Batch: 30720/100728 (30%) | G Loss: -0.072529 | C Loss: 0.130736\n",
            "Epoch: 2 | Batch: 32000/100728 (32%) | G Loss: -0.077709 | C Loss: 0.134157\n",
            "Epoch: 2 | Batch: 33280/100728 (33%) | G Loss: -0.084157 | C Loss: 0.081424\n",
            "Epoch: 2 | Batch: 34560/100728 (34%) | G Loss: -0.089096 | C Loss: 0.091246\n",
            "Epoch: 2 | Batch: 35840/100728 (36%) | G Loss: -0.089028 | C Loss: 0.073365\n",
            "Epoch: 2 | Batch: 37120/100728 (37%) | G Loss: -0.091051 | C Loss: 0.116320\n",
            "Epoch: 2 | Batch: 38400/100728 (38%) | G Loss: -0.094502 | C Loss: 0.101595\n",
            "Epoch: 2 | Batch: 39680/100728 (39%) | G Loss: -0.096743 | C Loss: 0.068789\n",
            "Epoch: 2 | Batch: 40960/100728 (41%) | G Loss: -0.096584 | C Loss: 0.057117\n",
            "Epoch: 2 | Batch: 42240/100728 (42%) | G Loss: -0.099469 | C Loss: 0.043121\n",
            "Epoch: 2 | Batch: 43520/100728 (43%) | G Loss: -0.099619 | C Loss: 0.036270\n",
            "Epoch: 2 | Batch: 44800/100728 (44%) | G Loss: -0.108280 | C Loss: 0.060098\n",
            "Epoch: 2 | Batch: 46080/100728 (46%) | G Loss: -0.110003 | C Loss: 0.058516\n",
            "Epoch: 2 | Batch: 47360/100728 (47%) | G Loss: -0.114499 | C Loss: 0.056291\n",
            "Epoch: 2 | Batch: 48640/100728 (48%) | G Loss: -0.111916 | C Loss: 0.055654\n",
            "Epoch: 2 | Batch: 49920/100728 (50%) | G Loss: -0.103318 | C Loss: 0.038675\n",
            "Epoch: 2 | Batch: 51200/100728 (51%) | G Loss: -0.069782 | C Loss: -0.000299\n",
            "Epoch: 2 | Batch: 52480/100728 (52%) | G Loss: -0.019712 | C Loss: -0.017323\n",
            "Epoch: 2 | Batch: 53760/100728 (53%) | G Loss: 0.026495 | C Loss: -0.094379\n",
            "Epoch: 2 | Batch: 55040/100728 (55%) | G Loss: 0.063455 | C Loss: -0.135259\n",
            "Epoch: 2 | Batch: 56320/100728 (56%) | G Loss: 0.066774 | C Loss: -0.117892\n",
            "Epoch: 2 | Batch: 57600/100728 (57%) | G Loss: 0.043522 | C Loss: -0.088405\n",
            "Epoch: 2 | Batch: 58880/100728 (58%) | G Loss: 0.021564 | C Loss: -0.059527\n",
            "Epoch: 2 | Batch: 60160/100728 (60%) | G Loss: -0.013518 | C Loss: -0.054247\n",
            "Epoch: 2 | Batch: 61440/100728 (61%) | G Loss: -0.040814 | C Loss: -0.018641\n",
            "Epoch: 2 | Batch: 62720/100728 (62%) | G Loss: -0.068770 | C Loss: -0.027340\n",
            "Epoch: 2 | Batch: 64000/100728 (64%) | G Loss: -0.080917 | C Loss: 0.008250\n",
            "Epoch: 2 | Batch: 65280/100728 (65%) | G Loss: -0.090887 | C Loss: 0.001480\n",
            "Epoch: 2 | Batch: 66560/100728 (66%) | G Loss: -0.094691 | C Loss: -0.004964\n",
            "Epoch: 2 | Batch: 67840/100728 (67%) | G Loss: -0.095997 | C Loss: -0.008448\n",
            "Epoch: 2 | Batch: 69120/100728 (69%) | G Loss: -0.099464 | C Loss: 0.018828\n",
            "Epoch: 2 | Batch: 70400/100728 (70%) | G Loss: -0.101494 | C Loss: 0.026496\n",
            "Epoch: 2 | Batch: 71680/100728 (71%) | G Loss: -0.103387 | C Loss: -0.006564\n",
            "Epoch: 2 | Batch: 72960/100728 (72%) | G Loss: -0.103767 | C Loss: 0.010534\n",
            "Epoch: 2 | Batch: 74240/100728 (74%) | G Loss: -0.105218 | C Loss: 0.004459\n",
            "Epoch: 2 | Batch: 75520/100728 (75%) | G Loss: -0.108030 | C Loss: -0.010553\n",
            "Epoch: 2 | Batch: 76800/100728 (76%) | G Loss: -0.110138 | C Loss: -0.006998\n",
            "Epoch: 2 | Batch: 78080/100728 (78%) | G Loss: -0.111881 | C Loss: 0.065692\n",
            "Epoch: 2 | Batch: 79360/100728 (79%) | G Loss: -0.113627 | C Loss: 0.021677\n",
            "Epoch: 2 | Batch: 80640/100728 (80%) | G Loss: -0.115263 | C Loss: -0.005221\n",
            "Epoch: 2 | Batch: 81920/100728 (81%) | G Loss: -0.117878 | C Loss: 0.017257\n",
            "Epoch: 2 | Batch: 83200/100728 (83%) | G Loss: -0.117599 | C Loss: 0.074893\n",
            "Epoch: 2 | Batch: 84480/100728 (84%) | G Loss: -0.120411 | C Loss: 0.006335\n",
            "Epoch: 2 | Batch: 85760/100728 (85%) | G Loss: -0.120622 | C Loss: 0.042881\n",
            "Epoch: 2 | Batch: 87040/100728 (86%) | G Loss: -0.122999 | C Loss: 0.022196\n",
            "Epoch: 2 | Batch: 88320/100728 (88%) | G Loss: -0.123271 | C Loss: 0.016077\n",
            "Epoch: 2 | Batch: 89600/100728 (89%) | G Loss: -0.124327 | C Loss: 0.049062\n",
            "Epoch: 2 | Batch: 90880/100728 (90%) | G Loss: -0.128620 | C Loss: 0.059518\n",
            "Epoch: 2 | Batch: 92160/100728 (91%) | G Loss: -0.128130 | C Loss: 0.064078\n",
            "Epoch: 2 | Batch: 93440/100728 (93%) | G Loss: -0.130441 | C Loss: 0.146337\n",
            "Epoch: 2 | Batch: 94720/100728 (94%) | G Loss: -0.132400 | C Loss: 0.052105\n",
            "Epoch: 2 | Batch: 96000/100728 (95%) | G Loss: -0.132878 | C Loss: 0.061019\n",
            "Epoch: 2 | Batch: 97280/100728 (97%) | G Loss: -0.133647 | C Loss: 0.056104\n",
            "Epoch: 2 | Batch: 98560/100728 (98%) | G Loss: -0.137642 | C Loss: 0.033132\n",
            "Epoch: 2 | Batch: 99840/100728 (99%) | G Loss: -0.138177 | C Loss: 0.033805\n",
            "* (Train) Epoch: 2 | G Loss: -0.0513 | C Loss: 0.0259\n",
            "* Saved\n",
            " turn . a farm technician farm boom boom boom boom farm farm the farm farm farm farm farm farm farm farm farm farm farm farm farm farm farm farm\n",
            " farts ? an e are trapped by 10 pounds of seeds\n",
            " consider consider prefers coffee and the single panda every after melania melania melania melania melania melania after melania melania\n",
            " not a thesaurus manufacturer asuh , but it can king midas the airrier , it has you siri wing weenie\n",
            " this black people as r aww r aww r aww r aww\n",
            " ? ? dive ? ? dive ? dive ? dive ? dive ? dive ?\n",
            " the asian were do on the asian scientist as a parrot ? a scientist has a hard to reed , i eventually do this as on this\n",
            " so , temperwriter , albert album jeff bezos album album prefers the atomic wild ago without clay shepherdless\n",
            " ? albert ? a white grenade the really ? ? ? it . it ? .\n",
            " pasta smells like to to get a woman with a woman hunters\n",
            "\n",
            "Epoch: 3 | Batch: 0/100728 (0%) | G Loss: -0.137955 | C Loss: 0.089604\n",
            "Epoch: 3 | Batch: 1280/100728 (1%) | G Loss: -0.137743 | C Loss: 0.042405\n",
            "Epoch: 3 | Batch: 2560/100728 (3%) | G Loss: -0.138253 | C Loss: 0.067543\n",
            "Epoch: 3 | Batch: 3840/100728 (4%) | G Loss: -0.138424 | C Loss: 0.013753\n",
            "Epoch: 3 | Batch: 5120/100728 (5%) | G Loss: -0.137153 | C Loss: 0.014481\n",
            "Epoch: 3 | Batch: 6400/100728 (6%) | G Loss: -0.138796 | C Loss: 0.021089\n",
            "Epoch: 3 | Batch: 7680/100728 (8%) | G Loss: -0.137999 | C Loss: 0.025716\n",
            "Epoch: 3 | Batch: 8960/100728 (9%) | G Loss: -0.137193 | C Loss: 0.044735\n",
            "Epoch: 3 | Batch: 10240/100728 (10%) | G Loss: -0.134752 | C Loss: 0.077188\n",
            "Epoch: 3 | Batch: 11520/100728 (11%) | G Loss: -0.135362 | C Loss: 0.101553\n",
            "Epoch: 3 | Batch: 12800/100728 (13%) | G Loss: -0.135373 | C Loss: 0.022224\n",
            "Epoch: 3 | Batch: 14080/100728 (14%) | G Loss: -0.131751 | C Loss: 0.021756\n",
            "Epoch: 3 | Batch: 15360/100728 (15%) | G Loss: -0.130579 | C Loss: 0.021154\n",
            "Epoch: 3 | Batch: 16640/100728 (17%) | G Loss: -0.128837 | C Loss: 0.042348\n",
            "Epoch: 3 | Batch: 17920/100728 (18%) | G Loss: -0.124234 | C Loss: 0.032290\n",
            "Epoch: 3 | Batch: 19200/100728 (19%) | G Loss: -0.123280 | C Loss: 0.010038\n",
            "Epoch: 3 | Batch: 20480/100728 (20%) | G Loss: -0.123045 | C Loss: 0.000407\n",
            "Epoch: 3 | Batch: 21760/100728 (22%) | G Loss: -0.121609 | C Loss: 0.008513\n",
            "Epoch: 3 | Batch: 23040/100728 (23%) | G Loss: -0.119684 | C Loss: 0.004794\n",
            "Epoch: 3 | Batch: 24320/100728 (24%) | G Loss: -0.119654 | C Loss: 0.019119\n",
            "Epoch: 3 | Batch: 25600/100728 (25%) | G Loss: -0.118379 | C Loss: -0.005914\n",
            "Epoch: 3 | Batch: 26880/100728 (27%) | G Loss: -0.117785 | C Loss: -0.000252\n",
            "Epoch: 3 | Batch: 28160/100728 (28%) | G Loss: -0.119758 | C Loss: 0.011360\n",
            "Epoch: 3 | Batch: 29440/100728 (29%) | G Loss: -0.115845 | C Loss: 0.012709\n",
            "Epoch: 3 | Batch: 30720/100728 (30%) | G Loss: -0.117650 | C Loss: 0.021486\n",
            "Epoch: 3 | Batch: 32000/100728 (32%) | G Loss: -0.118523 | C Loss: 0.005140\n",
            "Epoch: 3 | Batch: 33280/100728 (33%) | G Loss: -0.120155 | C Loss: -0.003619\n",
            "Epoch: 3 | Batch: 34560/100728 (34%) | G Loss: -0.120533 | C Loss: 0.009350\n",
            "Epoch: 3 | Batch: 35840/100728 (36%) | G Loss: -0.121790 | C Loss: -0.013392\n",
            "Epoch: 3 | Batch: 37120/100728 (37%) | G Loss: -0.121437 | C Loss: -0.006311\n",
            "Epoch: 3 | Batch: 38400/100728 (38%) | G Loss: -0.124565 | C Loss: -0.006918\n",
            "Epoch: 3 | Batch: 39680/100728 (39%) | G Loss: -0.125687 | C Loss: 0.006823\n",
            "Epoch: 3 | Batch: 40960/100728 (41%) | G Loss: -0.127077 | C Loss: 0.017751\n",
            "Epoch: 3 | Batch: 42240/100728 (42%) | G Loss: -0.126374 | C Loss: -0.000707\n",
            "Epoch: 3 | Batch: 43520/100728 (43%) | G Loss: -0.126564 | C Loss: -0.004520\n",
            "Epoch: 3 | Batch: 44800/100728 (44%) | G Loss: -0.127006 | C Loss: 0.017471\n",
            "Epoch: 3 | Batch: 46080/100728 (46%) | G Loss: -0.127838 | C Loss: -0.006189\n",
            "Epoch: 3 | Batch: 47360/100728 (47%) | G Loss: -0.126179 | C Loss: 0.023855\n",
            "Epoch: 3 | Batch: 48640/100728 (48%) | G Loss: -0.123950 | C Loss: 0.014508\n",
            "Epoch: 3 | Batch: 49920/100728 (50%) | G Loss: -0.124877 | C Loss: -0.002533\n",
            "Epoch: 3 | Batch: 51200/100728 (51%) | G Loss: -0.127473 | C Loss: 0.003101\n",
            "Epoch: 3 | Batch: 52480/100728 (52%) | G Loss: -0.126191 | C Loss: 0.006200\n",
            "Epoch: 3 | Batch: 53760/100728 (53%) | G Loss: -0.125680 | C Loss: -0.003904\n",
            "Epoch: 3 | Batch: 55040/100728 (55%) | G Loss: -0.124116 | C Loss: 0.000015\n",
            "Epoch: 3 | Batch: 56320/100728 (56%) | G Loss: -0.124858 | C Loss: 0.005639\n",
            "Epoch: 3 | Batch: 57600/100728 (57%) | G Loss: -0.126160 | C Loss: -0.006072\n",
            "Epoch: 3 | Batch: 58880/100728 (58%) | G Loss: -0.126158 | C Loss: 0.001010\n",
            "Epoch: 3 | Batch: 60160/100728 (60%) | G Loss: -0.125607 | C Loss: -0.006551\n",
            "Epoch: 3 | Batch: 61440/100728 (61%) | G Loss: -0.125550 | C Loss: -0.010586\n",
            "Epoch: 3 | Batch: 62720/100728 (62%) | G Loss: -0.126987 | C Loss: -0.009665\n",
            "Epoch: 3 | Batch: 64000/100728 (64%) | G Loss: -0.124460 | C Loss: -0.017305\n",
            "Epoch: 3 | Batch: 65280/100728 (65%) | G Loss: -0.126264 | C Loss: -0.001329\n",
            "Epoch: 3 | Batch: 66560/100728 (66%) | G Loss: -0.128095 | C Loss: -0.008483\n",
            "Epoch: 3 | Batch: 67840/100728 (67%) | G Loss: -0.126987 | C Loss: -0.004489\n",
            "Epoch: 3 | Batch: 69120/100728 (69%) | G Loss: -0.128643 | C Loss: -0.001291\n",
            "Epoch: 3 | Batch: 70400/100728 (70%) | G Loss: -0.129488 | C Loss: -0.009104\n",
            "Epoch: 3 | Batch: 71680/100728 (71%) | G Loss: -0.127838 | C Loss: -0.013029\n",
            "Epoch: 3 | Batch: 72960/100728 (72%) | G Loss: -0.128415 | C Loss: -0.008019\n",
            "Epoch: 3 | Batch: 74240/100728 (74%) | G Loss: -0.129137 | C Loss: -0.001666\n",
            "Epoch: 3 | Batch: 75520/100728 (75%) | G Loss: -0.131002 | C Loss: -0.003264\n",
            "Epoch: 3 | Batch: 76800/100728 (76%) | G Loss: -0.128886 | C Loss: 0.004946\n",
            "Epoch: 3 | Batch: 78080/100728 (78%) | G Loss: -0.128528 | C Loss: -0.006287\n",
            "Epoch: 3 | Batch: 79360/100728 (79%) | G Loss: -0.129658 | C Loss: -0.000187\n",
            "Epoch: 3 | Batch: 80640/100728 (80%) | G Loss: -0.129423 | C Loss: -0.002831\n",
            "Epoch: 3 | Batch: 81920/100728 (81%) | G Loss: -0.129172 | C Loss: -0.005579\n",
            "Epoch: 3 | Batch: 83200/100728 (83%) | G Loss: -0.130875 | C Loss: -0.000744\n",
            "Epoch: 3 | Batch: 84480/100728 (84%) | G Loss: -0.128367 | C Loss: -0.002020\n",
            "Epoch: 3 | Batch: 85760/100728 (85%) | G Loss: -0.128857 | C Loss: 0.008294\n",
            "Epoch: 3 | Batch: 87040/100728 (86%) | G Loss: -0.129049 | C Loss: -0.009233\n",
            "Epoch: 3 | Batch: 88320/100728 (88%) | G Loss: -0.128421 | C Loss: -0.006040\n",
            "Epoch: 3 | Batch: 89600/100728 (89%) | G Loss: -0.128590 | C Loss: -0.004501\n",
            "Epoch: 3 | Batch: 90880/100728 (90%) | G Loss: -0.127248 | C Loss: -0.007052\n",
            "Epoch: 3 | Batch: 92160/100728 (91%) | G Loss: -0.126227 | C Loss: 0.008867\n",
            "Epoch: 3 | Batch: 93440/100728 (93%) | G Loss: -0.127309 | C Loss: -0.005416\n",
            "Epoch: 3 | Batch: 94720/100728 (94%) | G Loss: -0.125988 | C Loss: -0.008525\n",
            "Epoch: 3 | Batch: 96000/100728 (95%) | G Loss: -0.125401 | C Loss: -0.006529\n",
            "Epoch: 3 | Batch: 97280/100728 (97%) | G Loss: -0.123802 | C Loss: -0.012118\n",
            "Epoch: 3 | Batch: 98560/100728 (98%) | G Loss: -0.124158 | C Loss: -0.015316\n",
            "Epoch: 3 | Batch: 99840/100728 (99%) | G Loss: -0.123775 | C Loss: -0.010444\n",
            "* (Train) Epoch: 3 | G Loss: -0.1271 | C Loss: 0.0074\n",
            "* Saved\n",
            " ranch will be last every every every every every every every you never will finally never .\n",
            " there i ' blonde stops so after every straw . never stops after every straw . every straw i never will never forget . . .\n",
            " detective the tisschess staff of bunnies are planting recipe staffcotzzle his carpet planting recipes\n",
            " did there isaac in the joke .\n",
            " what sauce purpose donald trump have you to you to the you you flush you you toast you toast\n",
            " how spies intolerant little pimple builders whether about you not little whine it\n",
            " who do thai had had an gonna rescue rescue rescue baby before they never lands ? never lands\n",
            " ' after never gives aladdin skywalker after he was un fo fo fo fo fo fo fo fo fo fo fo fo fo fo fo fo fo fo fo\n",
            " what is ' there is a baby delivery ? have roast before they tasted before they roast up before they tasted before before they don ' ' ' '\n",
            " what and this letter the f one letter we one letter white white white white white white white white\n",
            "\n",
            "Epoch: 4 | Batch: 0/100728 (0%) | G Loss: -0.123855 | C Loss: -0.018834\n",
            "Epoch: 4 | Batch: 1280/100728 (1%) | G Loss: -0.123263 | C Loss: -0.011095\n",
            "Epoch: 4 | Batch: 2560/100728 (3%) | G Loss: -0.122235 | C Loss: -0.021387\n",
            "Epoch: 4 | Batch: 3840/100728 (4%) | G Loss: -0.122518 | C Loss: -0.011708\n",
            "Epoch: 4 | Batch: 5120/100728 (5%) | G Loss: -0.121195 | C Loss: -0.014007\n",
            "Epoch: 4 | Batch: 6400/100728 (6%) | G Loss: -0.118893 | C Loss: -0.021974\n",
            "Epoch: 4 | Batch: 7680/100728 (8%) | G Loss: -0.120925 | C Loss: -0.017537\n",
            "Epoch: 4 | Batch: 8960/100728 (9%) | G Loss: -0.121633 | C Loss: -0.023110\n",
            "Epoch: 4 | Batch: 10240/100728 (10%) | G Loss: -0.122769 | C Loss: -0.022328\n",
            "Epoch: 4 | Batch: 11520/100728 (11%) | G Loss: -0.120907 | C Loss: -0.016998\n",
            "Epoch: 4 | Batch: 12800/100728 (13%) | G Loss: -0.123700 | C Loss: -0.021704\n",
            "Epoch: 4 | Batch: 14080/100728 (14%) | G Loss: -0.124943 | C Loss: -0.013362\n",
            "Epoch: 4 | Batch: 15360/100728 (15%) | G Loss: -0.123363 | C Loss: -0.023139\n",
            "Epoch: 4 | Batch: 16640/100728 (17%) | G Loss: -0.123856 | C Loss: -0.017671\n",
            "Epoch: 4 | Batch: 17920/100728 (18%) | G Loss: -0.124715 | C Loss: -0.017317\n",
            "Epoch: 4 | Batch: 19200/100728 (19%) | G Loss: -0.125295 | C Loss: -0.015448\n",
            "Epoch: 4 | Batch: 20480/100728 (20%) | G Loss: -0.127062 | C Loss: -0.019236\n",
            "Epoch: 4 | Batch: 21760/100728 (22%) | G Loss: -0.127986 | C Loss: -0.017174\n",
            "Epoch: 4 | Batch: 23040/100728 (23%) | G Loss: -0.127778 | C Loss: -0.018725\n",
            "Epoch: 4 | Batch: 24320/100728 (24%) | G Loss: -0.129232 | C Loss: -0.014994\n",
            "Epoch: 4 | Batch: 25600/100728 (25%) | G Loss: -0.128746 | C Loss: -0.019810\n",
            "Epoch: 4 | Batch: 26880/100728 (27%) | G Loss: -0.129192 | C Loss: 0.006774\n",
            "Epoch: 4 | Batch: 28160/100728 (28%) | G Loss: -0.129431 | C Loss: -0.013876\n",
            "Epoch: 4 | Batch: 29440/100728 (29%) | G Loss: -0.129031 | C Loss: -0.014458\n",
            "Epoch: 4 | Batch: 30720/100728 (30%) | G Loss: -0.131140 | C Loss: -0.010549\n",
            "Epoch: 4 | Batch: 32000/100728 (32%) | G Loss: -0.132672 | C Loss: -0.015367\n",
            "Epoch: 4 | Batch: 33280/100728 (33%) | G Loss: -0.133370 | C Loss: -0.013191\n",
            "Epoch: 4 | Batch: 34560/100728 (34%) | G Loss: -0.132909 | C Loss: -0.008111\n",
            "Epoch: 4 | Batch: 35840/100728 (36%) | G Loss: -0.134336 | C Loss: -0.013755\n",
            "Epoch: 4 | Batch: 37120/100728 (37%) | G Loss: -0.133843 | C Loss: -0.010459\n",
            "Epoch: 4 | Batch: 38400/100728 (38%) | G Loss: -0.135788 | C Loss: -0.009513\n",
            "Epoch: 4 | Batch: 39680/100728 (39%) | G Loss: -0.133940 | C Loss: -0.014962\n",
            "Epoch: 4 | Batch: 40960/100728 (41%) | G Loss: -0.134873 | C Loss: -0.008582\n",
            "Epoch: 4 | Batch: 42240/100728 (42%) | G Loss: -0.134652 | C Loss: -0.011603\n",
            "Epoch: 4 | Batch: 43520/100728 (43%) | G Loss: -0.133933 | C Loss: -0.007250\n",
            "Epoch: 4 | Batch: 44800/100728 (44%) | G Loss: -0.134703 | C Loss: -0.011437\n",
            "Epoch: 4 | Batch: 46080/100728 (46%) | G Loss: -0.135425 | C Loss: -0.008412\n",
            "Epoch: 4 | Batch: 47360/100728 (47%) | G Loss: -0.134667 | C Loss: -0.007273\n",
            "Epoch: 4 | Batch: 48640/100728 (48%) | G Loss: -0.132896 | C Loss: -0.007987\n",
            "Epoch: 4 | Batch: 49920/100728 (50%) | G Loss: -0.134133 | C Loss: -0.010536\n",
            "Epoch: 4 | Batch: 51200/100728 (51%) | G Loss: -0.134519 | C Loss: -0.009958\n",
            "Epoch: 4 | Batch: 52480/100728 (52%) | G Loss: -0.135954 | C Loss: -0.008112\n",
            "Epoch: 4 | Batch: 53760/100728 (53%) | G Loss: -0.132572 | C Loss: -0.008216\n",
            "Epoch: 4 | Batch: 55040/100728 (55%) | G Loss: -0.132380 | C Loss: -0.014243\n",
            "Epoch: 4 | Batch: 56320/100728 (56%) | G Loss: -0.132891 | C Loss: -0.011471\n",
            "Epoch: 4 | Batch: 57600/100728 (57%) | G Loss: -0.130710 | C Loss: -0.011894\n",
            "Epoch: 4 | Batch: 58880/100728 (58%) | G Loss: -0.129301 | C Loss: -0.011950\n",
            "Epoch: 4 | Batch: 60160/100728 (60%) | G Loss: -0.128553 | C Loss: -0.013359\n",
            "Epoch: 4 | Batch: 61440/100728 (61%) | G Loss: -0.124675 | C Loss: -0.016183\n",
            "Epoch: 4 | Batch: 62720/100728 (62%) | G Loss: -0.123782 | C Loss: -0.014385\n",
            "Epoch: 4 | Batch: 64000/100728 (64%) | G Loss: -0.119861 | C Loss: -0.019677\n",
            "Epoch: 4 | Batch: 65280/100728 (65%) | G Loss: -0.119597 | C Loss: -0.021793\n",
            "Epoch: 4 | Batch: 66560/100728 (66%) | G Loss: -0.117254 | C Loss: -0.026035\n",
            "Epoch: 4 | Batch: 67840/100728 (67%) | G Loss: -0.117235 | C Loss: -0.024727\n",
            "Epoch: 4 | Batch: 69120/100728 (69%) | G Loss: -0.118701 | C Loss: -0.024578\n",
            "Epoch: 4 | Batch: 70400/100728 (70%) | G Loss: -0.117104 | C Loss: -0.028420\n",
            "Epoch: 4 | Batch: 71680/100728 (71%) | G Loss: -0.116994 | C Loss: -0.027341\n",
            "Epoch: 4 | Batch: 72960/100728 (72%) | G Loss: -0.117429 | C Loss: -0.029394\n",
            "Epoch: 4 | Batch: 74240/100728 (74%) | G Loss: -0.118784 | C Loss: -0.025400\n",
            "Epoch: 4 | Batch: 75520/100728 (75%) | G Loss: -0.120755 | C Loss: -0.028556\n",
            "Epoch: 4 | Batch: 76800/100728 (76%) | G Loss: -0.121836 | C Loss: -0.023189\n",
            "Epoch: 4 | Batch: 78080/100728 (78%) | G Loss: -0.122811 | C Loss: -0.023626\n",
            "Epoch: 4 | Batch: 79360/100728 (79%) | G Loss: -0.122744 | C Loss: -0.024480\n",
            "Epoch: 4 | Batch: 80640/100728 (80%) | G Loss: -0.124055 | C Loss: -0.028387\n",
            "Epoch: 4 | Batch: 81920/100728 (81%) | G Loss: -0.124217 | C Loss: -0.023329\n",
            "Epoch: 4 | Batch: 83200/100728 (83%) | G Loss: -0.125151 | C Loss: -0.022826\n",
            "Epoch: 4 | Batch: 84480/100728 (84%) | G Loss: -0.126228 | C Loss: -0.022788\n",
            "Epoch: 4 | Batch: 85760/100728 (85%) | G Loss: -0.129050 | C Loss: -0.019114\n",
            "Epoch: 4 | Batch: 87040/100728 (86%) | G Loss: -0.131101 | C Loss: -0.018338\n",
            "Epoch: 4 | Batch: 88320/100728 (88%) | G Loss: -0.131370 | C Loss: -0.019817\n",
            "Epoch: 4 | Batch: 89600/100728 (89%) | G Loss: -0.132225 | C Loss: -0.016460\n",
            "Epoch: 4 | Batch: 90880/100728 (90%) | G Loss: -0.134604 | C Loss: -0.018487\n",
            "Epoch: 4 | Batch: 92160/100728 (91%) | G Loss: -0.134473 | C Loss: -0.012618\n",
            "Epoch: 4 | Batch: 93440/100728 (93%) | G Loss: -0.136774 | C Loss: -0.012596\n",
            "Epoch: 4 | Batch: 94720/100728 (94%) | G Loss: -0.138072 | C Loss: -0.012183\n",
            "Epoch: 4 | Batch: 96000/100728 (95%) | G Loss: -0.139769 | C Loss: -0.010137\n",
            "Epoch: 4 | Batch: 97280/100728 (97%) | G Loss: -0.138918 | C Loss: -0.011837\n",
            "Epoch: 4 | Batch: 98560/100728 (98%) | G Loss: -0.139615 | C Loss: -0.011447\n",
            "Epoch: 4 | Batch: 99840/100728 (99%) | G Loss: -0.140335 | C Loss: -0.004527\n",
            "* (Train) Epoch: 4 | G Loss: -0.1281 | C Loss: -0.0152\n",
            "* Saved\n",
            " what when the furries are meatlings a fly meat a a barkami bark ? .\n",
            " best so the whole hen has one but it takes too many calories , too .\n",
            " is taken wolverine must be santa .\n",
            " supplies from the least sofa clinton have the highest building in the least the design the design kick kinoys\n",
            " how . that only has little spaghetti spaghetti and . . . .\n",
            " liars liars the liars . liars liars liars .\n",
            " what did epileptictyling from your cock ? from an epileptic cock pan .\n",
            " dead mute up most busty mayo , a senior biker limbs treasure assaulted a penguin . penguin treasureneockne\n",
            " i polish loves that , were fed thousands of a giant crab toler , andler .\n",
            " the only the ideal longer defeat .\n",
            "\n",
            "Epoch: 5 | Batch: 0/100728 (0%) | G Loss: -0.141964 | C Loss: -0.004346\n",
            "Epoch: 5 | Batch: 1280/100728 (1%) | G Loss: -0.141096 | C Loss: -0.006299\n",
            "Epoch: 5 | Batch: 2560/100728 (3%) | G Loss: -0.139051 | C Loss: -0.006142\n",
            "Epoch: 5 | Batch: 3840/100728 (4%) | G Loss: -0.138865 | C Loss: -0.008254\n",
            "Epoch: 5 | Batch: 5120/100728 (5%) | G Loss: -0.137090 | C Loss: -0.003941\n",
            "Epoch: 5 | Batch: 6400/100728 (6%) | G Loss: -0.133482 | C Loss: -0.002202\n",
            "Epoch: 5 | Batch: 7680/100728 (8%) | G Loss: -0.134334 | C Loss: -0.005739\n",
            "Epoch: 5 | Batch: 8960/100728 (9%) | G Loss: -0.130849 | C Loss: -0.013495\n",
            "Epoch: 5 | Batch: 10240/100728 (10%) | G Loss: -0.127458 | C Loss: -0.014922\n",
            "Epoch: 5 | Batch: 11520/100728 (11%) | G Loss: -0.124794 | C Loss: -0.015367\n",
            "Epoch: 5 | Batch: 12800/100728 (13%) | G Loss: -0.121136 | C Loss: -0.014944\n",
            "Epoch: 5 | Batch: 14080/100728 (14%) | G Loss: -0.120246 | C Loss: -0.017424\n",
            "Epoch: 5 | Batch: 15360/100728 (15%) | G Loss: -0.116810 | C Loss: -0.019998\n",
            "Epoch: 5 | Batch: 16640/100728 (17%) | G Loss: -0.115970 | C Loss: -0.022765\n",
            "Epoch: 5 | Batch: 17920/100728 (18%) | G Loss: -0.114903 | C Loss: -0.026929\n",
            "Epoch: 5 | Batch: 19200/100728 (19%) | G Loss: -0.114013 | C Loss: -0.028716\n",
            "Epoch: 5 | Batch: 20480/100728 (20%) | G Loss: -0.113298 | C Loss: -0.029070\n",
            "Epoch: 5 | Batch: 21760/100728 (22%) | G Loss: -0.114265 | C Loss: -0.025463\n",
            "Epoch: 5 | Batch: 23040/100728 (23%) | G Loss: -0.115651 | C Loss: -0.029146\n",
            "Epoch: 5 | Batch: 24320/100728 (24%) | G Loss: -0.116347 | C Loss: -0.027255\n",
            "Epoch: 5 | Batch: 25600/100728 (25%) | G Loss: -0.116860 | C Loss: -0.028846\n",
            "Epoch: 5 | Batch: 26880/100728 (27%) | G Loss: -0.118213 | C Loss: -0.028392\n",
            "Epoch: 5 | Batch: 28160/100728 (28%) | G Loss: -0.120330 | C Loss: -0.028946\n",
            "Epoch: 5 | Batch: 29440/100728 (29%) | G Loss: -0.121748 | C Loss: -0.024750\n",
            "Epoch: 5 | Batch: 30720/100728 (30%) | G Loss: -0.123423 | C Loss: -0.025218\n",
            "Epoch: 5 | Batch: 32000/100728 (32%) | G Loss: -0.125429 | C Loss: -0.023285\n",
            "Epoch: 5 | Batch: 33280/100728 (33%) | G Loss: -0.130366 | C Loss: -0.019559\n",
            "Epoch: 5 | Batch: 34560/100728 (34%) | G Loss: -0.131520 | C Loss: -0.019769\n",
            "Epoch: 5 | Batch: 35840/100728 (36%) | G Loss: -0.133807 | C Loss: -0.019707\n",
            "Epoch: 5 | Batch: 37120/100728 (37%) | G Loss: -0.135981 | C Loss: -0.015283\n",
            "Epoch: 5 | Batch: 38400/100728 (38%) | G Loss: -0.138233 | C Loss: -0.016758\n",
            "Epoch: 5 | Batch: 39680/100728 (39%) | G Loss: -0.139025 | C Loss: -0.014580\n",
            "Epoch: 5 | Batch: 40960/100728 (41%) | G Loss: -0.139536 | C Loss: -0.017735\n",
            "Epoch: 5 | Batch: 42240/100728 (42%) | G Loss: -0.140074 | C Loss: -0.014434\n",
            "Epoch: 5 | Batch: 43520/100728 (43%) | G Loss: -0.140870 | C Loss: -0.011762\n",
            "Epoch: 5 | Batch: 44800/100728 (44%) | G Loss: -0.140660 | C Loss: -0.010023\n",
            "Epoch: 5 | Batch: 46080/100728 (46%) | G Loss: -0.142875 | C Loss: -0.011709\n",
            "Epoch: 5 | Batch: 47360/100728 (47%) | G Loss: -0.142972 | C Loss: -0.011856\n",
            "Epoch: 5 | Batch: 48640/100728 (48%) | G Loss: -0.141439 | C Loss: -0.010325\n",
            "Epoch: 5 | Batch: 49920/100728 (50%) | G Loss: -0.143647 | C Loss: -0.010126\n",
            "Epoch: 5 | Batch: 51200/100728 (51%) | G Loss: -0.143839 | C Loss: -0.009834\n",
            "Epoch: 5 | Batch: 52480/100728 (52%) | G Loss: -0.142296 | C Loss: -0.011840\n",
            "Epoch: 5 | Batch: 53760/100728 (53%) | G Loss: -0.142296 | C Loss: -0.007870\n",
            "Epoch: 5 | Batch: 55040/100728 (55%) | G Loss: -0.141627 | C Loss: -0.009432\n",
            "Epoch: 5 | Batch: 56320/100728 (56%) | G Loss: -0.141128 | C Loss: -0.001201\n",
            "Epoch: 5 | Batch: 57600/100728 (57%) | G Loss: -0.141089 | C Loss: -0.004790\n",
            "Epoch: 5 | Batch: 58880/100728 (58%) | G Loss: -0.140879 | C Loss: -0.007605\n",
            "Epoch: 5 | Batch: 60160/100728 (60%) | G Loss: -0.138083 | C Loss: -0.014398\n",
            "Epoch: 5 | Batch: 61440/100728 (61%) | G Loss: -0.136031 | C Loss: -0.006158\n",
            "Epoch: 5 | Batch: 62720/100728 (62%) | G Loss: -0.132058 | C Loss: -0.017287\n",
            "Epoch: 5 | Batch: 64000/100728 (64%) | G Loss: -0.132161 | C Loss: -0.012982\n",
            "Epoch: 5 | Batch: 65280/100728 (65%) | G Loss: -0.127203 | C Loss: -0.017214\n",
            "Epoch: 5 | Batch: 66560/100728 (66%) | G Loss: -0.127141 | C Loss: -0.015225\n",
            "Epoch: 5 | Batch: 67840/100728 (67%) | G Loss: -0.124509 | C Loss: -0.015048\n",
            "Epoch: 5 | Batch: 69120/100728 (69%) | G Loss: -0.120795 | C Loss: -0.020095\n",
            "Epoch: 5 | Batch: 70400/100728 (70%) | G Loss: -0.119223 | C Loss: -0.016684\n",
            "Epoch: 5 | Batch: 71680/100728 (71%) | G Loss: -0.117239 | C Loss: -0.026386\n",
            "Epoch: 5 | Batch: 72960/100728 (72%) | G Loss: -0.114980 | C Loss: -0.025114\n",
            "Epoch: 5 | Batch: 74240/100728 (74%) | G Loss: -0.114757 | C Loss: -0.027000\n",
            "Epoch: 5 | Batch: 75520/100728 (75%) | G Loss: -0.113502 | C Loss: -0.025754\n",
            "Epoch: 5 | Batch: 76800/100728 (76%) | G Loss: -0.113950 | C Loss: -0.026994\n",
            "Epoch: 5 | Batch: 78080/100728 (78%) | G Loss: -0.115093 | C Loss: -0.024424\n",
            "Epoch: 5 | Batch: 79360/100728 (79%) | G Loss: -0.116362 | C Loss: -0.023639\n",
            "Epoch: 5 | Batch: 80640/100728 (80%) | G Loss: -0.118134 | C Loss: -0.028489\n",
            "Epoch: 5 | Batch: 81920/100728 (81%) | G Loss: -0.117908 | C Loss: -0.026197\n",
            "Epoch: 5 | Batch: 83200/100728 (83%) | G Loss: -0.119922 | C Loss: -0.026155\n",
            "Epoch: 5 | Batch: 84480/100728 (84%) | G Loss: -0.123225 | C Loss: -0.022384\n",
            "Epoch: 5 | Batch: 85760/100728 (85%) | G Loss: -0.124047 | C Loss: -0.023677\n",
            "Epoch: 5 | Batch: 87040/100728 (86%) | G Loss: -0.126689 | C Loss: -0.022062\n",
            "Epoch: 5 | Batch: 88320/100728 (88%) | G Loss: -0.128749 | C Loss: -0.021753\n",
            "Epoch: 5 | Batch: 89600/100728 (89%) | G Loss: -0.131452 | C Loss: -0.020440\n",
            "Epoch: 5 | Batch: 90880/100728 (90%) | G Loss: -0.132123 | C Loss: -0.017572\n",
            "Epoch: 5 | Batch: 92160/100728 (91%) | G Loss: -0.135570 | C Loss: -0.017091\n",
            "Epoch: 5 | Batch: 93440/100728 (93%) | G Loss: -0.135671 | C Loss: -0.012161\n",
            "Epoch: 5 | Batch: 94720/100728 (94%) | G Loss: -0.137006 | C Loss: -0.012036\n",
            "Epoch: 5 | Batch: 96000/100728 (95%) | G Loss: -0.139131 | C Loss: -0.011297\n",
            "Epoch: 5 | Batch: 97280/100728 (97%) | G Loss: -0.138707 | C Loss: -0.011453\n",
            "Epoch: 5 | Batch: 98560/100728 (98%) | G Loss: -0.140390 | C Loss: -0.005846\n",
            "Epoch: 5 | Batch: 99840/100728 (99%) | G Loss: -0.140825 | C Loss: -0.003835\n",
            "* (Train) Epoch: 5 | G Loss: -0.1294 | C Loss: -0.0162\n",
            "* Saved\n",
            " herself do she ' ll never offer herself on his wife she wasn ' t double double double double ?\n",
            " nurse the cher font font never get so many hin games ? he had to be from chief .\n",
            " trump who is puzzle here puzzle puzzle puzzle puzzle puzzle puzzle puzzle puzzle puzzle puzzle puzzle . it .\n",
            " bmw mayor on deja paw on the christmas i ' ll get my neighbor i ' ll you ' ll my neighbor xd\n",
            " finally named after last last night last last night after the last season last night last night last night last night last night\n",
            " you an bumper so that i deleted you mustache tickets ?\n",
            " honey do i do for her she is always her ' she\n",
            " i harry potter endgame my babies never replaces that sounds like and i never get them\n",
            " the russian letter the so have youggg fg .\n",
            " last last last last last last last last last last will never last again .\n",
            "\n",
            "Epoch: 6 | Batch: 0/100728 (0%) | G Loss: -0.138506 | C Loss: -0.005066\n",
            "Epoch: 6 | Batch: 1280/100728 (1%) | G Loss: -0.135835 | C Loss: -0.006119\n",
            "Epoch: 6 | Batch: 2560/100728 (3%) | G Loss: -0.133974 | C Loss: -0.000781\n",
            "Epoch: 6 | Batch: 3840/100728 (4%) | G Loss: -0.131584 | C Loss: -0.009242\n",
            "Epoch: 6 | Batch: 5120/100728 (5%) | G Loss: -0.130844 | C Loss: -0.006925\n",
            "Epoch: 6 | Batch: 6400/100728 (6%) | G Loss: -0.128183 | C Loss: -0.009866\n",
            "Epoch: 6 | Batch: 7680/100728 (8%) | G Loss: -0.122305 | C Loss: -0.012918\n",
            "Epoch: 6 | Batch: 8960/100728 (9%) | G Loss: -0.118698 | C Loss: -0.018654\n",
            "Epoch: 6 | Batch: 10240/100728 (10%) | G Loss: -0.116243 | C Loss: -0.017852\n",
            "Epoch: 6 | Batch: 11520/100728 (11%) | G Loss: -0.114433 | C Loss: -0.025972\n",
            "Epoch: 6 | Batch: 12800/100728 (13%) | G Loss: -0.115438 | C Loss: -0.027677\n",
            "Epoch: 6 | Batch: 14080/100728 (14%) | G Loss: -0.115859 | C Loss: -0.028974\n",
            "Epoch: 6 | Batch: 15360/100728 (15%) | G Loss: -0.116883 | C Loss: -0.030054\n",
            "Epoch: 6 | Batch: 16640/100728 (17%) | G Loss: -0.119037 | C Loss: -0.028581\n",
            "Epoch: 6 | Batch: 17920/100728 (18%) | G Loss: -0.120948 | C Loss: -0.028769\n",
            "Epoch: 6 | Batch: 19200/100728 (19%) | G Loss: -0.126451 | C Loss: -0.026554\n",
            "Epoch: 6 | Batch: 20480/100728 (20%) | G Loss: -0.127049 | C Loss: -0.026572\n",
            "Epoch: 6 | Batch: 21760/100728 (22%) | G Loss: -0.130023 | C Loss: -0.024609\n",
            "Epoch: 6 | Batch: 23040/100728 (23%) | G Loss: -0.130442 | C Loss: -0.022780\n",
            "Epoch: 6 | Batch: 24320/100728 (24%) | G Loss: -0.130062 | C Loss: -0.021521\n",
            "Epoch: 6 | Batch: 25600/100728 (25%) | G Loss: -0.131646 | C Loss: -0.022422\n",
            "Epoch: 6 | Batch: 26880/100728 (27%) | G Loss: -0.132556 | C Loss: -0.022598\n",
            "Epoch: 6 | Batch: 28160/100728 (28%) | G Loss: -0.133486 | C Loss: -0.021345\n",
            "Epoch: 6 | Batch: 29440/100728 (29%) | G Loss: -0.134205 | C Loss: -0.019668\n",
            "Epoch: 6 | Batch: 30720/100728 (30%) | G Loss: -0.134727 | C Loss: -0.018653\n",
            "Epoch: 6 | Batch: 32000/100728 (32%) | G Loss: -0.136228 | C Loss: -0.017193\n",
            "Epoch: 6 | Batch: 33280/100728 (33%) | G Loss: -0.137989 | C Loss: -0.014709\n",
            "Epoch: 6 | Batch: 34560/100728 (34%) | G Loss: -0.139505 | C Loss: -0.013538\n",
            "Epoch: 6 | Batch: 35840/100728 (36%) | G Loss: -0.140303 | C Loss: -0.015068\n",
            "Epoch: 6 | Batch: 37120/100728 (37%) | G Loss: -0.142208 | C Loss: -0.010824\n",
            "Epoch: 6 | Batch: 38400/100728 (38%) | G Loss: -0.141665 | C Loss: -0.011086\n",
            "Epoch: 6 | Batch: 39680/100728 (39%) | G Loss: -0.143330 | C Loss: -0.010613\n",
            "Epoch: 6 | Batch: 40960/100728 (41%) | G Loss: -0.144777 | C Loss: -0.011969\n",
            "Epoch: 6 | Batch: 42240/100728 (42%) | G Loss: -0.146514 | C Loss: -0.009517\n",
            "Epoch: 6 | Batch: 43520/100728 (43%) | G Loss: -0.146192 | C Loss: -0.007587\n",
            "Epoch: 6 | Batch: 44800/100728 (44%) | G Loss: -0.148284 | C Loss: -0.007420\n",
            "Epoch: 6 | Batch: 46080/100728 (46%) | G Loss: -0.147040 | C Loss: -0.008238\n",
            "Epoch: 6 | Batch: 47360/100728 (47%) | G Loss: -0.147077 | C Loss: -0.004238\n",
            "Epoch: 6 | Batch: 48640/100728 (48%) | G Loss: -0.145094 | C Loss: -0.004798\n",
            "Epoch: 6 | Batch: 49920/100728 (50%) | G Loss: -0.143442 | C Loss: -0.008187\n",
            "Epoch: 6 | Batch: 51200/100728 (51%) | G Loss: -0.140081 | C Loss: -0.004624\n",
            "Epoch: 6 | Batch: 52480/100728 (52%) | G Loss: -0.138776 | C Loss: -0.007522\n",
            "Epoch: 6 | Batch: 53760/100728 (53%) | G Loss: -0.136420 | C Loss: -0.013188\n",
            "Epoch: 6 | Batch: 55040/100728 (55%) | G Loss: -0.131993 | C Loss: -0.013841\n",
            "Epoch: 6 | Batch: 56320/100728 (56%) | G Loss: -0.126584 | C Loss: -0.016983\n",
            "Epoch: 6 | Batch: 57600/100728 (57%) | G Loss: -0.126059 | C Loss: -0.019890\n",
            "Epoch: 6 | Batch: 58880/100728 (58%) | G Loss: -0.126133 | C Loss: -0.020287\n",
            "Epoch: 6 | Batch: 60160/100728 (60%) | G Loss: -0.121524 | C Loss: -0.025257\n",
            "Epoch: 6 | Batch: 61440/100728 (61%) | G Loss: -0.120381 | C Loss: -0.017042\n",
            "Epoch: 6 | Batch: 62720/100728 (62%) | G Loss: -0.120391 | C Loss: -0.025222\n",
            "Epoch: 6 | Batch: 64000/100728 (64%) | G Loss: -0.120799 | C Loss: -0.024037\n",
            "Epoch: 6 | Batch: 65280/100728 (65%) | G Loss: -0.122173 | C Loss: -0.027300\n",
            "Epoch: 6 | Batch: 66560/100728 (66%) | G Loss: -0.123593 | C Loss: -0.027163\n",
            "Epoch: 6 | Batch: 67840/100728 (67%) | G Loss: -0.122812 | C Loss: -0.025285\n",
            "Epoch: 6 | Batch: 69120/100728 (69%) | G Loss: -0.123094 | C Loss: -0.021105\n",
            "Epoch: 6 | Batch: 70400/100728 (70%) | G Loss: -0.123047 | C Loss: -0.021438\n",
            "Epoch: 6 | Batch: 71680/100728 (71%) | G Loss: -0.124283 | C Loss: -0.020502\n",
            "Epoch: 6 | Batch: 72960/100728 (72%) | G Loss: -0.124022 | C Loss: -0.019306\n",
            "Epoch: 6 | Batch: 74240/100728 (74%) | G Loss: -0.125952 | C Loss: -0.019775\n",
            "Epoch: 6 | Batch: 75520/100728 (75%) | G Loss: -0.127749 | C Loss: -0.018476\n",
            "Epoch: 6 | Batch: 76800/100728 (76%) | G Loss: -0.128307 | C Loss: -0.016674\n",
            "Epoch: 6 | Batch: 78080/100728 (78%) | G Loss: -0.127848 | C Loss: -0.016799\n",
            "Epoch: 6 | Batch: 79360/100728 (79%) | G Loss: -0.128034 | C Loss: -0.017111\n",
            "Epoch: 6 | Batch: 80640/100728 (80%) | G Loss: -0.129685 | C Loss: -0.015471\n",
            "Epoch: 6 | Batch: 81920/100728 (81%) | G Loss: -0.129373 | C Loss: -0.012924\n",
            "Epoch: 6 | Batch: 83200/100728 (83%) | G Loss: -0.132116 | C Loss: -0.017398\n",
            "Epoch: 6 | Batch: 84480/100728 (84%) | G Loss: -0.130642 | C Loss: -0.013923\n",
            "Epoch: 6 | Batch: 85760/100728 (85%) | G Loss: -0.129340 | C Loss: -0.014360\n",
            "Epoch: 6 | Batch: 87040/100728 (86%) | G Loss: -0.129450 | C Loss: -0.014214\n",
            "Epoch: 6 | Batch: 88320/100728 (88%) | G Loss: -0.133852 | C Loss: -0.006168\n",
            "Epoch: 6 | Batch: 89600/100728 (89%) | G Loss: -0.134125 | C Loss: -0.011923\n",
            "Epoch: 6 | Batch: 90880/100728 (90%) | G Loss: -0.135164 | C Loss: -0.009161\n",
            "Epoch: 6 | Batch: 92160/100728 (91%) | G Loss: -0.134873 | C Loss: -0.005767\n",
            "Epoch: 6 | Batch: 93440/100728 (93%) | G Loss: -0.134629 | C Loss: -0.011436\n",
            "Epoch: 6 | Batch: 94720/100728 (94%) | G Loss: -0.135345 | C Loss: -0.012047\n",
            "Epoch: 6 | Batch: 96000/100728 (95%) | G Loss: -0.134634 | C Loss: -0.008884\n",
            "Epoch: 6 | Batch: 97280/100728 (97%) | G Loss: -0.136043 | C Loss: -0.011222\n",
            "Epoch: 6 | Batch: 98560/100728 (98%) | G Loss: -0.133618 | C Loss: -0.009744\n",
            "Epoch: 6 | Batch: 99840/100728 (99%) | G Loss: -0.134113 | C Loss: -0.009567\n",
            "* (Train) Epoch: 6 | G Loss: -0.1311 | C Loss: -0.0148\n",
            "* Saved\n",
            " one needs so one needs one needs . and have one liner . a tend . . . .\n",
            " my abusive birthday the third taste recently . to swallow . because as a year to swallow her year .\n",
            " koala demons delicious them up them recently to them to them to them up to them . them .\n",
            " being just super glue or 28 simple trick or as they as other isn ' t yours ?\n",
            " in the . without the duct . without . . . . .\n",
            " a snow inrate ? snow jersey . or snow .\n",
            " is to to to to a bald relative to the bald behavior to to have to six .\n",
            " some wet black black black black black black black black black black black black black black black black . black . . .\n",
            " x and have three gears twice and you play twice as you . . .\n",
            " ' clam unlicers uses unlicers after anyone uses .\n",
            "\n",
            "Epoch: 7 | Batch: 0/100728 (0%) | G Loss: -0.132017 | C Loss: -0.008145\n",
            "Epoch: 7 | Batch: 1280/100728 (1%) | G Loss: -0.133725 | C Loss: -0.009354\n",
            "Epoch: 7 | Batch: 2560/100728 (3%) | G Loss: -0.129997 | C Loss: -0.009620\n",
            "Epoch: 7 | Batch: 3840/100728 (4%) | G Loss: -0.128382 | C Loss: -0.011362\n",
            "Epoch: 7 | Batch: 5120/100728 (5%) | G Loss: -0.126384 | C Loss: -0.011784\n",
            "Epoch: 7 | Batch: 6400/100728 (6%) | G Loss: -0.124595 | C Loss: -0.012341\n",
            "Epoch: 7 | Batch: 7680/100728 (8%) | G Loss: -0.125448 | C Loss: -0.011159\n",
            "Epoch: 7 | Batch: 8960/100728 (9%) | G Loss: -0.123000 | C Loss: -0.016684\n",
            "Epoch: 7 | Batch: 10240/100728 (10%) | G Loss: -0.124161 | C Loss: -0.018118\n",
            "Epoch: 7 | Batch: 11520/100728 (11%) | G Loss: -0.124867 | C Loss: -0.018841\n",
            "Epoch: 7 | Batch: 12800/100728 (13%) | G Loss: -0.124523 | C Loss: -0.018520\n",
            "Epoch: 7 | Batch: 14080/100728 (14%) | G Loss: -0.125530 | C Loss: -0.020908\n",
            "Epoch: 7 | Batch: 15360/100728 (15%) | G Loss: -0.128937 | C Loss: -0.017386\n",
            "Epoch: 7 | Batch: 16640/100728 (17%) | G Loss: -0.129540 | C Loss: -0.018179\n",
            "Epoch: 7 | Batch: 17920/100728 (18%) | G Loss: -0.131923 | C Loss: -0.020401\n",
            "Epoch: 7 | Batch: 19200/100728 (19%) | G Loss: -0.134685 | C Loss: -0.019440\n",
            "Epoch: 7 | Batch: 20480/100728 (20%) | G Loss: -0.135924 | C Loss: -0.016821\n",
            "Epoch: 7 | Batch: 21760/100728 (22%) | G Loss: -0.136343 | C Loss: -0.017171\n",
            "Epoch: 7 | Batch: 23040/100728 (23%) | G Loss: -0.135648 | C Loss: -0.016638\n",
            "Epoch: 7 | Batch: 24320/100728 (24%) | G Loss: -0.135587 | C Loss: -0.015346\n",
            "Epoch: 7 | Batch: 25600/100728 (25%) | G Loss: -0.135848 | C Loss: -0.016209\n",
            "Epoch: 7 | Batch: 26880/100728 (27%) | G Loss: -0.134536 | C Loss: -0.010630\n",
            "Epoch: 7 | Batch: 28160/100728 (28%) | G Loss: -0.131506 | C Loss: -0.014091\n",
            "Epoch: 7 | Batch: 29440/100728 (29%) | G Loss: -0.129958 | C Loss: -0.011101\n",
            "Epoch: 7 | Batch: 30720/100728 (30%) | G Loss: -0.130066 | C Loss: 0.001192\n",
            "Epoch: 7 | Batch: 32000/100728 (32%) | G Loss: -0.126904 | C Loss: -0.012179\n",
            "Epoch: 7 | Batch: 33280/100728 (33%) | G Loss: -0.123667 | C Loss: -0.012124\n",
            "Epoch: 7 | Batch: 34560/100728 (34%) | G Loss: -0.122090 | C Loss: -0.014768\n",
            "Epoch: 7 | Batch: 35840/100728 (36%) | G Loss: -0.120866 | C Loss: -0.011950\n",
            "Epoch: 7 | Batch: 37120/100728 (37%) | G Loss: -0.121055 | C Loss: -0.016017\n",
            "Epoch: 7 | Batch: 38400/100728 (38%) | G Loss: -0.118192 | C Loss: -0.017431\n",
            "Epoch: 7 | Batch: 39680/100728 (39%) | G Loss: -0.119282 | C Loss: -0.011457\n",
            "Epoch: 7 | Batch: 40960/100728 (41%) | G Loss: -0.119649 | C Loss: -0.013995\n",
            "Epoch: 7 | Batch: 42240/100728 (42%) | G Loss: -0.121688 | C Loss: -0.014097\n",
            "Epoch: 7 | Batch: 43520/100728 (43%) | G Loss: -0.125153 | C Loss: -0.010190\n",
            "Epoch: 7 | Batch: 44800/100728 (44%) | G Loss: -0.127247 | C Loss: -0.008341\n",
            "Epoch: 7 | Batch: 46080/100728 (46%) | G Loss: -0.131303 | C Loss: -0.009889\n",
            "Epoch: 7 | Batch: 47360/100728 (47%) | G Loss: -0.131716 | C Loss: -0.012097\n",
            "Epoch: 7 | Batch: 48640/100728 (48%) | G Loss: -0.136308 | C Loss: -0.005852\n",
            "Epoch: 7 | Batch: 49920/100728 (50%) | G Loss: -0.137319 | C Loss: -0.011682\n",
            "Epoch: 7 | Batch: 51200/100728 (51%) | G Loss: -0.136919 | C Loss: -0.011569\n",
            "Epoch: 7 | Batch: 52480/100728 (52%) | G Loss: -0.137802 | C Loss: -0.013319\n",
            "Epoch: 7 | Batch: 53760/100728 (53%) | G Loss: -0.138490 | C Loss: -0.013797\n",
            "Epoch: 7 | Batch: 55040/100728 (55%) | G Loss: -0.138622 | C Loss: -0.012141\n",
            "Epoch: 7 | Batch: 56320/100728 (56%) | G Loss: -0.138644 | C Loss: -0.011306\n",
            "Epoch: 7 | Batch: 57600/100728 (57%) | G Loss: -0.138006 | C Loss: -0.015378\n",
            "Epoch: 7 | Batch: 58880/100728 (58%) | G Loss: -0.136295 | C Loss: -0.012145\n",
            "Epoch: 7 | Batch: 60160/100728 (60%) | G Loss: -0.137229 | C Loss: -0.017364\n",
            "Epoch: 7 | Batch: 61440/100728 (61%) | G Loss: -0.134371 | C Loss: -0.015422\n",
            "Epoch: 7 | Batch: 62720/100728 (62%) | G Loss: -0.132702 | C Loss: -0.017089\n",
            "Epoch: 7 | Batch: 64000/100728 (64%) | G Loss: -0.130604 | C Loss: -0.016106\n",
            "Epoch: 7 | Batch: 65280/100728 (65%) | G Loss: -0.128931 | C Loss: -0.014589\n",
            "Epoch: 7 | Batch: 66560/100728 (66%) | G Loss: -0.129367 | C Loss: -0.017942\n",
            "Epoch: 7 | Batch: 67840/100728 (67%) | G Loss: -0.129090 | C Loss: -0.017641\n",
            "Epoch: 7 | Batch: 69120/100728 (69%) | G Loss: -0.127008 | C Loss: -0.017402\n",
            "Epoch: 7 | Batch: 70400/100728 (70%) | G Loss: -0.126257 | C Loss: -0.019816\n",
            "Epoch: 7 | Batch: 71680/100728 (71%) | G Loss: -0.124206 | C Loss: -0.017065\n",
            "Epoch: 7 | Batch: 72960/100728 (72%) | G Loss: -0.122869 | C Loss: -0.017186\n",
            "Epoch: 7 | Batch: 74240/100728 (74%) | G Loss: -0.121449 | C Loss: -0.015747\n",
            "Epoch: 7 | Batch: 75520/100728 (75%) | G Loss: -0.122754 | C Loss: -0.013873\n",
            "Epoch: 7 | Batch: 76800/100728 (76%) | G Loss: -0.122394 | C Loss: -0.012568\n",
            "Epoch: 7 | Batch: 78080/100728 (78%) | G Loss: -0.120182 | C Loss: -0.018246\n",
            "Epoch: 7 | Batch: 79360/100728 (79%) | G Loss: -0.119384 | C Loss: -0.016912\n",
            "Epoch: 7 | Batch: 80640/100728 (80%) | G Loss: -0.121395 | C Loss: -0.013253\n",
            "Epoch: 7 | Batch: 81920/100728 (81%) | G Loss: -0.118226 | C Loss: -0.013972\n",
            "Epoch: 7 | Batch: 83200/100728 (83%) | G Loss: -0.118278 | C Loss: -0.015322\n",
            "Epoch: 7 | Batch: 84480/100728 (84%) | G Loss: -0.116931 | C Loss: -0.010835\n",
            "Epoch: 7 | Batch: 85760/100728 (85%) | G Loss: -0.116090 | C Loss: -0.009567\n",
            "Epoch: 7 | Batch: 87040/100728 (86%) | G Loss: -0.114728 | C Loss: -0.011692\n",
            "Epoch: 7 | Batch: 88320/100728 (88%) | G Loss: -0.114988 | C Loss: -0.011807\n",
            "Epoch: 7 | Batch: 89600/100728 (89%) | G Loss: -0.114566 | C Loss: -0.010940\n",
            "Epoch: 7 | Batch: 90880/100728 (90%) | G Loss: -0.113840 | C Loss: -0.012213\n",
            "Epoch: 7 | Batch: 92160/100728 (91%) | G Loss: -0.113080 | C Loss: -0.012102\n",
            "Epoch: 7 | Batch: 93440/100728 (93%) | G Loss: -0.115540 | C Loss: -0.010981\n",
            "Epoch: 7 | Batch: 94720/100728 (94%) | G Loss: -0.114072 | C Loss: -0.005301\n",
            "Epoch: 7 | Batch: 96000/100728 (95%) | G Loss: -0.113394 | C Loss: -0.007479\n",
            "Epoch: 7 | Batch: 97280/100728 (97%) | G Loss: -0.117682 | C Loss: -0.010340\n",
            "Epoch: 7 | Batch: 98560/100728 (98%) | G Loss: -0.116924 | C Loss: -0.011053\n",
            "Epoch: 7 | Batch: 99840/100728 (99%) | G Loss: -0.117197 | C Loss: -0.008041\n",
            "* (Train) Epoch: 7 | G Loss: -0.1264 | C Loss: -0.0129\n",
            " essay what of a switchels the poets have a sprinkle ? tyrannosaurus proper ar ar ar\n",
            " african masseuse did the masseuse ? he couldn ' t get his right handed on his house he hates him\n",
            " what do the polar bears have their vanss on on them on them ? on on paper on them .\n",
            " the neighbor his neighbor xd mentalbloels in the mental mate\n",
            " de deters have up to sai with the alter ones ?\n",
            " what on dry ramsay shouldn ' t have creative dreams on a ceiling\n",
            "ual i freeze mints the other tits without titsbees titsual titsual tits titss tits tits tits\n",
            " bartender joke why did the sponge ? i don ' t get myself out of the closet feeling oh wait , feeling feeling feeling out of himself\n",
            " what did there have recently been from a giant co worker from in the co worker they both have to have in panic\n",
            " narcissistic have one butt cheek ? the one 0 one vitamin\n",
            "\n",
            "Epoch: 8 | Batch: 0/100728 (0%) | G Loss: -0.119966 | C Loss: -0.013226\n",
            "Epoch: 8 | Batch: 1280/100728 (1%) | G Loss: -0.123384 | C Loss: -0.011797\n",
            "Epoch: 8 | Batch: 2560/100728 (3%) | G Loss: -0.126746 | C Loss: -0.012629\n",
            "Epoch: 8 | Batch: 3840/100728 (4%) | G Loss: -0.129684 | C Loss: -0.014188\n",
            "Epoch: 8 | Batch: 5120/100728 (5%) | G Loss: -0.131840 | C Loss: -0.014591\n",
            "Epoch: 8 | Batch: 6400/100728 (6%) | G Loss: -0.135034 | C Loss: -0.013350\n",
            "Epoch: 8 | Batch: 7680/100728 (8%) | G Loss: -0.136099 | C Loss: -0.018115\n",
            "Epoch: 8 | Batch: 8960/100728 (9%) | G Loss: -0.136435 | C Loss: -0.017594\n",
            "Epoch: 8 | Batch: 10240/100728 (10%) | G Loss: -0.136295 | C Loss: -0.012539\n",
            "Epoch: 8 | Batch: 11520/100728 (11%) | G Loss: -0.136945 | C Loss: -0.010880\n",
            "Epoch: 8 | Batch: 12800/100728 (13%) | G Loss: -0.136017 | C Loss: -0.019999\n",
            "Epoch: 8 | Batch: 14080/100728 (14%) | G Loss: -0.136756 | C Loss: -0.019742\n",
            "Epoch: 8 | Batch: 15360/100728 (15%) | G Loss: -0.137174 | C Loss: -0.018079\n",
            "Epoch: 8 | Batch: 16640/100728 (17%) | G Loss: -0.137250 | C Loss: -0.022431\n",
            "Epoch: 8 | Batch: 17920/100728 (18%) | G Loss: -0.137114 | C Loss: -0.019445\n",
            "Epoch: 8 | Batch: 19200/100728 (19%) | G Loss: -0.136041 | C Loss: -0.018632\n",
            "Epoch: 8 | Batch: 20480/100728 (20%) | G Loss: -0.136453 | C Loss: -0.019987\n",
            "Epoch: 8 | Batch: 21760/100728 (22%) | G Loss: -0.134846 | C Loss: -0.011569\n",
            "Epoch: 8 | Batch: 23040/100728 (23%) | G Loss: -0.134582 | C Loss: -0.015058\n",
            "Epoch: 8 | Batch: 24320/100728 (24%) | G Loss: -0.131800 | C Loss: -0.011459\n",
            "Epoch: 8 | Batch: 25600/100728 (25%) | G Loss: -0.129063 | C Loss: -0.010312\n",
            "Epoch: 8 | Batch: 26880/100728 (27%) | G Loss: -0.130869 | C Loss: -0.007725\n",
            "Epoch: 8 | Batch: 28160/100728 (28%) | G Loss: -0.127704 | C Loss: -0.011526\n",
            "Epoch: 8 | Batch: 29440/100728 (29%) | G Loss: -0.127070 | C Loss: -0.011877\n",
            "Epoch: 8 | Batch: 30720/100728 (30%) | G Loss: -0.126306 | C Loss: -0.006642\n",
            "Epoch: 8 | Batch: 32000/100728 (32%) | G Loss: -0.122769 | C Loss: 0.002415\n",
            "Epoch: 8 | Batch: 33280/100728 (33%) | G Loss: -0.119562 | C Loss: -0.008863\n",
            "Epoch: 8 | Batch: 34560/100728 (34%) | G Loss: -0.117720 | C Loss: -0.006031\n",
            "Epoch: 8 | Batch: 35840/100728 (36%) | G Loss: -0.116360 | C Loss: -0.006888\n",
            "Epoch: 8 | Batch: 37120/100728 (37%) | G Loss: -0.114508 | C Loss: -0.008208\n",
            "Epoch: 8 | Batch: 38400/100728 (38%) | G Loss: -0.115126 | C Loss: -0.006468\n",
            "Epoch: 8 | Batch: 39680/100728 (39%) | G Loss: -0.113379 | C Loss: 0.000107\n",
            "Epoch: 8 | Batch: 40960/100728 (41%) | G Loss: -0.112247 | C Loss: -0.005161\n",
            "Epoch: 8 | Batch: 42240/100728 (42%) | G Loss: -0.111848 | C Loss: -0.008907\n",
            "Epoch: 8 | Batch: 43520/100728 (43%) | G Loss: -0.110986 | C Loss: -0.010759\n",
            "Epoch: 8 | Batch: 44800/100728 (44%) | G Loss: -0.109129 | C Loss: -0.009129\n",
            "Epoch: 8 | Batch: 46080/100728 (46%) | G Loss: -0.113126 | C Loss: -0.014316\n",
            "Epoch: 8 | Batch: 47360/100728 (47%) | G Loss: -0.115329 | C Loss: -0.014583\n",
            "Epoch: 8 | Batch: 48640/100728 (48%) | G Loss: -0.118185 | C Loss: -0.012822\n",
            "Epoch: 8 | Batch: 49920/100728 (50%) | G Loss: -0.120431 | C Loss: -0.014432\n",
            "Epoch: 8 | Batch: 51200/100728 (51%) | G Loss: -0.123592 | C Loss: -0.014519\n",
            "Epoch: 8 | Batch: 52480/100728 (52%) | G Loss: -0.124747 | C Loss: -0.014729\n",
            "Epoch: 8 | Batch: 53760/100728 (53%) | G Loss: -0.127604 | C Loss: -0.016254\n",
            "Epoch: 8 | Batch: 55040/100728 (55%) | G Loss: -0.125903 | C Loss: -0.018289\n",
            "Epoch: 8 | Batch: 56320/100728 (56%) | G Loss: -0.128286 | C Loss: -0.017825\n",
            "Epoch: 8 | Batch: 57600/100728 (57%) | G Loss: -0.127657 | C Loss: -0.013862\n",
            "Epoch: 8 | Batch: 58880/100728 (58%) | G Loss: -0.125046 | C Loss: -0.019111\n",
            "Epoch: 8 | Batch: 60160/100728 (60%) | G Loss: -0.124807 | C Loss: -0.016701\n",
            "Epoch: 8 | Batch: 61440/100728 (61%) | G Loss: -0.122301 | C Loss: -0.012704\n",
            "Epoch: 8 | Batch: 62720/100728 (62%) | G Loss: -0.122442 | C Loss: -0.019011\n",
            "Epoch: 8 | Batch: 64000/100728 (64%) | G Loss: -0.121959 | C Loss: -0.017933\n",
            "Epoch: 8 | Batch: 65280/100728 (65%) | G Loss: -0.122601 | C Loss: -0.018449\n",
            "Epoch: 8 | Batch: 66560/100728 (66%) | G Loss: -0.123052 | C Loss: -0.017374\n",
            "Epoch: 8 | Batch: 67840/100728 (67%) | G Loss: -0.120613 | C Loss: -0.015082\n",
            "Epoch: 8 | Batch: 69120/100728 (69%) | G Loss: -0.120298 | C Loss: -0.006721\n",
            "Epoch: 8 | Batch: 70400/100728 (70%) | G Loss: -0.116946 | C Loss: -0.011548\n",
            "Epoch: 8 | Batch: 71680/100728 (71%) | G Loss: -0.117319 | C Loss: -0.015126\n",
            "Epoch: 8 | Batch: 72960/100728 (72%) | G Loss: -0.114589 | C Loss: -0.011394\n",
            "Epoch: 8 | Batch: 74240/100728 (74%) | G Loss: -0.111419 | C Loss: -0.011571\n",
            "Epoch: 8 | Batch: 75520/100728 (75%) | G Loss: -0.107862 | C Loss: -0.013382\n",
            "Epoch: 8 | Batch: 76800/100728 (76%) | G Loss: -0.104093 | C Loss: -0.013089\n",
            "Epoch: 8 | Batch: 78080/100728 (78%) | G Loss: -0.105297 | C Loss: -0.011410\n",
            "Epoch: 8 | Batch: 79360/100728 (79%) | G Loss: -0.104425 | C Loss: -0.011743\n",
            "Epoch: 8 | Batch: 80640/100728 (80%) | G Loss: -0.101137 | C Loss: -0.015059\n",
            "Epoch: 8 | Batch: 81920/100728 (81%) | G Loss: -0.106091 | C Loss: -0.010250\n",
            "Epoch: 8 | Batch: 83200/100728 (83%) | G Loss: -0.109409 | C Loss: -0.010771\n",
            "Epoch: 8 | Batch: 84480/100728 (84%) | G Loss: -0.108741 | C Loss: -0.013036\n",
            "Epoch: 8 | Batch: 85760/100728 (85%) | G Loss: -0.110958 | C Loss: -0.002568\n",
            "Epoch: 8 | Batch: 87040/100728 (86%) | G Loss: -0.108955 | C Loss: -0.010841\n",
            "Epoch: 8 | Batch: 88320/100728 (88%) | G Loss: -0.110751 | C Loss: -0.009304\n",
            "Epoch: 8 | Batch: 89600/100728 (89%) | G Loss: -0.108625 | C Loss: -0.009361\n",
            "Epoch: 8 | Batch: 90880/100728 (90%) | G Loss: -0.111776 | C Loss: 0.000513\n",
            "Epoch: 8 | Batch: 92160/100728 (91%) | G Loss: -0.113232 | C Loss: -0.008353\n",
            "Epoch: 8 | Batch: 93440/100728 (93%) | G Loss: -0.113550 | C Loss: -0.010328\n",
            "Epoch: 8 | Batch: 94720/100728 (94%) | G Loss: -0.112733 | C Loss: -0.011482\n",
            "Epoch: 8 | Batch: 96000/100728 (95%) | G Loss: -0.116008 | C Loss: -0.010346\n",
            "Epoch: 8 | Batch: 97280/100728 (97%) | G Loss: -0.115517 | C Loss: 0.000669\n",
            "Epoch: 8 | Batch: 98560/100728 (98%) | G Loss: -0.115297 | C Loss: -0.013936\n",
            "Epoch: 8 | Batch: 99840/100728 (99%) | G Loss: -0.118710 | C Loss: -0.014326\n",
            "* (Train) Epoch: 8 | G Loss: -0.1212 | C Loss: -0.0111\n",
            " to ex there to the you you have no . you don ' t to be there .\n",
            " want to bully . . . . . . . . like to get you .\n",
            " city . . . . . . . . . . . . have . . . . . .\n",
            " johnny epstein with an erectionish relationship with his neighbor luckily i ' m slowly charging him .\n",
            " i pho gonna have ever pho sexual assault pho pho pho pho pho pho pho phoction .\n",
            " wasn ' t . . . . . . . . . . . . . . . . . . .\n",
            " who constantly self self defense server so self . to really to get really self defense self frustrated . . . .\n",
            " my baby told me for the wheel chair have had me eyes ? me .\n",
            " chinese driver only said to driver . i thought to driver i ' m so many .\n",
            " epstein knocks without horny test pitt we wasn ' too inside it eventually folding inside straw badumgled\n",
            "\n",
            "Epoch: 9 | Batch: 0/100728 (0%) | G Loss: -0.121632 | C Loss: -0.011186\n",
            "Epoch: 9 | Batch: 1280/100728 (1%) | G Loss: -0.122980 | C Loss: -0.011749\n",
            "Epoch: 9 | Batch: 2560/100728 (3%) | G Loss: -0.126934 | C Loss: -0.015313\n",
            "Epoch: 9 | Batch: 3840/100728 (4%) | G Loss: -0.129124 | C Loss: -0.010898\n",
            "Epoch: 9 | Batch: 5120/100728 (5%) | G Loss: -0.131009 | C Loss: -0.004041\n",
            "Epoch: 9 | Batch: 6400/100728 (6%) | G Loss: -0.134949 | C Loss: -0.010326\n",
            "Epoch: 9 | Batch: 7680/100728 (8%) | G Loss: -0.135546 | C Loss: -0.013393\n",
            "Epoch: 9 | Batch: 8960/100728 (9%) | G Loss: -0.137268 | C Loss: -0.010386\n",
            "Epoch: 9 | Batch: 10240/100728 (10%) | G Loss: -0.136372 | C Loss: -0.012943\n",
            "Epoch: 9 | Batch: 11520/100728 (11%) | G Loss: -0.134953 | C Loss: -0.014911\n",
            "Epoch: 9 | Batch: 12800/100728 (13%) | G Loss: -0.131982 | C Loss: -0.013198\n",
            "Epoch: 9 | Batch: 14080/100728 (14%) | G Loss: -0.129591 | C Loss: -0.013487\n",
            "Epoch: 9 | Batch: 15360/100728 (15%) | G Loss: -0.125394 | C Loss: -0.017814\n",
            "Epoch: 9 | Batch: 16640/100728 (17%) | G Loss: -0.125424 | C Loss: -0.011150\n",
            "Epoch: 9 | Batch: 17920/100728 (18%) | G Loss: -0.124637 | C Loss: -0.018053\n",
            "Epoch: 9 | Batch: 19200/100728 (19%) | G Loss: -0.123638 | C Loss: -0.014599\n",
            "Epoch: 9 | Batch: 20480/100728 (20%) | G Loss: -0.124725 | C Loss: -0.016703\n",
            "Epoch: 9 | Batch: 21760/100728 (22%) | G Loss: -0.127035 | C Loss: -0.011938\n",
            "Epoch: 9 | Batch: 23040/100728 (23%) | G Loss: -0.125745 | C Loss: -0.012487\n",
            "Epoch: 9 | Batch: 24320/100728 (24%) | G Loss: -0.127804 | C Loss: -0.009566\n",
            "Epoch: 9 | Batch: 25600/100728 (25%) | G Loss: -0.129717 | C Loss: -0.009007\n",
            "Epoch: 9 | Batch: 26880/100728 (27%) | G Loss: -0.131164 | C Loss: -0.005833\n",
            "Epoch: 9 | Batch: 28160/100728 (28%) | G Loss: -0.128955 | C Loss: -0.005926\n",
            "Epoch: 9 | Batch: 29440/100728 (29%) | G Loss: -0.130135 | C Loss: -0.004393\n",
            "Epoch: 9 | Batch: 30720/100728 (30%) | G Loss: -0.129490 | C Loss: -0.004238\n",
            "Epoch: 9 | Batch: 32000/100728 (32%) | G Loss: -0.131691 | C Loss: -0.003202\n",
            "Epoch: 9 | Batch: 33280/100728 (33%) | G Loss: -0.132560 | C Loss: -0.004178\n",
            "Epoch: 9 | Batch: 34560/100728 (34%) | G Loss: -0.132399 | C Loss: -0.005056\n",
            "Epoch: 9 | Batch: 35840/100728 (36%) | G Loss: -0.130721 | C Loss: -0.004342\n",
            "Epoch: 9 | Batch: 37120/100728 (37%) | G Loss: -0.128817 | C Loss: -0.007503\n",
            "Epoch: 9 | Batch: 38400/100728 (38%) | G Loss: -0.124531 | C Loss: -0.007074\n",
            "Epoch: 9 | Batch: 39680/100728 (39%) | G Loss: -0.119548 | C Loss: -0.009901\n",
            "Epoch: 9 | Batch: 40960/100728 (41%) | G Loss: -0.114443 | C Loss: -0.012459\n",
            "Epoch: 9 | Batch: 42240/100728 (42%) | G Loss: -0.110760 | C Loss: -0.011155\n",
            "Epoch: 9 | Batch: 43520/100728 (43%) | G Loss: -0.107926 | C Loss: -0.014553\n",
            "Epoch: 9 | Batch: 44800/100728 (44%) | G Loss: -0.105906 | C Loss: -0.018786\n",
            "Epoch: 9 | Batch: 46080/100728 (46%) | G Loss: -0.105576 | C Loss: -0.021851\n",
            "Epoch: 9 | Batch: 47360/100728 (47%) | G Loss: -0.105573 | C Loss: -0.020470\n",
            "Epoch: 9 | Batch: 48640/100728 (48%) | G Loss: -0.104451 | C Loss: -0.019954\n",
            "Epoch: 9 | Batch: 49920/100728 (50%) | G Loss: -0.104100 | C Loss: -0.016080\n",
            "Epoch: 9 | Batch: 51200/100728 (51%) | G Loss: -0.105299 | C Loss: -0.020355\n",
            "Epoch: 9 | Batch: 52480/100728 (52%) | G Loss: -0.108971 | C Loss: -0.017820\n",
            "Epoch: 9 | Batch: 53760/100728 (53%) | G Loss: -0.107941 | C Loss: -0.018120\n",
            "Epoch: 9 | Batch: 55040/100728 (55%) | G Loss: -0.110013 | C Loss: -0.016162\n",
            "Epoch: 9 | Batch: 56320/100728 (56%) | G Loss: -0.111696 | C Loss: -0.014225\n",
            "Epoch: 9 | Batch: 57600/100728 (57%) | G Loss: -0.114929 | C Loss: -0.013981\n",
            "Epoch: 9 | Batch: 58880/100728 (58%) | G Loss: -0.117809 | C Loss: -0.008506\n",
            "Epoch: 9 | Batch: 60160/100728 (60%) | G Loss: -0.118905 | C Loss: -0.014037\n",
            "Epoch: 9 | Batch: 61440/100728 (61%) | G Loss: -0.125177 | C Loss: -0.010173\n",
            "Epoch: 9 | Batch: 62720/100728 (62%) | G Loss: -0.129544 | C Loss: -0.008438\n",
            "Epoch: 9 | Batch: 64000/100728 (64%) | G Loss: -0.131547 | C Loss: -0.009382\n",
            "Epoch: 9 | Batch: 65280/100728 (65%) | G Loss: -0.134391 | C Loss: -0.004461\n",
            "Epoch: 9 | Batch: 66560/100728 (66%) | G Loss: -0.137004 | C Loss: -0.006731\n",
            "Epoch: 9 | Batch: 67840/100728 (67%) | G Loss: -0.140584 | C Loss: 0.000063\n",
            "Epoch: 9 | Batch: 69120/100728 (69%) | G Loss: -0.139984 | C Loss: 0.009071\n",
            "Epoch: 9 | Batch: 70400/100728 (70%) | G Loss: -0.139623 | C Loss: -0.000149\n",
            "Epoch: 9 | Batch: 71680/100728 (71%) | G Loss: -0.139853 | C Loss: -0.000059\n",
            "Epoch: 9 | Batch: 72960/100728 (72%) | G Loss: -0.139053 | C Loss: -0.003524\n",
            "Epoch: 9 | Batch: 74240/100728 (74%) | G Loss: -0.136819 | C Loss: -0.007720\n",
            "Epoch: 9 | Batch: 75520/100728 (75%) | G Loss: -0.135991 | C Loss: 0.000425\n",
            "Epoch: 9 | Batch: 76800/100728 (76%) | G Loss: -0.130736 | C Loss: -0.005338\n",
            "Epoch: 9 | Batch: 78080/100728 (78%) | G Loss: -0.130682 | C Loss: 0.004986\n",
            "Epoch: 9 | Batch: 79360/100728 (79%) | G Loss: -0.127186 | C Loss: -0.000723\n",
            "Epoch: 9 | Batch: 80640/100728 (80%) | G Loss: -0.124346 | C Loss: -0.012077\n",
            "Epoch: 9 | Batch: 81920/100728 (81%) | G Loss: -0.123263 | C Loss: -0.016056\n",
            "Epoch: 9 | Batch: 83200/100728 (83%) | G Loss: -0.119923 | C Loss: -0.010306\n",
            "Epoch: 9 | Batch: 84480/100728 (84%) | G Loss: -0.120273 | C Loss: -0.016076\n",
            "Epoch: 9 | Batch: 85760/100728 (85%) | G Loss: -0.120178 | C Loss: -0.010361\n",
            "Epoch: 9 | Batch: 87040/100728 (86%) | G Loss: -0.120691 | C Loss: -0.005425\n",
            "Epoch: 9 | Batch: 88320/100728 (88%) | G Loss: -0.124265 | C Loss: -0.013534\n",
            "Epoch: 9 | Batch: 89600/100728 (89%) | G Loss: -0.124639 | C Loss: -0.009584\n",
            "Epoch: 9 | Batch: 90880/100728 (90%) | G Loss: -0.129373 | C Loss: -0.007946\n",
            "Epoch: 9 | Batch: 92160/100728 (91%) | G Loss: -0.132421 | C Loss: -0.010927\n",
            "Epoch: 9 | Batch: 93440/100728 (93%) | G Loss: -0.134272 | C Loss: -0.006535\n",
            "Epoch: 9 | Batch: 94720/100728 (94%) | G Loss: -0.137210 | C Loss: -0.005054\n",
            "Epoch: 9 | Batch: 96000/100728 (95%) | G Loss: -0.139845 | C Loss: -0.006365\n",
            "Epoch: 9 | Batch: 97280/100728 (97%) | G Loss: -0.137436 | C Loss: -0.004489\n",
            "Epoch: 9 | Batch: 98560/100728 (98%) | G Loss: -0.136111 | C Loss: -0.006032\n",
            "Epoch: 9 | Batch: 99840/100728 (99%) | G Loss: -0.135140 | C Loss: -0.008266\n",
            "* (Train) Epoch: 9 | G Loss: -0.1262 | C Loss: -0.0084\n",
            " experts had a switch of confusion of confusion of confusion ? switches were they doing to switch off ?\n",
            " i like my square account that do square root or square isn ' t yours yoursin square\n",
            " my statistics had my most in the other i have any other i had any other either .\n",
            " monkeys hate mermaids diet or mintsty thot diet ?\n",
            " ' is you not a real or or or or or or or or or or or or or or or yours\n",
            " the mechanics only had some better inconomic diet yours ? surgery .\n",
            " some of extra fries just just just just doing extra extra fries by doing other\n",
            " basketball release turn test ? test test software test them they get them on the test offer ?\n",
            " do australians think the other vacuum still sucks as any other , but not have\n",
            " my friends are when you never trust the other unual seedual they just never trust them you just trust them\n",
            "\n",
            "Epoch: 10 | Batch: 0/100728 (0%) | G Loss: -0.135357 | C Loss: -0.010723\n",
            "Epoch: 10 | Batch: 1280/100728 (1%) | G Loss: -0.132524 | C Loss: -0.006587\n",
            "Epoch: 10 | Batch: 2560/100728 (3%) | G Loss: -0.128749 | C Loss: -0.013687\n",
            "Epoch: 10 | Batch: 3840/100728 (4%) | G Loss: -0.124285 | C Loss: -0.012838\n",
            "Epoch: 10 | Batch: 5120/100728 (5%) | G Loss: -0.119219 | C Loss: -0.015227\n",
            "Epoch: 10 | Batch: 6400/100728 (6%) | G Loss: -0.117628 | C Loss: -0.012659\n",
            "Epoch: 10 | Batch: 7680/100728 (8%) | G Loss: -0.115141 | C Loss: -0.011992\n",
            "Epoch: 10 | Batch: 8960/100728 (9%) | G Loss: -0.113284 | C Loss: -0.011884\n",
            "Epoch: 10 | Batch: 10240/100728 (10%) | G Loss: -0.111529 | C Loss: -0.011432\n",
            "Epoch: 10 | Batch: 11520/100728 (11%) | G Loss: -0.110255 | C Loss: -0.007607\n",
            "Epoch: 10 | Batch: 12800/100728 (13%) | G Loss: -0.106338 | C Loss: -0.007106\n",
            "Epoch: 10 | Batch: 14080/100728 (14%) | G Loss: -0.098027 | C Loss: -0.004936\n",
            "Epoch: 10 | Batch: 15360/100728 (15%) | G Loss: -0.099353 | C Loss: -0.005291\n",
            "Epoch: 10 | Batch: 16640/100728 (17%) | G Loss: -0.098965 | C Loss: -0.000123\n",
            "Epoch: 10 | Batch: 17920/100728 (18%) | G Loss: -0.099058 | C Loss: -0.012336\n",
            "Epoch: 10 | Batch: 19200/100728 (19%) | G Loss: -0.101192 | C Loss: -0.012363\n",
            "Epoch: 10 | Batch: 20480/100728 (20%) | G Loss: -0.103311 | C Loss: -0.012620\n",
            "Epoch: 10 | Batch: 21760/100728 (22%) | G Loss: -0.105711 | C Loss: -0.008972\n",
            "Epoch: 10 | Batch: 23040/100728 (23%) | G Loss: -0.105869 | C Loss: -0.011379\n",
            "Epoch: 10 | Batch: 24320/100728 (24%) | G Loss: -0.107251 | C Loss: -0.004328\n",
            "Epoch: 10 | Batch: 25600/100728 (25%) | G Loss: -0.111733 | C Loss: -0.005196\n",
            "Epoch: 10 | Batch: 26880/100728 (27%) | G Loss: -0.114144 | C Loss: -0.009520\n",
            "Epoch: 10 | Batch: 28160/100728 (28%) | G Loss: -0.120785 | C Loss: 0.000195\n",
            "Epoch: 10 | Batch: 29440/100728 (29%) | G Loss: -0.121353 | C Loss: -0.006706\n",
            "Epoch: 10 | Batch: 30720/100728 (30%) | G Loss: -0.124046 | C Loss: -0.008575\n",
            "Epoch: 10 | Batch: 32000/100728 (32%) | G Loss: -0.125541 | C Loss: -0.002569\n",
            "Epoch: 10 | Batch: 33280/100728 (33%) | G Loss: -0.126884 | C Loss: -0.009784\n",
            "Epoch: 10 | Batch: 34560/100728 (34%) | G Loss: -0.129534 | C Loss: -0.008603\n",
            "Epoch: 10 | Batch: 35840/100728 (36%) | G Loss: -0.131807 | C Loss: -0.011100\n",
            "Epoch: 10 | Batch: 37120/100728 (37%) | G Loss: -0.132994 | C Loss: -0.005394\n",
            "Epoch: 10 | Batch: 38400/100728 (38%) | G Loss: -0.133267 | C Loss: -0.012573\n",
            "Epoch: 10 | Batch: 39680/100728 (39%) | G Loss: -0.131222 | C Loss: -0.015747\n",
            "Epoch: 10 | Batch: 40960/100728 (41%) | G Loss: -0.129603 | C Loss: -0.015779\n",
            "Epoch: 10 | Batch: 42240/100728 (42%) | G Loss: -0.126997 | C Loss: -0.017556\n",
            "Epoch: 10 | Batch: 43520/100728 (43%) | G Loss: -0.125785 | C Loss: -0.016900\n",
            "Epoch: 10 | Batch: 44800/100728 (44%) | G Loss: -0.124281 | C Loss: -0.016245\n",
            "Epoch: 10 | Batch: 46080/100728 (46%) | G Loss: -0.122680 | C Loss: -0.017772\n",
            "Epoch: 10 | Batch: 47360/100728 (47%) | G Loss: -0.121959 | C Loss: -0.013185\n",
            "Epoch: 10 | Batch: 48640/100728 (48%) | G Loss: -0.122871 | C Loss: -0.011892\n",
            "Epoch: 10 | Batch: 49920/100728 (50%) | G Loss: -0.121099 | C Loss: -0.014273\n",
            "Epoch: 10 | Batch: 51200/100728 (51%) | G Loss: -0.122580 | C Loss: -0.012314\n",
            "Epoch: 10 | Batch: 52480/100728 (52%) | G Loss: -0.123160 | C Loss: -0.004477\n",
            "Epoch: 10 | Batch: 53760/100728 (53%) | G Loss: -0.122403 | C Loss: -0.010432\n",
            "Epoch: 10 | Batch: 55040/100728 (55%) | G Loss: -0.121308 | C Loss: -0.010312\n",
            "Epoch: 10 | Batch: 56320/100728 (56%) | G Loss: -0.123587 | C Loss: -0.009164\n",
            "Epoch: 10 | Batch: 57600/100728 (57%) | G Loss: -0.126692 | C Loss: 0.003543\n",
            "Epoch: 10 | Batch: 58880/100728 (58%) | G Loss: -0.126549 | C Loss: -0.003910\n",
            "Epoch: 10 | Batch: 60160/100728 (60%) | G Loss: -0.127390 | C Loss: 0.000871\n",
            "Epoch: 10 | Batch: 61440/100728 (61%) | G Loss: -0.125585 | C Loss: 0.002588\n",
            "Epoch: 10 | Batch: 62720/100728 (62%) | G Loss: -0.124317 | C Loss: -0.006359\n",
            "Epoch: 10 | Batch: 64000/100728 (64%) | G Loss: -0.122231 | C Loss: -0.004049\n",
            "Epoch: 10 | Batch: 65280/100728 (65%) | G Loss: -0.117408 | C Loss: -0.008693\n",
            "Epoch: 10 | Batch: 66560/100728 (66%) | G Loss: -0.113289 | C Loss: -0.008708\n",
            "Epoch: 10 | Batch: 67840/100728 (67%) | G Loss: -0.107882 | C Loss: -0.004626\n",
            "Epoch: 10 | Batch: 69120/100728 (69%) | G Loss: -0.104411 | C Loss: 0.003532\n",
            "Epoch: 10 | Batch: 70400/100728 (70%) | G Loss: -0.098809 | C Loss: 0.004943\n",
            "Epoch: 10 | Batch: 71680/100728 (71%) | G Loss: -0.097836 | C Loss: -0.008701\n",
            "Epoch: 10 | Batch: 72960/100728 (72%) | G Loss: -0.096400 | C Loss: 0.003605\n",
            "Epoch: 10 | Batch: 74240/100728 (74%) | G Loss: -0.096094 | C Loss: -0.007277\n",
            "Epoch: 10 | Batch: 75520/100728 (75%) | G Loss: -0.099581 | C Loss: 0.001321\n",
            "Epoch: 10 | Batch: 76800/100728 (76%) | G Loss: -0.098181 | C Loss: -0.008053\n",
            "Epoch: 10 | Batch: 78080/100728 (78%) | G Loss: -0.100672 | C Loss: -0.008988\n",
            "Epoch: 10 | Batch: 79360/100728 (79%) | G Loss: -0.106733 | C Loss: 0.006088\n",
            "Epoch: 10 | Batch: 80640/100728 (80%) | G Loss: -0.115001 | C Loss: -0.007321\n",
            "Epoch: 10 | Batch: 81920/100728 (81%) | G Loss: -0.118378 | C Loss: -0.000368\n",
            "Epoch: 10 | Batch: 83200/100728 (83%) | G Loss: -0.118819 | C Loss: 0.005185\n",
            "Epoch: 10 | Batch: 84480/100728 (84%) | G Loss: -0.118311 | C Loss: -0.005917\n",
            "Epoch: 10 | Batch: 85760/100728 (85%) | G Loss: -0.116280 | C Loss: -0.006832\n",
            "Epoch: 10 | Batch: 87040/100728 (86%) | G Loss: -0.112708 | C Loss: -0.000799\n",
            "Epoch: 10 | Batch: 88320/100728 (88%) | G Loss: -0.114060 | C Loss: -0.000130\n",
            "Epoch: 10 | Batch: 89600/100728 (89%) | G Loss: -0.113918 | C Loss: 0.004028\n",
            "Epoch: 10 | Batch: 90880/100728 (90%) | G Loss: -0.112058 | C Loss: 0.002084\n",
            "Epoch: 10 | Batch: 92160/100728 (91%) | G Loss: -0.110467 | C Loss: 0.011691\n",
            "Epoch: 10 | Batch: 93440/100728 (93%) | G Loss: -0.108064 | C Loss: -0.010149\n",
            "Epoch: 10 | Batch: 94720/100728 (94%) | G Loss: -0.108064 | C Loss: -0.004140\n",
            "Epoch: 10 | Batch: 96000/100728 (95%) | G Loss: -0.106845 | C Loss: -0.010979\n",
            "Epoch: 10 | Batch: 97280/100728 (97%) | G Loss: -0.106460 | C Loss: -0.011777\n",
            "Epoch: 10 | Batch: 98560/100728 (98%) | G Loss: -0.107206 | C Loss: -0.007134\n",
            "Epoch: 10 | Batch: 99840/100728 (99%) | G Loss: -0.114221 | C Loss: -0.001479\n",
            "* (Train) Epoch: 10 | G Loss: -0.1157 | C Loss: -0.0061\n",
            " greek jews in so many and you can ' t switch in my com\n",
            " do you have in in common ? but then the garbage and fast\n",
            " fun the fun and antuador isn ' t any other\n",
            " hitler what did in large and not have ? a very close in large\n",
            " which get the stack in depressed ? votic os of pi\n",
            " the scarecrow can ' t believe and i have six weeks of gossip\n",
            " urge 500 i have my eyes during a way and not any asshole .\n",
            " me and like frankney walk onto my wife and dead\n",
            " in my mall ? ? ? are involve of twelve ?\n",
            " people think we is not stupid and this one subreddit contains some solid reually re\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Critic Loss')"
            ]
          },
          "execution_count": 54,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "########################################## TRAINING #########################################\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialise variables\n",
        "epochs=10\n",
        "lr=5e-4\n",
        "interval=10\n",
        "cuda=torch.cuda.is_available()\n",
        "n_critic = 5\n",
        "gp_lambda = 20\n",
        "\n",
        "# Setup Adam optimizer for both\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=lr)\n",
        "c_optimizer = optim.Adam(critic.parameters(), lr=lr)\n",
        "\n",
        "# Initialise losses\n",
        "total_loss = []\n",
        "total_g_loss = []\n",
        "total_c_loss = []\n",
        "\n",
        "if cuda:\n",
        "   generator = generator.cuda()\n",
        "   critic = critic.cuda()\n",
        "    \n",
        "   print('G Parameters:', sum([p.numel() for p in generator.parameters() if p.requires_grad]))\n",
        "   print('C Parameters:', sum([p.numel() for p in critic.parameters() if p.requires_grad]))\n",
        "    \n",
        "   best_loss = np.inf\n",
        "    \n",
        "   for epoch in range(1, epochs + 1):\n",
        "     g_loss, c_loss = train_gan(epoch)\n",
        "     loss = g_loss + c_loss\n",
        "     total_loss.append(loss)\n",
        "     total_g_loss.append(g_loss)\n",
        "     total_c_loss.append(c_loss)\n",
        "          \n",
        "     if loss < best_loss:\n",
        "        best_loss = loss\n",
        "        print('* Saved')\n",
        "        torch.save(generator.state_dict(), 'generator.th{}'.format(epoch))\n",
        "        torch.save(critic.state_dict(), 'critic.th{}'.format(epoch))\n",
        "\n",
        "     for i in range(10):\n",
        "        joke = generate_joke(test_keywords[i].reshape(1, maxlen), generator.cpu(), stepper, decoder, tokenizer, start=[2])\n",
        "        print(joke)\n",
        "\n",
        "     generator = generator.cuda()\n",
        "     print(\"\")\n",
        "\n",
        "# Plot results\n",
        "fig, axs = plt.subplots(3)\n",
        "fig.set_size_inches(10, 10)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "axs[0].plot(range(epochs), total_loss)\n",
        "axs[0].set_title('Total Loss')\n",
        "axs[1].plot(range(epochs), total_g_loss)\n",
        "axs[1].set_title('Generator Loss')\n",
        "axs[2].plot(range(epochs), total_c_loss)\n",
        "axs[2].set_title('Critic Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n6tNo3or4abA",
        "outputId": "564af548-3d56-4420-8de6-5302e40afd89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "G Parameters: 101000\n",
            "C Parameters: 101000\n",
            "Epoch: 1 | Batch: 0/100728 (0%) | G Loss: -0.107470 | C Loss: -0.007796\n",
            "Epoch: 1 | Batch: 1280/100728 (1%) | G Loss: -0.134955 | C Loss: 0.132668\n",
            "Epoch: 1 | Batch: 2560/100728 (3%) | G Loss: -0.143705 | C Loss: 0.026444\n",
            "Epoch: 1 | Batch: 3840/100728 (4%) | G Loss: -0.149605 | C Loss: 0.041548\n",
            "Epoch: 1 | Batch: 5120/100728 (5%) | G Loss: -0.153499 | C Loss: 0.017807\n",
            "Epoch: 1 | Batch: 6400/100728 (6%) | G Loss: -0.155642 | C Loss: 0.017000\n",
            "Epoch: 1 | Batch: 7680/100728 (8%) | G Loss: -0.152015 | C Loss: 0.019139\n",
            "Epoch: 1 | Batch: 8960/100728 (9%) | G Loss: -0.143708 | C Loss: 0.018654\n",
            "Epoch: 1 | Batch: 10240/100728 (10%) | G Loss: -0.130186 | C Loss: 0.013278\n",
            "Epoch: 1 | Batch: 11520/100728 (11%) | G Loss: -0.109476 | C Loss: -0.001204\n",
            "Epoch: 1 | Batch: 12800/100728 (13%) | G Loss: -0.086030 | C Loss: -0.012986\n",
            "Epoch: 1 | Batch: 14080/100728 (14%) | G Loss: -0.069801 | C Loss: -0.023159\n",
            "Epoch: 1 | Batch: 15360/100728 (15%) | G Loss: -0.061639 | C Loss: -0.032302\n",
            "Epoch: 1 | Batch: 16640/100728 (17%) | G Loss: -0.054151 | C Loss: -0.039391\n",
            "Epoch: 1 | Batch: 17920/100728 (18%) | G Loss: -0.062010 | C Loss: -0.015929\n",
            "Epoch: 1 | Batch: 19200/100728 (19%) | G Loss: -0.062195 | C Loss: -0.035257\n",
            "Epoch: 1 | Batch: 20480/100728 (20%) | G Loss: -0.063126 | C Loss: -0.029465\n",
            "Epoch: 1 | Batch: 21760/100728 (22%) | G Loss: -0.066840 | C Loss: -0.022214\n",
            "Epoch: 1 | Batch: 23040/100728 (23%) | G Loss: -0.064930 | C Loss: -0.027258\n",
            "Epoch: 1 | Batch: 24320/100728 (24%) | G Loss: -0.066694 | C Loss: -0.015934\n",
            "Epoch: 1 | Batch: 25600/100728 (25%) | G Loss: -0.069511 | C Loss: -0.017627\n",
            "Epoch: 1 | Batch: 26880/100728 (27%) | G Loss: -0.074091 | C Loss: -0.016276\n",
            "Epoch: 1 | Batch: 28160/100728 (28%) | G Loss: -0.075682 | C Loss: -0.010324\n",
            "Epoch: 1 | Batch: 29440/100728 (29%) | G Loss: -0.080051 | C Loss: -0.010890\n",
            "Epoch: 1 | Batch: 30720/100728 (30%) | G Loss: -0.082370 | C Loss: -0.008387\n",
            "Epoch: 1 | Batch: 32000/100728 (32%) | G Loss: -0.084145 | C Loss: -0.005836\n",
            "Epoch: 1 | Batch: 33280/100728 (33%) | G Loss: -0.089700 | C Loss: 0.003184\n",
            "Epoch: 1 | Batch: 34560/100728 (34%) | G Loss: -0.092695 | C Loss: -0.002409\n",
            "Epoch: 1 | Batch: 35840/100728 (36%) | G Loss: -0.097888 | C Loss: 0.000234\n",
            "Epoch: 1 | Batch: 37120/100728 (37%) | G Loss: -0.101166 | C Loss: -0.001343\n",
            "Epoch: 1 | Batch: 38400/100728 (38%) | G Loss: -0.106336 | C Loss: -0.005911\n",
            "Epoch: 1 | Batch: 39680/100728 (39%) | G Loss: -0.112294 | C Loss: -0.001134\n",
            "Epoch: 1 | Batch: 40960/100728 (41%) | G Loss: -0.118299 | C Loss: -0.003362\n",
            "Epoch: 1 | Batch: 42240/100728 (42%) | G Loss: -0.123601 | C Loss: -0.002037\n",
            "Epoch: 1 | Batch: 43520/100728 (43%) | G Loss: -0.129391 | C Loss: 0.003030\n",
            "Epoch: 1 | Batch: 44800/100728 (44%) | G Loss: -0.130184 | C Loss: -0.007047\n",
            "Epoch: 1 | Batch: 46080/100728 (46%) | G Loss: -0.131604 | C Loss: -0.005278\n",
            "Epoch: 1 | Batch: 47360/100728 (47%) | G Loss: -0.129022 | C Loss: -0.006582\n",
            "Epoch: 1 | Batch: 48640/100728 (48%) | G Loss: -0.126436 | C Loss: -0.003664\n",
            "Epoch: 1 | Batch: 49920/100728 (50%) | G Loss: -0.120540 | C Loss: -0.007803\n",
            "Epoch: 1 | Batch: 51200/100728 (51%) | G Loss: -0.114693 | C Loss: -0.003497\n",
            "Epoch: 1 | Batch: 52480/100728 (52%) | G Loss: -0.104914 | C Loss: -0.009709\n",
            "Epoch: 1 | Batch: 53760/100728 (53%) | G Loss: -0.090501 | C Loss: -0.001630\n",
            "Epoch: 1 | Batch: 55040/100728 (55%) | G Loss: -0.081040 | C Loss: -0.014612\n",
            "Epoch: 1 | Batch: 56320/100728 (56%) | G Loss: -0.074462 | C Loss: -0.011002\n",
            "Epoch: 1 | Batch: 57600/100728 (57%) | G Loss: -0.071076 | C Loss: -0.004056\n",
            "Epoch: 1 | Batch: 58880/100728 (58%) | G Loss: -0.073064 | C Loss: -0.005304\n",
            "Epoch: 1 | Batch: 60160/100728 (60%) | G Loss: -0.069857 | C Loss: -0.004803\n",
            "Epoch: 1 | Batch: 61440/100728 (61%) | G Loss: -0.072685 | C Loss: -0.013565\n",
            "Epoch: 1 | Batch: 62720/100728 (62%) | G Loss: -0.071978 | C Loss: -0.015542\n",
            "Epoch: 1 | Batch: 64000/100728 (64%) | G Loss: -0.074369 | C Loss: 0.003725\n",
            "Epoch: 1 | Batch: 65280/100728 (65%) | G Loss: -0.082867 | C Loss: -0.003371\n",
            "Epoch: 1 | Batch: 66560/100728 (66%) | G Loss: -0.085933 | C Loss: -0.002485\n",
            "Epoch: 1 | Batch: 67840/100728 (67%) | G Loss: -0.088412 | C Loss: -0.007316\n",
            "Epoch: 1 | Batch: 69120/100728 (69%) | G Loss: -0.091797 | C Loss: -0.007438\n",
            "Epoch: 1 | Batch: 70400/100728 (70%) | G Loss: -0.097030 | C Loss: -0.001979\n",
            "Epoch: 1 | Batch: 71680/100728 (71%) | G Loss: -0.102485 | C Loss: 0.009640\n",
            "Epoch: 1 | Batch: 72960/100728 (72%) | G Loss: -0.105030 | C Loss: -0.002976\n",
            "Epoch: 1 | Batch: 74240/100728 (74%) | G Loss: -0.106465 | C Loss: -0.008385\n",
            "Epoch: 1 | Batch: 75520/100728 (75%) | G Loss: -0.104596 | C Loss: -0.010173\n",
            "Epoch: 1 | Batch: 76800/100728 (76%) | G Loss: -0.104492 | C Loss: -0.009683\n",
            "Epoch: 1 | Batch: 78080/100728 (78%) | G Loss: -0.106988 | C Loss: 0.000039\n",
            "Epoch: 1 | Batch: 79360/100728 (79%) | G Loss: -0.107598 | C Loss: -0.000086\n",
            "Epoch: 1 | Batch: 80640/100728 (80%) | G Loss: -0.106845 | C Loss: -0.001345\n",
            "Epoch: 1 | Batch: 81920/100728 (81%) | G Loss: -0.107923 | C Loss: 0.004133\n",
            "Epoch: 1 | Batch: 83200/100728 (83%) | G Loss: -0.107446 | C Loss: -0.002790\n",
            "Epoch: 1 | Batch: 84480/100728 (84%) | G Loss: -0.103726 | C Loss: -0.002358\n",
            "Epoch: 1 | Batch: 85760/100728 (85%) | G Loss: -0.097670 | C Loss: -0.005333\n",
            "Epoch: 1 | Batch: 87040/100728 (86%) | G Loss: -0.089780 | C Loss: -0.003228\n",
            "Epoch: 1 | Batch: 88320/100728 (88%) | G Loss: -0.080745 | C Loss: -0.005917\n",
            "Epoch: 1 | Batch: 89600/100728 (89%) | G Loss: -0.074285 | C Loss: 0.017863\n",
            "Epoch: 1 | Batch: 90880/100728 (90%) | G Loss: -0.073113 | C Loss: -0.000009\n",
            "Epoch: 1 | Batch: 92160/100728 (91%) | G Loss: -0.071222 | C Loss: -0.011639\n",
            "Epoch: 1 | Batch: 93440/100728 (93%) | G Loss: -0.070926 | C Loss: -0.015657\n",
            "Epoch: 1 | Batch: 94720/100728 (94%) | G Loss: -0.069981 | C Loss: -0.012454\n",
            "Epoch: 1 | Batch: 96000/100728 (95%) | G Loss: -0.067583 | C Loss: -0.013499\n",
            "Epoch: 1 | Batch: 97280/100728 (97%) | G Loss: -0.070026 | C Loss: -0.013449\n",
            "Epoch: 1 | Batch: 98560/100728 (98%) | G Loss: -0.073023 | C Loss: -0.012832\n",
            "Epoch: 1 | Batch: 99840/100728 (99%) | G Loss: -0.071627 | C Loss: -0.013466\n",
            "* (Train) Epoch: 1 | G Loss: -0.0952 | C Loss: 0.0006\n",
            "* Saved\n",
            " what does a with foreplay ? the police ? with the heart ? ? ? ?\n",
            " is the fastest charging you ? you can t rhyme for a lot you ?\n",
            " hillbillies do you have an erect of the channel ? ? ? ? by . 9 .\n",
            " do christians be out when you are the same ? four squared\n",
            " original joke and god reposted joke you like god comment\n",
            " uk do\n",
            " why did the restaurant play with its eyes ? its its heart ? its flood ? its flood ? its flood gets its heart last .\n",
            " what does a flat earther play in the twin play ? only because i get in the dead body . i play , because of dead people play .\n",
            " offender is on a monkey ? . last night and had an first monkey .\n",
            " i . an . why . it . . never bang . . . . .\n",
            "\n",
            "Epoch: 2 | Batch: 0/100728 (0%) | G Loss: -0.072634 | C Loss: -0.011733\n",
            "Epoch: 2 | Batch: 1280/100728 (1%) | G Loss: -0.072011 | C Loss: -0.011752\n",
            "Epoch: 2 | Batch: 2560/100728 (3%) | G Loss: -0.074220 | C Loss: -0.009071\n",
            "Epoch: 2 | Batch: 3840/100728 (4%) | G Loss: -0.076100 | C Loss: -0.008202\n",
            "Epoch: 2 | Batch: 5120/100728 (5%) | G Loss: -0.076953 | C Loss: -0.004087\n",
            "Epoch: 2 | Batch: 6400/100728 (6%) | G Loss: -0.079371 | C Loss: -0.009836\n",
            "Epoch: 2 | Batch: 7680/100728 (8%) | G Loss: -0.082049 | C Loss: 0.021694\n",
            "Epoch: 2 | Batch: 8960/100728 (9%) | G Loss: -0.092032 | C Loss: 0.018226\n",
            "Epoch: 2 | Batch: 10240/100728 (10%) | G Loss: -0.098402 | C Loss: -0.007327\n",
            "Epoch: 2 | Batch: 11520/100728 (11%) | G Loss: -0.108660 | C Loss: -0.006810\n",
            "Epoch: 2 | Batch: 12800/100728 (13%) | G Loss: -0.114874 | C Loss: 0.008009\n",
            "Epoch: 2 | Batch: 14080/100728 (14%) | G Loss: -0.120617 | C Loss: -0.006715\n",
            "Epoch: 2 | Batch: 15360/100728 (15%) | G Loss: -0.119854 | C Loss: -0.004693\n",
            "Epoch: 2 | Batch: 16640/100728 (17%) | G Loss: -0.120135 | C Loss: -0.007342\n",
            "Epoch: 2 | Batch: 17920/100728 (18%) | G Loss: -0.118246 | C Loss: 0.001143\n",
            "Epoch: 2 | Batch: 19200/100728 (19%) | G Loss: -0.116770 | C Loss: -0.004674\n",
            "Epoch: 2 | Batch: 20480/100728 (20%) | G Loss: -0.113822 | C Loss: -0.004019\n",
            "Epoch: 2 | Batch: 21760/100728 (22%) | G Loss: -0.111745 | C Loss: -0.002495\n",
            "Epoch: 2 | Batch: 23040/100728 (23%) | G Loss: -0.109020 | C Loss: 0.004690\n",
            "Epoch: 2 | Batch: 24320/100728 (24%) | G Loss: -0.107264 | C Loss: 0.001786\n",
            "Epoch: 2 | Batch: 25600/100728 (25%) | G Loss: -0.095855 | C Loss: 0.011621\n",
            "Epoch: 2 | Batch: 26880/100728 (27%) | G Loss: -0.085035 | C Loss: -0.003475\n",
            "Epoch: 2 | Batch: 28160/100728 (28%) | G Loss: -0.074491 | C Loss: 0.036153\n",
            "Epoch: 2 | Batch: 29440/100728 (29%) | G Loss: -0.073374 | C Loss: 0.007125\n",
            "Epoch: 2 | Batch: 30720/100728 (30%) | G Loss: -0.074040 | C Loss: 0.013399\n",
            "Epoch: 2 | Batch: 32000/100728 (32%) | G Loss: -0.073432 | C Loss: -0.004805\n",
            "Epoch: 2 | Batch: 33280/100728 (33%) | G Loss: -0.068546 | C Loss: -0.009567\n",
            "Epoch: 2 | Batch: 34560/100728 (34%) | G Loss: -0.070239 | C Loss: -0.012982\n",
            "Epoch: 2 | Batch: 35840/100728 (36%) | G Loss: -0.071268 | C Loss: -0.009363\n",
            "Epoch: 2 | Batch: 37120/100728 (37%) | G Loss: -0.073414 | C Loss: 0.000301\n",
            "Epoch: 2 | Batch: 38400/100728 (38%) | G Loss: -0.076585 | C Loss: -0.009148\n",
            "Epoch: 2 | Batch: 39680/100728 (39%) | G Loss: -0.082084 | C Loss: -0.012969\n",
            "Epoch: 2 | Batch: 40960/100728 (41%) | G Loss: -0.087508 | C Loss: -0.011374\n",
            "Epoch: 2 | Batch: 42240/100728 (42%) | G Loss: -0.091796 | C Loss: 0.012704\n",
            "Epoch: 2 | Batch: 43520/100728 (43%) | G Loss: -0.099024 | C Loss: -0.010640\n",
            "Epoch: 2 | Batch: 44800/100728 (44%) | G Loss: -0.097922 | C Loss: -0.007779\n",
            "Epoch: 2 | Batch: 46080/100728 (46%) | G Loss: -0.099035 | C Loss: -0.009356\n",
            "Epoch: 2 | Batch: 47360/100728 (47%) | G Loss: -0.099263 | C Loss: -0.008146\n",
            "Epoch: 2 | Batch: 48640/100728 (48%) | G Loss: -0.099178 | C Loss: 0.007668\n",
            "Epoch: 2 | Batch: 49920/100728 (50%) | G Loss: -0.098220 | C Loss: -0.007384\n",
            "Epoch: 2 | Batch: 51200/100728 (51%) | G Loss: -0.098332 | C Loss: -0.007316\n",
            "Epoch: 2 | Batch: 52480/100728 (52%) | G Loss: -0.094067 | C Loss: -0.012403\n",
            "Epoch: 2 | Batch: 53760/100728 (53%) | G Loss: -0.093537 | C Loss: -0.011845\n",
            "Epoch: 2 | Batch: 55040/100728 (55%) | G Loss: -0.091068 | C Loss: -0.011583\n",
            "Epoch: 2 | Batch: 56320/100728 (56%) | G Loss: -0.085588 | C Loss: 0.003686\n",
            "Epoch: 2 | Batch: 57600/100728 (57%) | G Loss: -0.079245 | C Loss: -0.005441\n",
            "Epoch: 2 | Batch: 58880/100728 (58%) | G Loss: -0.081180 | C Loss: -0.007340\n",
            "Epoch: 2 | Batch: 60160/100728 (60%) | G Loss: -0.079810 | C Loss: -0.004332\n",
            "Epoch: 2 | Batch: 61440/100728 (61%) | G Loss: -0.079099 | C Loss: -0.004524\n",
            "Epoch: 2 | Batch: 62720/100728 (62%) | G Loss: -0.079926 | C Loss: -0.004552\n",
            "Epoch: 2 | Batch: 64000/100728 (64%) | G Loss: -0.077871 | C Loss: 0.005891\n",
            "Epoch: 2 | Batch: 65280/100728 (65%) | G Loss: -0.078275 | C Loss: -0.010772\n",
            "Epoch: 2 | Batch: 66560/100728 (66%) | G Loss: -0.076694 | C Loss: -0.010354\n",
            "Epoch: 2 | Batch: 67840/100728 (67%) | G Loss: -0.076222 | C Loss: -0.007188\n",
            "Epoch: 2 | Batch: 69120/100728 (69%) | G Loss: -0.075148 | C Loss: 0.008971\n",
            "Epoch: 2 | Batch: 70400/100728 (70%) | G Loss: -0.076647 | C Loss: -0.005972\n",
            "Epoch: 2 | Batch: 71680/100728 (71%) | G Loss: -0.078315 | C Loss: -0.006212\n",
            "Epoch: 2 | Batch: 72960/100728 (72%) | G Loss: -0.079038 | C Loss: -0.006224\n",
            "Epoch: 2 | Batch: 74240/100728 (74%) | G Loss: -0.080897 | C Loss: -0.004780\n",
            "Epoch: 2 | Batch: 75520/100728 (75%) | G Loss: -0.082358 | C Loss: -0.002015\n",
            "Epoch: 2 | Batch: 76800/100728 (76%) | G Loss: -0.085705 | C Loss: -0.000412\n",
            "Epoch: 2 | Batch: 78080/100728 (78%) | G Loss: -0.086996 | C Loss: -0.002363\n",
            "Epoch: 2 | Batch: 79360/100728 (79%) | G Loss: -0.089641 | C Loss: 0.007907\n",
            "Epoch: 2 | Batch: 80640/100728 (80%) | G Loss: -0.089136 | C Loss: 0.000229\n",
            "Epoch: 2 | Batch: 81920/100728 (81%) | G Loss: -0.088097 | C Loss: -0.003451\n",
            "Epoch: 2 | Batch: 83200/100728 (83%) | G Loss: -0.084776 | C Loss: -0.004643\n",
            "Epoch: 2 | Batch: 84480/100728 (84%) | G Loss: -0.077253 | C Loss: 0.030319\n",
            "Epoch: 2 | Batch: 85760/100728 (85%) | G Loss: -0.073602 | C Loss: -0.010274\n",
            "Epoch: 2 | Batch: 87040/100728 (86%) | G Loss: -0.068806 | C Loss: -0.013329\n",
            "Epoch: 2 | Batch: 88320/100728 (88%) | G Loss: -0.063995 | C Loss: -0.015716\n",
            "Epoch: 2 | Batch: 89600/100728 (89%) | G Loss: -0.060917 | C Loss: -0.019137\n",
            "Epoch: 2 | Batch: 90880/100728 (90%) | G Loss: -0.060409 | C Loss: -0.006830\n",
            "Epoch: 2 | Batch: 92160/100728 (91%) | G Loss: -0.063321 | C Loss: -0.001295\n",
            "Epoch: 2 | Batch: 93440/100728 (93%) | G Loss: -0.063426 | C Loss: -0.016632\n",
            "Epoch: 2 | Batch: 94720/100728 (94%) | G Loss: -0.065907 | C Loss: -0.012734\n",
            "Epoch: 2 | Batch: 96000/100728 (95%) | G Loss: -0.068714 | C Loss: -0.013240\n",
            "Epoch: 2 | Batch: 97280/100728 (97%) | G Loss: -0.070322 | C Loss: -0.007816\n",
            "Epoch: 2 | Batch: 98560/100728 (98%) | G Loss: -0.074506 | C Loss: -0.007615\n",
            "Epoch: 2 | Batch: 99840/100728 (99%) | G Loss: -0.080511 | C Loss: -0.007478\n",
            "* (Train) Epoch: 2 | G Loss: -0.0852 | C Loss: -0.0020\n",
            " do like a rapist deodorant are arguing of arguing ? just make that you are just a switch factory .\n",
            " do you like never russian described its to are a tall ? its a lot of 15 .\n",
            " do you get sick of a day ? they don ' t make sense to make a good naan of naan .\n",
            " did you get a small neighbor to be close to the baseball they would they would they were always willing . .\n",
            " do you ever been at a religious sized comedian they are half full sized half of half of religious sized reason that turned\n",
            " what foolines had a audition of ? they were ? they haven ' t swear that up ? ?\n",
            " did you do to a fertgage are looking into a liquor store ? they are looking\n",
            " do you like a 5 of a sex life ? a copy of dead guys\n",
            " do you ever heard of the only were a disney bin of a giant corpag ?\n",
            " at . anyone . anyone who don ' t . to anyone ? a . . . .\n",
            "\n",
            "Epoch: 3 | Batch: 0/100728 (0%) | G Loss: -0.086067 | C Loss: 0.001474\n",
            "Epoch: 3 | Batch: 1280/100728 (1%) | G Loss: -0.090870 | C Loss: -0.003808\n",
            "Epoch: 3 | Batch: 2560/100728 (3%) | G Loss: -0.097153 | C Loss: 0.004069\n",
            "Epoch: 3 | Batch: 3840/100728 (4%) | G Loss: -0.102433 | C Loss: 0.002861\n",
            "Epoch: 3 | Batch: 5120/100728 (5%) | G Loss: -0.108582 | C Loss: 0.011567\n",
            "Epoch: 3 | Batch: 6400/100728 (6%) | G Loss: -0.115977 | C Loss: -0.000062\n",
            "Epoch: 3 | Batch: 7680/100728 (8%) | G Loss: -0.121577 | C Loss: -0.007130\n",
            "Epoch: 3 | Batch: 8960/100728 (9%) | G Loss: -0.122913 | C Loss: -0.005441\n",
            "Epoch: 3 | Batch: 10240/100728 (10%) | G Loss: -0.120610 | C Loss: 0.021036\n",
            "Epoch: 3 | Batch: 11520/100728 (11%) | G Loss: -0.120374 | C Loss: -0.003351\n",
            "Epoch: 3 | Batch: 12800/100728 (13%) | G Loss: -0.117077 | C Loss: -0.006485\n",
            "Epoch: 3 | Batch: 14080/100728 (14%) | G Loss: -0.114546 | C Loss: -0.011487\n",
            "Epoch: 3 | Batch: 15360/100728 (15%) | G Loss: -0.111925 | C Loss: -0.007641\n",
            "Epoch: 3 | Batch: 16640/100728 (17%) | G Loss: -0.109909 | C Loss: -0.009122\n",
            "Epoch: 3 | Batch: 17920/100728 (18%) | G Loss: -0.107855 | C Loss: -0.000280\n",
            "Epoch: 3 | Batch: 19200/100728 (19%) | G Loss: -0.103739 | C Loss: -0.004689\n",
            "Epoch: 3 | Batch: 20480/100728 (20%) | G Loss: -0.100867 | C Loss: 0.000074\n",
            "Epoch: 3 | Batch: 21760/100728 (22%) | G Loss: -0.096524 | C Loss: -0.002847\n",
            "Epoch: 3 | Batch: 23040/100728 (23%) | G Loss: -0.087830 | C Loss: 0.022061\n",
            "Epoch: 3 | Batch: 24320/100728 (24%) | G Loss: -0.077300 | C Loss: 0.015993\n",
            "Epoch: 3 | Batch: 25600/100728 (25%) | G Loss: -0.068691 | C Loss: 0.001272\n",
            "Epoch: 3 | Batch: 26880/100728 (27%) | G Loss: -0.063791 | C Loss: 0.020341\n",
            "Epoch: 3 | Batch: 28160/100728 (28%) | G Loss: -0.057592 | C Loss: -0.007316\n",
            "Epoch: 3 | Batch: 29440/100728 (29%) | G Loss: -0.045247 | C Loss: -0.007985\n",
            "Epoch: 3 | Batch: 30720/100728 (30%) | G Loss: -0.037228 | C Loss: 0.003417\n",
            "Epoch: 3 | Batch: 32000/100728 (32%) | G Loss: -0.037694 | C Loss: -0.016103\n",
            "Epoch: 3 | Batch: 33280/100728 (33%) | G Loss: -0.038713 | C Loss: -0.005562\n",
            "Epoch: 3 | Batch: 34560/100728 (34%) | G Loss: -0.042116 | C Loss: -0.008533\n",
            "Epoch: 3 | Batch: 35840/100728 (36%) | G Loss: -0.041040 | C Loss: -0.007802\n",
            "Epoch: 3 | Batch: 37120/100728 (37%) | G Loss: -0.043438 | C Loss: -0.008123\n",
            "Epoch: 3 | Batch: 38400/100728 (38%) | G Loss: -0.045546 | C Loss: 0.005139\n",
            "Epoch: 3 | Batch: 39680/100728 (39%) | G Loss: -0.053581 | C Loss: -0.004175\n",
            "Epoch: 3 | Batch: 40960/100728 (41%) | G Loss: -0.059536 | C Loss: -0.004759\n",
            "Epoch: 3 | Batch: 42240/100728 (42%) | G Loss: -0.066597 | C Loss: -0.004265\n",
            "Epoch: 3 | Batch: 43520/100728 (43%) | G Loss: -0.075567 | C Loss: 0.018311\n",
            "Epoch: 3 | Batch: 44800/100728 (44%) | G Loss: -0.080439 | C Loss: 0.008584\n",
            "Epoch: 3 | Batch: 46080/100728 (46%) | G Loss: -0.082762 | C Loss: 0.006637\n",
            "Epoch: 3 | Batch: 47360/100728 (47%) | G Loss: -0.086202 | C Loss: -0.002294\n",
            "Epoch: 3 | Batch: 48640/100728 (48%) | G Loss: -0.065872 | C Loss: -0.008057\n",
            "Epoch: 3 | Batch: 49920/100728 (50%) | G Loss: -0.066523 | C Loss: 0.049370\n",
            "Epoch: 3 | Batch: 51200/100728 (51%) | G Loss: -0.070168 | C Loss: -0.014230\n",
            "Epoch: 3 | Batch: 52480/100728 (52%) | G Loss: -0.068753 | C Loss: -0.008802\n",
            "Epoch: 3 | Batch: 53760/100728 (53%) | G Loss: -0.070890 | C Loss: -0.009838\n",
            "Epoch: 3 | Batch: 55040/100728 (55%) | G Loss: -0.072286 | C Loss: -0.006551\n",
            "Epoch: 3 | Batch: 56320/100728 (56%) | G Loss: -0.072615 | C Loss: -0.010458\n",
            "Epoch: 3 | Batch: 57600/100728 (57%) | G Loss: -0.070766 | C Loss: -0.007585\n",
            "Epoch: 3 | Batch: 58880/100728 (58%) | G Loss: -0.067508 | C Loss: -0.006308\n",
            "Epoch: 3 | Batch: 60160/100728 (60%) | G Loss: -0.064627 | C Loss: -0.007316\n",
            "Epoch: 3 | Batch: 61440/100728 (61%) | G Loss: -0.063104 | C Loss: -0.005464\n",
            "Epoch: 3 | Batch: 62720/100728 (62%) | G Loss: -0.066324 | C Loss: -0.000210\n",
            "Epoch: 3 | Batch: 64000/100728 (64%) | G Loss: -0.067699 | C Loss: 0.003808\n",
            "Epoch: 3 | Batch: 65280/100728 (65%) | G Loss: -0.071775 | C Loss: 0.009944\n",
            "Epoch: 3 | Batch: 66560/100728 (66%) | G Loss: -0.077554 | C Loss: 0.003986\n",
            "Epoch: 3 | Batch: 67840/100728 (67%) | G Loss: -0.079629 | C Loss: 0.010182\n",
            "Epoch: 3 | Batch: 69120/100728 (69%) | G Loss: -0.082635 | C Loss: -0.002564\n",
            "Epoch: 3 | Batch: 70400/100728 (70%) | G Loss: -0.084437 | C Loss: -0.001009\n",
            "Epoch: 3 | Batch: 71680/100728 (71%) | G Loss: -0.084539 | C Loss: -0.006833\n",
            "Epoch: 3 | Batch: 72960/100728 (72%) | G Loss: -0.083085 | C Loss: -0.002388\n",
            "Epoch: 3 | Batch: 74240/100728 (74%) | G Loss: -0.084567 | C Loss: 0.000699\n",
            "Epoch: 3 | Batch: 75520/100728 (75%) | G Loss: -0.073796 | C Loss: 0.006554\n",
            "Epoch: 3 | Batch: 76800/100728 (76%) | G Loss: -0.067148 | C Loss: 0.005606\n",
            "Epoch: 3 | Batch: 78080/100728 (78%) | G Loss: -0.057714 | C Loss: 0.013819\n",
            "Epoch: 3 | Batch: 79360/100728 (79%) | G Loss: -0.058198 | C Loss: -0.010327\n",
            "Epoch: 3 | Batch: 80640/100728 (80%) | G Loss: -0.055535 | C Loss: -0.012212\n",
            "Epoch: 3 | Batch: 81920/100728 (81%) | G Loss: -0.059509 | C Loss: 0.008319\n",
            "Epoch: 3 | Batch: 83200/100728 (83%) | G Loss: -0.058104 | C Loss: -0.014169\n",
            "Epoch: 3 | Batch: 84480/100728 (84%) | G Loss: -0.056421 | C Loss: -0.012090\n",
            "Epoch: 3 | Batch: 85760/100728 (85%) | G Loss: -0.057125 | C Loss: -0.010420\n",
            "Epoch: 3 | Batch: 87040/100728 (86%) | G Loss: -0.058830 | C Loss: -0.008118\n",
            "Epoch: 3 | Batch: 88320/100728 (88%) | G Loss: -0.060295 | C Loss: -0.010795\n",
            "Epoch: 3 | Batch: 89600/100728 (89%) | G Loss: -0.063275 | C Loss: -0.009311\n",
            "Epoch: 3 | Batch: 90880/100728 (90%) | G Loss: -0.066118 | C Loss: -0.006326\n",
            "Epoch: 3 | Batch: 92160/100728 (91%) | G Loss: -0.069239 | C Loss: -0.001497\n",
            "Epoch: 3 | Batch: 93440/100728 (93%) | G Loss: -0.071628 | C Loss: -0.006049\n",
            "Epoch: 3 | Batch: 94720/100728 (94%) | G Loss: -0.073676 | C Loss: 0.004452\n",
            "Epoch: 3 | Batch: 96000/100728 (95%) | G Loss: -0.076500 | C Loss: 0.002796\n",
            "Epoch: 3 | Batch: 97280/100728 (97%) | G Loss: -0.081580 | C Loss: -0.007680\n",
            "Epoch: 3 | Batch: 98560/100728 (98%) | G Loss: -0.082843 | C Loss: -0.009336\n",
            "Epoch: 3 | Batch: 99840/100728 (99%) | G Loss: -0.080110 | C Loss: -0.010659\n",
            "* (Train) Epoch: 3 | G Loss: -0.0760 | C Loss: 0.0017\n",
            " did the muslim friend there a the other bountaive if i was arguing metal not by my\n",
            " what did the tribe cin the name ? a cinhowin ?\n",
            " i have the american porn joke the black men your cee one hand .\n",
            " did what would the a crazy person say ? neighbor\n",
            " did one people say the difference ? i am in a\n",
            " did the black lady as the dog ? the police .\n",
            " i did the cat , the eyes run into a bar and you\n",
            " did the pp , come ? dead as dead\n",
            " the did the tree cleaner have a great car ? i thought , you had a great buzz here\n",
            " what did the huss ? pee ? the pee pee ? ? ? ? pee pee .\n",
            "\n",
            "Epoch: 4 | Batch: 0/100728 (0%) | G Loss: -0.080023 | C Loss: -0.010128\n",
            "Epoch: 4 | Batch: 1280/100728 (1%) | G Loss: -0.076831 | C Loss: -0.009334\n",
            "Epoch: 4 | Batch: 2560/100728 (3%) | G Loss: -0.075395 | C Loss: -0.008621\n",
            "Epoch: 4 | Batch: 3840/100728 (4%) | G Loss: -0.077038 | C Loss: -0.003537\n",
            "Epoch: 4 | Batch: 5120/100728 (5%) | G Loss: -0.081334 | C Loss: 0.000794\n",
            "Epoch: 4 | Batch: 6400/100728 (6%) | G Loss: -0.085631 | C Loss: 0.001417\n",
            "Epoch: 4 | Batch: 7680/100728 (8%) | G Loss: -0.079087 | C Loss: -0.001971\n",
            "Epoch: 4 | Batch: 8960/100728 (9%) | G Loss: -0.077092 | C Loss: -0.007297\n",
            "Epoch: 4 | Batch: 10240/100728 (10%) | G Loss: -0.076153 | C Loss: -0.007165\n",
            "Epoch: 4 | Batch: 11520/100728 (11%) | G Loss: -0.069304 | C Loss: 0.062874\n",
            "Epoch: 4 | Batch: 12800/100728 (13%) | G Loss: -0.073314 | C Loss: 0.006918\n",
            "Epoch: 4 | Batch: 14080/100728 (14%) | G Loss: -0.075437 | C Loss: -0.009300\n",
            "Epoch: 4 | Batch: 15360/100728 (15%) | G Loss: -0.075803 | C Loss: -0.014156\n",
            "Epoch: 4 | Batch: 16640/100728 (17%) | G Loss: -0.076498 | C Loss: -0.013772\n",
            "Epoch: 4 | Batch: 17920/100728 (18%) | G Loss: -0.078040 | C Loss: -0.012928\n",
            "Epoch: 4 | Batch: 19200/100728 (19%) | G Loss: -0.077851 | C Loss: -0.011693\n",
            "Epoch: 4 | Batch: 20480/100728 (20%) | G Loss: -0.076834 | C Loss: -0.011409\n",
            "Epoch: 4 | Batch: 21760/100728 (22%) | G Loss: -0.075141 | C Loss: -0.006398\n",
            "Epoch: 4 | Batch: 23040/100728 (23%) | G Loss: -0.073534 | C Loss: -0.006447\n",
            "Epoch: 4 | Batch: 24320/100728 (24%) | G Loss: -0.074665 | C Loss: 0.013641\n",
            "Epoch: 4 | Batch: 25600/100728 (25%) | G Loss: -0.072911 | C Loss: -0.006216\n",
            "Epoch: 4 | Batch: 26880/100728 (27%) | G Loss: -0.072706 | C Loss: -0.003227\n",
            "Epoch: 4 | Batch: 28160/100728 (28%) | G Loss: -0.075410 | C Loss: -0.002068\n",
            "Epoch: 4 | Batch: 29440/100728 (29%) | G Loss: -0.074683 | C Loss: -0.009887\n",
            "Epoch: 4 | Batch: 30720/100728 (30%) | G Loss: -0.075125 | C Loss: -0.008555\n",
            "Epoch: 4 | Batch: 32000/100728 (32%) | G Loss: -0.077681 | C Loss: -0.011789\n",
            "Epoch: 4 | Batch: 33280/100728 (33%) | G Loss: -0.081214 | C Loss: -0.011147\n",
            "Epoch: 4 | Batch: 34560/100728 (34%) | G Loss: -0.084711 | C Loss: -0.009555\n",
            "Epoch: 4 | Batch: 35840/100728 (36%) | G Loss: -0.086016 | C Loss: -0.001123\n",
            "Epoch: 4 | Batch: 37120/100728 (37%) | G Loss: -0.088881 | C Loss: -0.003066\n",
            "Epoch: 4 | Batch: 38400/100728 (38%) | G Loss: -0.090411 | C Loss: -0.005884\n",
            "Epoch: 4 | Batch: 39680/100728 (39%) | G Loss: -0.090625 | C Loss: 0.003724\n",
            "Epoch: 4 | Batch: 40960/100728 (41%) | G Loss: -0.091746 | C Loss: -0.006544\n",
            "Epoch: 4 | Batch: 42240/100728 (42%) | G Loss: -0.085488 | C Loss: -0.003101\n",
            "Epoch: 4 | Batch: 43520/100728 (43%) | G Loss: -0.079713 | C Loss: -0.012268\n",
            "Epoch: 4 | Batch: 44800/100728 (44%) | G Loss: -0.077683 | C Loss: -0.010836\n",
            "Epoch: 4 | Batch: 46080/100728 (46%) | G Loss: -0.078890 | C Loss: -0.007857\n",
            "Epoch: 4 | Batch: 47360/100728 (47%) | G Loss: -0.079134 | C Loss: 0.000111\n",
            "Epoch: 4 | Batch: 48640/100728 (48%) | G Loss: -0.076216 | C Loss: -0.004805\n",
            "Epoch: 4 | Batch: 49920/100728 (50%) | G Loss: -0.072362 | C Loss: 0.000710\n",
            "Epoch: 4 | Batch: 51200/100728 (51%) | G Loss: -0.076502 | C Loss: 0.023297\n",
            "Epoch: 4 | Batch: 52480/100728 (52%) | G Loss: -0.076391 | C Loss: 0.007808\n",
            "Epoch: 4 | Batch: 53760/100728 (53%) | G Loss: -0.075850 | C Loss: -0.000610\n",
            "Epoch: 4 | Batch: 55040/100728 (55%) | G Loss: -0.072656 | C Loss: -0.001422\n",
            "Epoch: 4 | Batch: 56320/100728 (56%) | G Loss: -0.070874 | C Loss: -0.006414\n",
            "Epoch: 4 | Batch: 57600/100728 (57%) | G Loss: -0.075499 | C Loss: 0.002114\n",
            "Epoch: 4 | Batch: 58880/100728 (58%) | G Loss: -0.075445 | C Loss: -0.005152\n",
            "Epoch: 4 | Batch: 60160/100728 (60%) | G Loss: -0.078399 | C Loss: -0.009182\n",
            "Epoch: 4 | Batch: 61440/100728 (61%) | G Loss: -0.081225 | C Loss: -0.000641\n",
            "Epoch: 4 | Batch: 62720/100728 (62%) | G Loss: -0.081495 | C Loss: -0.005876\n",
            "Epoch: 4 | Batch: 64000/100728 (64%) | G Loss: -0.082929 | C Loss: -0.006909\n",
            "Epoch: 4 | Batch: 65280/100728 (65%) | G Loss: -0.083749 | C Loss: 0.003975\n",
            "Epoch: 4 | Batch: 66560/100728 (66%) | G Loss: -0.089076 | C Loss: 0.022471\n",
            "Epoch: 4 | Batch: 67840/100728 (67%) | G Loss: -0.091903 | C Loss: 0.002912\n",
            "Epoch: 4 | Batch: 69120/100728 (69%) | G Loss: -0.093988 | C Loss: -0.003717\n",
            "Epoch: 4 | Batch: 70400/100728 (70%) | G Loss: -0.094517 | C Loss: -0.005945\n",
            "Epoch: 4 | Batch: 71680/100728 (71%) | G Loss: -0.094704 | C Loss: -0.003761\n",
            "Epoch: 4 | Batch: 72960/100728 (72%) | G Loss: -0.094791 | C Loss: -0.004537\n",
            "Epoch: 4 | Batch: 74240/100728 (74%) | G Loss: -0.095101 | C Loss: 0.028986\n",
            "Epoch: 4 | Batch: 75520/100728 (75%) | G Loss: -0.089762 | C Loss: -0.001332\n",
            "Epoch: 4 | Batch: 76800/100728 (76%) | G Loss: -0.079070 | C Loss: -0.008280\n",
            "Epoch: 4 | Batch: 78080/100728 (78%) | G Loss: -0.068367 | C Loss: -0.018828\n",
            "Epoch: 4 | Batch: 79360/100728 (79%) | G Loss: -0.063132 | C Loss: -0.020395\n",
            "Epoch: 4 | Batch: 80640/100728 (80%) | G Loss: -0.056204 | C Loss: 0.000987\n",
            "Epoch: 4 | Batch: 81920/100728 (81%) | G Loss: -0.058522 | C Loss: -0.008758\n",
            "Epoch: 4 | Batch: 83200/100728 (83%) | G Loss: -0.060716 | C Loss: -0.012984\n",
            "Epoch: 4 | Batch: 84480/100728 (84%) | G Loss: -0.060481 | C Loss: -0.011724\n",
            "Epoch: 4 | Batch: 85760/100728 (85%) | G Loss: -0.061641 | C Loss: -0.012868\n",
            "Epoch: 4 | Batch: 87040/100728 (86%) | G Loss: -0.062851 | C Loss: -0.009991\n",
            "Epoch: 4 | Batch: 88320/100728 (88%) | G Loss: -0.066489 | C Loss: -0.008825\n",
            "Epoch: 4 | Batch: 89600/100728 (89%) | G Loss: -0.070842 | C Loss: -0.008371\n",
            "Epoch: 4 | Batch: 90880/100728 (90%) | G Loss: -0.075752 | C Loss: -0.005255\n",
            "Epoch: 4 | Batch: 92160/100728 (91%) | G Loss: -0.080118 | C Loss: -0.002564\n",
            "Epoch: 4 | Batch: 93440/100728 (93%) | G Loss: -0.082291 | C Loss: -0.003967\n",
            "Epoch: 4 | Batch: 94720/100728 (94%) | G Loss: -0.083139 | C Loss: 0.005538\n",
            "Epoch: 4 | Batch: 96000/100728 (95%) | G Loss: -0.085569 | C Loss: 0.000249\n",
            "Epoch: 4 | Batch: 97280/100728 (97%) | G Loss: -0.088620 | C Loss: -0.002967\n",
            "Epoch: 4 | Batch: 98560/100728 (98%) | G Loss: -0.088400 | C Loss: -0.005914\n",
            "Epoch: 4 | Batch: 99840/100728 (99%) | G Loss: -0.087003 | C Loss: -0.005947\n",
            "* (Train) Epoch: 4 | G Loss: -0.0786 | C Loss: -0.0019\n",
            " why do you have like about arguing in light ? a switch ? a switch ?\n",
            " what does the frustrated teenager had a fat low in ? a quarter bagin .\n",
            " what is pour decision as an african fruit in a crowded ? a slight chuckle result .\n",
            " how if someone likes algebra out ? a neighbor replies algebra replies ? neighbor ?\n",
            " what do an simple longer and a lit benedict forgets machine pump forgets machine pump piggy\n",
            " what swear can you have a dragonsty out during the dragon machine ? because elephants\n",
            " misses potatoes can get during the eyes shaped asses shaped eyes out a woman no longer\n",
            " if what does a cannibal and an african cha in and consuming ? to get a dead in\n",
            " what had would . then then had an arctic ? ? a rental wanking then ? ? trampoline ?\n",
            " anyone had a white fat look fat and anyone have an fat ?\n",
            "\n",
            "Epoch: 5 | Batch: 0/100728 (0%) | G Loss: -0.089531 | C Loss: -0.008333\n",
            "Epoch: 5 | Batch: 1280/100728 (1%) | G Loss: -0.088282 | C Loss: -0.003485\n",
            "Epoch: 5 | Batch: 2560/100728 (3%) | G Loss: -0.089055 | C Loss: -0.013615\n",
            "Epoch: 5 | Batch: 3840/100728 (4%) | G Loss: -0.087554 | C Loss: -0.016320\n",
            "Epoch: 5 | Batch: 5120/100728 (5%) | G Loss: -0.089508 | C Loss: -0.006135\n",
            "Epoch: 5 | Batch: 6400/100728 (6%) | G Loss: -0.093556 | C Loss: -0.001531\n",
            "Epoch: 5 | Batch: 7680/100728 (8%) | G Loss: -0.096326 | C Loss: -0.003492\n",
            "Epoch: 5 | Batch: 8960/100728 (9%) | G Loss: -0.099439 | C Loss: -0.002428\n",
            "Epoch: 5 | Batch: 10240/100728 (10%) | G Loss: -0.103516 | C Loss: -0.004307\n",
            "Epoch: 5 | Batch: 11520/100728 (11%) | G Loss: -0.106099 | C Loss: 0.002278\n",
            "Epoch: 5 | Batch: 12800/100728 (13%) | G Loss: -0.104281 | C Loss: -0.001604\n",
            "Epoch: 5 | Batch: 14080/100728 (14%) | G Loss: -0.101453 | C Loss: -0.004448\n",
            "Epoch: 5 | Batch: 15360/100728 (15%) | G Loss: -0.095749 | C Loss: -0.006133\n",
            "Epoch: 5 | Batch: 16640/100728 (17%) | G Loss: -0.087679 | C Loss: 0.008369\n",
            "Epoch: 5 | Batch: 17920/100728 (18%) | G Loss: -0.085668 | C Loss: -0.002838\n",
            "Epoch: 5 | Batch: 19200/100728 (19%) | G Loss: -0.085360 | C Loss: -0.003116\n",
            "Epoch: 5 | Batch: 20480/100728 (20%) | G Loss: -0.085045 | C Loss: -0.010784\n",
            "Epoch: 5 | Batch: 21760/100728 (22%) | G Loss: -0.085303 | C Loss: -0.000182\n",
            "Epoch: 5 | Batch: 23040/100728 (23%) | G Loss: -0.084464 | C Loss: -0.007752\n",
            "Epoch: 5 | Batch: 24320/100728 (24%) | G Loss: -0.085588 | C Loss: -0.009821\n",
            "Epoch: 5 | Batch: 25600/100728 (25%) | G Loss: -0.086829 | C Loss: -0.011758\n",
            "Epoch: 5 | Batch: 26880/100728 (27%) | G Loss: -0.088109 | C Loss: 0.008456\n",
            "Epoch: 5 | Batch: 28160/100728 (28%) | G Loss: -0.092825 | C Loss: 0.004964\n",
            "Epoch: 5 | Batch: 29440/100728 (29%) | G Loss: -0.094981 | C Loss: -0.005140\n",
            "Epoch: 5 | Batch: 30720/100728 (30%) | G Loss: -0.092700 | C Loss: -0.004113\n",
            "Epoch: 5 | Batch: 32000/100728 (32%) | G Loss: -0.089398 | C Loss: 0.051249\n",
            "Epoch: 5 | Batch: 33280/100728 (33%) | G Loss: -0.094088 | C Loss: 0.019682\n",
            "Epoch: 5 | Batch: 34560/100728 (34%) | G Loss: -0.094225 | C Loss: 0.031168\n",
            "Epoch: 5 | Batch: 35840/100728 (36%) | G Loss: -0.096339 | C Loss: 0.025990\n",
            "Epoch: 5 | Batch: 37120/100728 (37%) | G Loss: -0.096182 | C Loss: 0.009520\n",
            "Epoch: 5 | Batch: 38400/100728 (38%) | G Loss: -0.090653 | C Loss: -0.003021\n",
            "Epoch: 5 | Batch: 39680/100728 (39%) | G Loss: -0.083651 | C Loss: -0.008391\n",
            "Epoch: 5 | Batch: 40960/100728 (41%) | G Loss: -0.079385 | C Loss: 0.005040\n",
            "Epoch: 5 | Batch: 42240/100728 (42%) | G Loss: -0.078252 | C Loss: -0.005908\n",
            "Epoch: 5 | Batch: 43520/100728 (43%) | G Loss: -0.073093 | C Loss: -0.010339\n",
            "Epoch: 5 | Batch: 44800/100728 (44%) | G Loss: -0.067082 | C Loss: -0.012582\n",
            "Epoch: 5 | Batch: 46080/100728 (46%) | G Loss: -0.059896 | C Loss: -0.017799\n",
            "Epoch: 5 | Batch: 47360/100728 (47%) | G Loss: -0.059944 | C Loss: 0.003090\n",
            "Epoch: 5 | Batch: 48640/100728 (48%) | G Loss: -0.063188 | C Loss: -0.017753\n",
            "Epoch: 5 | Batch: 49920/100728 (50%) | G Loss: -0.068638 | C Loss: -0.017925\n",
            "Epoch: 5 | Batch: 51200/100728 (51%) | G Loss: -0.076139 | C Loss: -0.015807\n",
            "Epoch: 5 | Batch: 52480/100728 (52%) | G Loss: -0.080874 | C Loss: -0.013790\n",
            "Epoch: 5 | Batch: 53760/100728 (53%) | G Loss: -0.084654 | C Loss: -0.010849\n",
            "Epoch: 5 | Batch: 55040/100728 (55%) | G Loss: -0.088223 | C Loss: -0.006429\n",
            "Epoch: 5 | Batch: 56320/100728 (56%) | G Loss: -0.091283 | C Loss: -0.008120\n",
            "Epoch: 5 | Batch: 57600/100728 (57%) | G Loss: -0.094135 | C Loss: -0.002253\n",
            "Epoch: 5 | Batch: 58880/100728 (58%) | G Loss: -0.099404 | C Loss: -0.004663\n",
            "Epoch: 5 | Batch: 60160/100728 (60%) | G Loss: -0.101810 | C Loss: -0.003595\n",
            "Epoch: 5 | Batch: 61440/100728 (61%) | G Loss: -0.101202 | C Loss: -0.000727\n",
            "Epoch: 5 | Batch: 62720/100728 (62%) | G Loss: -0.097862 | C Loss: -0.006493\n",
            "Epoch: 5 | Batch: 64000/100728 (64%) | G Loss: -0.093989 | C Loss: -0.009692\n",
            "Epoch: 5 | Batch: 65280/100728 (65%) | G Loss: -0.092475 | C Loss: -0.002431\n",
            "Epoch: 5 | Batch: 66560/100728 (66%) | G Loss: -0.089506 | C Loss: -0.002347\n",
            "Epoch: 5 | Batch: 67840/100728 (67%) | G Loss: -0.089031 | C Loss: -0.006740\n",
            "Epoch: 5 | Batch: 69120/100728 (69%) | G Loss: -0.087196 | C Loss: -0.007112\n",
            "Epoch: 5 | Batch: 70400/100728 (70%) | G Loss: -0.083732 | C Loss: -0.009478\n",
            "Epoch: 5 | Batch: 71680/100728 (71%) | G Loss: -0.080692 | C Loss: 0.009168\n",
            "Epoch: 5 | Batch: 72960/100728 (72%) | G Loss: -0.078699 | C Loss: -0.009697\n",
            "Epoch: 5 | Batch: 74240/100728 (74%) | G Loss: -0.077646 | C Loss: -0.006405\n",
            "Epoch: 5 | Batch: 75520/100728 (75%) | G Loss: -0.076143 | C Loss: -0.011532\n",
            "Epoch: 5 | Batch: 76800/100728 (76%) | G Loss: -0.074983 | C Loss: -0.005536\n",
            "Epoch: 5 | Batch: 78080/100728 (78%) | G Loss: -0.071984 | C Loss: -0.000736\n",
            "Epoch: 5 | Batch: 79360/100728 (79%) | G Loss: -0.070890 | C Loss: -0.009113\n",
            "Epoch: 5 | Batch: 80640/100728 (80%) | G Loss: -0.069062 | C Loss: -0.007325\n",
            "Epoch: 5 | Batch: 81920/100728 (81%) | G Loss: -0.066364 | C Loss: -0.010819\n",
            "Epoch: 5 | Batch: 83200/100728 (83%) | G Loss: -0.065273 | C Loss: -0.012601\n",
            "Epoch: 5 | Batch: 84480/100728 (84%) | G Loss: -0.063847 | C Loss: -0.010617\n",
            "Epoch: 5 | Batch: 85760/100728 (85%) | G Loss: -0.064563 | C Loss: -0.013870\n",
            "Epoch: 5 | Batch: 87040/100728 (86%) | G Loss: -0.066256 | C Loss: -0.010622\n",
            "Epoch: 5 | Batch: 88320/100728 (88%) | G Loss: -0.066430 | C Loss: 0.014745\n",
            "Epoch: 5 | Batch: 89600/100728 (89%) | G Loss: -0.069118 | C Loss: 0.010945\n",
            "Epoch: 5 | Batch: 90880/100728 (90%) | G Loss: -0.071644 | C Loss: 0.000616\n",
            "Epoch: 5 | Batch: 92160/100728 (91%) | G Loss: -0.071546 | C Loss: -0.005096\n",
            "Epoch: 5 | Batch: 93440/100728 (93%) | G Loss: -0.073081 | C Loss: -0.002772\n",
            "Epoch: 5 | Batch: 94720/100728 (94%) | G Loss: -0.072696 | C Loss: 0.048561\n",
            "Epoch: 5 | Batch: 96000/100728 (95%) | G Loss: -0.079422 | C Loss: 0.032771\n",
            "Epoch: 5 | Batch: 97280/100728 (97%) | G Loss: -0.087889 | C Loss: 0.025408\n",
            "Epoch: 5 | Batch: 98560/100728 (98%) | G Loss: -0.088187 | C Loss: -0.008262\n",
            "Epoch: 5 | Batch: 99840/100728 (99%) | G Loss: -0.085251 | C Loss: -0.006749\n",
            "* (Train) Epoch: 5 | G Loss: -0.0841 | C Loss: -0.0007\n",
            " school class what did vincent say during the class interview when he graduated out his class . he would need his patlostomy class\n",
            " blonde grade class and frustrated and frustrated . he has in common when i leave his house , i both know what .\n",
            " ate from her dry and iron woman touching her underpants ? her get her sweet from her .\n",
            " i ever see the and stoner and his neighbor kicked out of home , i would be close , i would have been close in her\n",
            " i accidentally kidnapped a cosby cosby cosby cosby cosby cosby cosby the difference between jack and mary jane ate you shall have turned deeply .\n",
            " all i did the trampoline who won in round shop yesterday ? they all ackbar performance in his own greece boss\n",
            " stoner piggy stoner know what he grows in his own sentence during his own sentence ? because his own bad drug , because he checks his own\n",
            " mom and ooan has been dead because he was dead in theduction of dead men because he is dead in theduction from dead\n",
            "ologist ? what ? the mall . he thought he was a bad time and thought he was way\n",
            " knives , and anyone comes in the male , and anyone get stabbed in anyone and blow me in the sentence and anyone gets stabbed in anyone and anyone\n",
            "\n",
            "Epoch: 6 | Batch: 0/100728 (0%) | G Loss: -0.087623 | C Loss: -0.009291\n",
            "Epoch: 6 | Batch: 1280/100728 (1%) | G Loss: -0.089241 | C Loss: -0.010498\n",
            "Epoch: 6 | Batch: 2560/100728 (3%) | G Loss: -0.090234 | C Loss: -0.009206\n",
            "Epoch: 6 | Batch: 3840/100728 (4%) | G Loss: -0.090818 | C Loss: -0.008245\n",
            "Epoch: 6 | Batch: 5120/100728 (5%) | G Loss: -0.092617 | C Loss: -0.006401\n",
            "Epoch: 6 | Batch: 6400/100728 (6%) | G Loss: -0.095042 | C Loss: -0.000856\n",
            "Epoch: 6 | Batch: 7680/100728 (8%) | G Loss: -0.094884 | C Loss: -0.006284\n",
            "Epoch: 6 | Batch: 8960/100728 (9%) | G Loss: -0.093778 | C Loss: -0.008267\n",
            "Epoch: 6 | Batch: 10240/100728 (10%) | G Loss: -0.088090 | C Loss: -0.009316\n",
            "Epoch: 6 | Batch: 11520/100728 (11%) | G Loss: -0.081210 | C Loss: -0.009806\n",
            "Epoch: 6 | Batch: 12800/100728 (13%) | G Loss: -0.080762 | C Loss: -0.008715\n",
            "Epoch: 6 | Batch: 14080/100728 (14%) | G Loss: -0.079265 | C Loss: -0.014310\n",
            "Epoch: 6 | Batch: 15360/100728 (15%) | G Loss: -0.080583 | C Loss: -0.008237\n",
            "Epoch: 6 | Batch: 16640/100728 (17%) | G Loss: -0.079498 | C Loss: -0.008871\n",
            "Epoch: 6 | Batch: 17920/100728 (18%) | G Loss: -0.079440 | C Loss: -0.012345\n",
            "Epoch: 6 | Batch: 19200/100728 (19%) | G Loss: -0.078452 | C Loss: 0.019024\n",
            "Epoch: 6 | Batch: 20480/100728 (20%) | G Loss: -0.086195 | C Loss: -0.008344\n",
            "Epoch: 6 | Batch: 21760/100728 (22%) | G Loss: -0.087697 | C Loss: -0.006279\n",
            "Epoch: 6 | Batch: 23040/100728 (23%) | G Loss: -0.089493 | C Loss: -0.005964\n",
            "Epoch: 6 | Batch: 24320/100728 (24%) | G Loss: -0.090368 | C Loss: -0.005064\n",
            "Epoch: 6 | Batch: 25600/100728 (25%) | G Loss: -0.088190 | C Loss: 0.014810\n",
            "Epoch: 6 | Batch: 26880/100728 (27%) | G Loss: -0.087231 | C Loss: -0.005122\n",
            "Epoch: 6 | Batch: 28160/100728 (28%) | G Loss: -0.088443 | C Loss: 0.126998\n",
            "Epoch: 6 | Batch: 29440/100728 (29%) | G Loss: -0.096447 | C Loss: 0.005448\n",
            "Epoch: 6 | Batch: 30720/100728 (30%) | G Loss: -0.092809 | C Loss: -0.002351\n",
            "Epoch: 6 | Batch: 32000/100728 (32%) | G Loss: -0.088797 | C Loss: -0.008399\n",
            "Epoch: 6 | Batch: 33280/100728 (33%) | G Loss: -0.085449 | C Loss: -0.009245\n",
            "Epoch: 6 | Batch: 34560/100728 (34%) | G Loss: -0.083191 | C Loss: -0.009622\n",
            "Epoch: 6 | Batch: 35840/100728 (36%) | G Loss: -0.080417 | C Loss: -0.008685\n",
            "Epoch: 6 | Batch: 37120/100728 (37%) | G Loss: -0.073633 | C Loss: -0.012117\n",
            "Epoch: 6 | Batch: 38400/100728 (38%) | G Loss: -0.067133 | C Loss: -0.011919\n",
            "Epoch: 6 | Batch: 39680/100728 (39%) | G Loss: -0.064935 | C Loss: 0.006049\n",
            "Epoch: 6 | Batch: 40960/100728 (41%) | G Loss: -0.067485 | C Loss: -0.010330\n",
            "Epoch: 6 | Batch: 42240/100728 (42%) | G Loss: -0.071886 | C Loss: -0.014631\n",
            "Epoch: 6 | Batch: 43520/100728 (43%) | G Loss: -0.076459 | C Loss: -0.008180\n",
            "Epoch: 6 | Batch: 44800/100728 (44%) | G Loss: -0.079709 | C Loss: -0.011805\n",
            "Epoch: 6 | Batch: 46080/100728 (46%) | G Loss: -0.080741 | C Loss: 0.013184\n",
            "Epoch: 6 | Batch: 47360/100728 (47%) | G Loss: -0.083339 | C Loss: -0.008178\n",
            "Epoch: 6 | Batch: 48640/100728 (48%) | G Loss: -0.086057 | C Loss: -0.008425\n",
            "Epoch: 6 | Batch: 49920/100728 (50%) | G Loss: -0.088011 | C Loss: -0.002336\n",
            "Epoch: 6 | Batch: 51200/100728 (51%) | G Loss: -0.088495 | C Loss: -0.005485\n",
            "Epoch: 6 | Batch: 52480/100728 (52%) | G Loss: -0.087894 | C Loss: -0.003864\n",
            "Epoch: 6 | Batch: 53760/100728 (53%) | G Loss: -0.088713 | C Loss: -0.003785\n",
            "Epoch: 6 | Batch: 55040/100728 (55%) | G Loss: -0.089140 | C Loss: 0.001017\n",
            "Epoch: 6 | Batch: 56320/100728 (56%) | G Loss: -0.090740 | C Loss: 0.000664\n",
            "Epoch: 6 | Batch: 57600/100728 (57%) | G Loss: -0.088758 | C Loss: -0.005846\n",
            "Epoch: 6 | Batch: 58880/100728 (58%) | G Loss: -0.089821 | C Loss: -0.005261\n",
            "Epoch: 6 | Batch: 60160/100728 (60%) | G Loss: -0.089884 | C Loss: -0.005843\n",
            "Epoch: 6 | Batch: 61440/100728 (61%) | G Loss: -0.088363 | C Loss: -0.007123\n",
            "Epoch: 6 | Batch: 62720/100728 (62%) | G Loss: -0.087621 | C Loss: -0.006268\n",
            "Epoch: 6 | Batch: 64000/100728 (64%) | G Loss: -0.086330 | C Loss: -0.006395\n",
            "Epoch: 6 | Batch: 65280/100728 (65%) | G Loss: -0.083829 | C Loss: -0.004196\n",
            "Epoch: 6 | Batch: 66560/100728 (66%) | G Loss: -0.080361 | C Loss: -0.006099\n",
            "Epoch: 6 | Batch: 67840/100728 (67%) | G Loss: -0.079719 | C Loss: -0.002217\n",
            "Epoch: 6 | Batch: 69120/100728 (69%) | G Loss: -0.077123 | C Loss: -0.006270\n",
            "Epoch: 6 | Batch: 70400/100728 (70%) | G Loss: -0.075690 | C Loss: 0.000934\n",
            "Epoch: 6 | Batch: 71680/100728 (71%) | G Loss: -0.076069 | C Loss: -0.006662\n",
            "Epoch: 6 | Batch: 72960/100728 (72%) | G Loss: -0.076367 | C Loss: 0.006425\n",
            "Epoch: 6 | Batch: 74240/100728 (74%) | G Loss: -0.078465 | C Loss: -0.010338\n",
            "Epoch: 6 | Batch: 75520/100728 (75%) | G Loss: -0.079059 | C Loss: -0.012306\n",
            "Epoch: 6 | Batch: 76800/100728 (76%) | G Loss: -0.080258 | C Loss: 0.005750\n",
            "Epoch: 6 | Batch: 78080/100728 (78%) | G Loss: -0.080198 | C Loss: -0.016402\n",
            "Epoch: 6 | Batch: 79360/100728 (79%) | G Loss: -0.083704 | C Loss: -0.014314\n",
            "Epoch: 6 | Batch: 80640/100728 (80%) | G Loss: -0.085770 | C Loss: -0.012719\n",
            "Epoch: 6 | Batch: 81920/100728 (81%) | G Loss: -0.086445 | C Loss: -0.004495\n",
            "Epoch: 6 | Batch: 83200/100728 (83%) | G Loss: -0.088432 | C Loss: -0.010017\n",
            "Epoch: 6 | Batch: 84480/100728 (84%) | G Loss: -0.087929 | C Loss: -0.010611\n",
            "Epoch: 6 | Batch: 85760/100728 (85%) | G Loss: -0.086455 | C Loss: -0.008912\n",
            "Epoch: 6 | Batch: 87040/100728 (86%) | G Loss: -0.082210 | C Loss: -0.002625\n",
            "Epoch: 6 | Batch: 88320/100728 (88%) | G Loss: -0.079890 | C Loss: 0.000624\n",
            "Epoch: 6 | Batch: 89600/100728 (89%) | G Loss: -0.076452 | C Loss: -0.005621\n",
            "Epoch: 6 | Batch: 90880/100728 (90%) | G Loss: -0.072254 | C Loss: -0.005099\n",
            "Epoch: 6 | Batch: 92160/100728 (91%) | G Loss: -0.065777 | C Loss: 0.019475\n",
            "Epoch: 6 | Batch: 93440/100728 (93%) | G Loss: -0.067205 | C Loss: -0.000425\n",
            "Epoch: 6 | Batch: 94720/100728 (94%) | G Loss: -0.067719 | C Loss: -0.002154\n",
            "Epoch: 6 | Batch: 96000/100728 (95%) | G Loss: -0.066709 | C Loss: 0.018217\n",
            "Epoch: 6 | Batch: 97280/100728 (97%) | G Loss: -0.063539 | C Loss: -0.003595\n",
            "Epoch: 6 | Batch: 98560/100728 (98%) | G Loss: -0.063179 | C Loss: -0.005128\n",
            "Epoch: 6 | Batch: 99840/100728 (99%) | G Loss: -0.063777 | C Loss: -0.006976\n",
            "* (Train) Epoch: 6 | G Loss: -0.0822 | C Loss: -0.0020\n",
            " what are people in this rvulation this light bulb ? scientist this to hold this .\n",
            " what many operating system wasn ' t you to blow his house as a blow job ?\n",
            " heroin as the day are double boring to double boring player double doubleble double .\n",
            " igon upgrade kanye west temperature are you a joke as you can close a joke\n",
            " did serious turkish insp fallout ? as he locked himself to ice as .\n",
            " i can ban this orphans as this as this wasn ' t this banugee .\n",
            " i love parallel lines so what to get to any other than a bad life ? he is not .\n",
            " what hot meth wasn ' t his blood ? as he wasn t to crack itself .\n",
            " basketball he thought he was his way to go as he he thought he .\n",
            " merry turkish ? jean . edit to anyone duct . edit ? jeff ? crimea river\n",
            "\n",
            "Epoch: 7 | Batch: 0/100728 (0%) | G Loss: -0.067272 | C Loss: -0.006900\n",
            "Epoch: 7 | Batch: 1280/100728 (1%) | G Loss: -0.069526 | C Loss: -0.004590\n",
            "Epoch: 7 | Batch: 2560/100728 (3%) | G Loss: -0.074762 | C Loss: -0.003687\n",
            "Epoch: 7 | Batch: 3840/100728 (4%) | G Loss: -0.079270 | C Loss: -0.006207\n",
            "Epoch: 7 | Batch: 5120/100728 (5%) | G Loss: -0.086453 | C Loss: 0.007294\n",
            "Epoch: 7 | Batch: 6400/100728 (6%) | G Loss: -0.088963 | C Loss: -0.008579\n",
            "Epoch: 7 | Batch: 7680/100728 (8%) | G Loss: -0.090165 | C Loss: -0.011338\n",
            "Epoch: 7 | Batch: 8960/100728 (9%) | G Loss: -0.088215 | C Loss: -0.010438\n",
            "Epoch: 7 | Batch: 10240/100728 (10%) | G Loss: -0.086518 | C Loss: -0.009178\n",
            "Epoch: 7 | Batch: 11520/100728 (11%) | G Loss: -0.085021 | C Loss: -0.008489\n",
            "Epoch: 7 | Batch: 12800/100728 (13%) | G Loss: -0.082023 | C Loss: -0.007383\n",
            "Epoch: 7 | Batch: 14080/100728 (14%) | G Loss: -0.081110 | C Loss: -0.005038\n",
            "Epoch: 7 | Batch: 15360/100728 (15%) | G Loss: -0.078303 | C Loss: -0.006677\n",
            "Epoch: 7 | Batch: 16640/100728 (17%) | G Loss: -0.073738 | C Loss: 0.023262\n",
            "Epoch: 7 | Batch: 17920/100728 (18%) | G Loss: -0.073247 | C Loss: -0.001163\n",
            "Epoch: 7 | Batch: 19200/100728 (19%) | G Loss: -0.068664 | C Loss: 0.000283\n",
            "Epoch: 7 | Batch: 20480/100728 (20%) | G Loss: -0.069127 | C Loss: -0.008656\n",
            "Epoch: 7 | Batch: 21760/100728 (22%) | G Loss: -0.070382 | C Loss: -0.016258\n",
            "Epoch: 7 | Batch: 23040/100728 (23%) | G Loss: -0.075474 | C Loss: -0.015002\n",
            "Epoch: 7 | Batch: 24320/100728 (24%) | G Loss: -0.079116 | C Loss: -0.012846\n",
            "Epoch: 7 | Batch: 25600/100728 (25%) | G Loss: -0.082670 | C Loss: -0.001812\n",
            "Epoch: 7 | Batch: 26880/100728 (27%) | G Loss: -0.085007 | C Loss: -0.007530\n",
            "Epoch: 7 | Batch: 28160/100728 (28%) | G Loss: -0.086074 | C Loss: -0.010010\n",
            "Epoch: 7 | Batch: 29440/100728 (29%) | G Loss: -0.084699 | C Loss: 0.013412\n",
            "Epoch: 7 | Batch: 30720/100728 (30%) | G Loss: -0.088128 | C Loss: -0.008108\n",
            "Epoch: 7 | Batch: 32000/100728 (32%) | G Loss: -0.089330 | C Loss: -0.005023\n",
            "Epoch: 7 | Batch: 33280/100728 (33%) | G Loss: -0.088560 | C Loss: -0.002906\n",
            "Epoch: 7 | Batch: 34560/100728 (34%) | G Loss: -0.089368 | C Loss: -0.006272\n",
            "Epoch: 7 | Batch: 35840/100728 (36%) | G Loss: -0.089942 | C Loss: -0.005335\n",
            "Epoch: 7 | Batch: 37120/100728 (37%) | G Loss: -0.089344 | C Loss: -0.004363\n",
            "Epoch: 7 | Batch: 38400/100728 (38%) | G Loss: -0.090666 | C Loss: 0.000712\n",
            "Epoch: 7 | Batch: 39680/100728 (39%) | G Loss: -0.095305 | C Loss: 0.007886\n",
            "Epoch: 7 | Batch: 40960/100728 (41%) | G Loss: -0.095660 | C Loss: 0.002337\n",
            "Epoch: 7 | Batch: 42240/100728 (42%) | G Loss: -0.096806 | C Loss: 0.000773\n",
            "Epoch: 7 | Batch: 43520/100728 (43%) | G Loss: -0.096009 | C Loss: -0.008587\n",
            "Epoch: 7 | Batch: 44800/100728 (44%) | G Loss: -0.093565 | C Loss: -0.009079\n",
            "Epoch: 7 | Batch: 46080/100728 (46%) | G Loss: -0.094307 | C Loss: 0.044818\n",
            "Epoch: 7 | Batch: 47360/100728 (47%) | G Loss: -0.095222 | C Loss: 0.009217\n",
            "Epoch: 7 | Batch: 48640/100728 (48%) | G Loss: -0.095812 | C Loss: -0.008419\n",
            "Epoch: 7 | Batch: 49920/100728 (50%) | G Loss: -0.096002 | C Loss: -0.005500\n",
            "Epoch: 7 | Batch: 51200/100728 (51%) | G Loss: -0.095150 | C Loss: -0.005429\n",
            "Epoch: 7 | Batch: 52480/100728 (52%) | G Loss: -0.094007 | C Loss: -0.006421\n",
            "Epoch: 7 | Batch: 53760/100728 (53%) | G Loss: -0.092922 | C Loss: -0.006980\n",
            "Epoch: 7 | Batch: 55040/100728 (55%) | G Loss: -0.091346 | C Loss: -0.004390\n",
            "Epoch: 7 | Batch: 56320/100728 (56%) | G Loss: -0.088437 | C Loss: -0.007665\n",
            "Epoch: 7 | Batch: 57600/100728 (57%) | G Loss: -0.084315 | C Loss: -0.008151\n",
            "Epoch: 7 | Batch: 58880/100728 (58%) | G Loss: -0.080199 | C Loss: -0.007395\n",
            "Epoch: 7 | Batch: 60160/100728 (60%) | G Loss: -0.075951 | C Loss: -0.006619\n",
            "Epoch: 7 | Batch: 61440/100728 (61%) | G Loss: -0.071602 | C Loss: -0.005770\n",
            "Epoch: 7 | Batch: 62720/100728 (62%) | G Loss: -0.067148 | C Loss: 0.003943\n",
            "Epoch: 7 | Batch: 64000/100728 (64%) | G Loss: -0.064185 | C Loss: -0.011146\n",
            "Epoch: 7 | Batch: 65280/100728 (65%) | G Loss: -0.060532 | C Loss: -0.013876\n",
            "Epoch: 7 | Batch: 66560/100728 (66%) | G Loss: -0.061422 | C Loss: -0.014941\n",
            "Epoch: 7 | Batch: 67840/100728 (67%) | G Loss: -0.062247 | C Loss: 0.003815\n",
            "Epoch: 7 | Batch: 69120/100728 (69%) | G Loss: -0.066385 | C Loss: 0.014269\n",
            "Epoch: 7 | Batch: 70400/100728 (70%) | G Loss: -0.073679 | C Loss: -0.010110\n",
            "Epoch: 7 | Batch: 71680/100728 (71%) | G Loss: -0.076513 | C Loss: -0.009322\n",
            "Epoch: 7 | Batch: 72960/100728 (72%) | G Loss: -0.080621 | C Loss: -0.008610\n",
            "Epoch: 7 | Batch: 74240/100728 (74%) | G Loss: -0.082361 | C Loss: -0.003453\n",
            "Epoch: 7 | Batch: 75520/100728 (75%) | G Loss: -0.086663 | C Loss: -0.007454\n",
            "Epoch: 7 | Batch: 76800/100728 (76%) | G Loss: -0.089390 | C Loss: 0.004124\n",
            "Epoch: 7 | Batch: 78080/100728 (78%) | G Loss: -0.094419 | C Loss: 0.008611\n",
            "Epoch: 7 | Batch: 79360/100728 (79%) | G Loss: -0.098232 | C Loss: -0.002389\n",
            "Epoch: 7 | Batch: 80640/100728 (80%) | G Loss: -0.098893 | C Loss: -0.003192\n",
            "Epoch: 7 | Batch: 81920/100728 (81%) | G Loss: -0.096469 | C Loss: 0.002579\n",
            "Epoch: 7 | Batch: 83200/100728 (83%) | G Loss: -0.094449 | C Loss: -0.001619\n",
            "Epoch: 7 | Batch: 84480/100728 (84%) | G Loss: -0.093111 | C Loss: 0.013305\n",
            "Epoch: 7 | Batch: 85760/100728 (85%) | G Loss: -0.090867 | C Loss: 0.012178\n",
            "Epoch: 7 | Batch: 87040/100728 (86%) | G Loss: -0.086372 | C Loss: -0.004180\n",
            "Epoch: 7 | Batch: 88320/100728 (88%) | G Loss: -0.081409 | C Loss: -0.010152\n",
            "Epoch: 7 | Batch: 89600/100728 (89%) | G Loss: -0.077956 | C Loss: -0.002391\n",
            "Epoch: 7 | Batch: 90880/100728 (90%) | G Loss: -0.075905 | C Loss: -0.012835\n",
            "Epoch: 7 | Batch: 92160/100728 (91%) | G Loss: -0.076806 | C Loss: -0.003374\n",
            "Epoch: 7 | Batch: 93440/100728 (93%) | G Loss: -0.080231 | C Loss: -0.003325\n",
            "Epoch: 7 | Batch: 94720/100728 (94%) | G Loss: -0.081265 | C Loss: -0.005537\n",
            "Epoch: 7 | Batch: 96000/100728 (95%) | G Loss: -0.080783 | C Loss: -0.012561\n",
            "Epoch: 7 | Batch: 97280/100728 (97%) | G Loss: -0.083753 | C Loss: -0.010521\n",
            "Epoch: 7 | Batch: 98560/100728 (98%) | G Loss: -0.086242 | C Loss: -0.004444\n",
            "Epoch: 7 | Batch: 99840/100728 (99%) | G Loss: -0.088624 | C Loss: -0.006254\n",
            "* (Train) Epoch: 7 | G Loss: -0.0837 | C Loss: -0.0015\n",
            " what and sometimes santa claus are arguing in walking pass too hard to turn them too hard he doublepe double hard\n",
            " what is the difference and shiransess ? a lot was to blow her\n",
            " what and father gets in circles ? a woman are both a woman who is a day\n",
            " nsfw what would only be when they turned down and turned down to the home with 3 trees as a joke\n",
            " what is a sexist tampon about the group with a group has to rob a soul ? .\n",
            " what is an expensive and a foot fetishist has to castrate by a soccer player ? marco stakes\n",
            " what are with a misore in the eyes that way ? is a way to stay\n",
            " i was a lot like and has been dead and confirmed that is dead\n",
            " what is in a jigsaw and a narcissists are walking down the mall walking down a mall and airplanes ? walking downs\n",
            " i ' m just moved up a sleeping pills has a sore losers . they are to stop stealing a little mountain .\n",
            "\n",
            "Epoch: 8 | Batch: 0/100728 (0%) | G Loss: -0.091492 | C Loss: -0.001306\n",
            "Epoch: 8 | Batch: 1280/100728 (1%) | G Loss: -0.092502 | C Loss: -0.004787\n",
            "Epoch: 8 | Batch: 2560/100728 (3%) | G Loss: -0.092264 | C Loss: -0.002790\n",
            "Epoch: 8 | Batch: 3840/100728 (4%) | G Loss: -0.093984 | C Loss: -0.000610\n",
            "Epoch: 8 | Batch: 5120/100728 (5%) | G Loss: -0.088082 | C Loss: -0.004678\n",
            "Epoch: 8 | Batch: 6400/100728 (6%) | G Loss: -0.081981 | C Loss: -0.009051\n",
            "Epoch: 8 | Batch: 7680/100728 (8%) | G Loss: -0.079467 | C Loss: 0.004280\n",
            "Epoch: 8 | Batch: 8960/100728 (9%) | G Loss: -0.080509 | C Loss: 0.022838\n",
            "Epoch: 8 | Batch: 10240/100728 (10%) | G Loss: -0.085588 | C Loss: -0.000133\n",
            "Epoch: 8 | Batch: 11520/100728 (11%) | G Loss: -0.085829 | C Loss: 0.010534\n",
            "Epoch: 8 | Batch: 12800/100728 (13%) | G Loss: -0.089629 | C Loss: -0.007795\n",
            "Epoch: 8 | Batch: 14080/100728 (14%) | G Loss: -0.091692 | C Loss: -0.007475\n",
            "Epoch: 8 | Batch: 15360/100728 (15%) | G Loss: -0.096288 | C Loss: 0.020020\n",
            "Epoch: 8 | Batch: 16640/100728 (17%) | G Loss: -0.097618 | C Loss: -0.003257\n",
            "Epoch: 8 | Batch: 17920/100728 (18%) | G Loss: -0.101267 | C Loss: -0.003013\n",
            "Epoch: 8 | Batch: 19200/100728 (19%) | G Loss: -0.103615 | C Loss: 0.002308\n",
            "Epoch: 8 | Batch: 20480/100728 (20%) | G Loss: -0.104806 | C Loss: 0.008463\n",
            "Epoch: 8 | Batch: 21760/100728 (22%) | G Loss: -0.102963 | C Loss: -0.004192\n",
            "Epoch: 8 | Batch: 23040/100728 (23%) | G Loss: -0.101362 | C Loss: -0.005322\n",
            "Epoch: 8 | Batch: 24320/100728 (24%) | G Loss: -0.096722 | C Loss: -0.003364\n",
            "Epoch: 8 | Batch: 25600/100728 (25%) | G Loss: -0.091115 | C Loss: -0.009064\n",
            "Epoch: 8 | Batch: 26880/100728 (27%) | G Loss: -0.083329 | C Loss: -0.006031\n",
            "Epoch: 8 | Batch: 28160/100728 (28%) | G Loss: -0.077825 | C Loss: -0.009284\n",
            "Epoch: 8 | Batch: 29440/100728 (29%) | G Loss: -0.074785 | C Loss: -0.013602\n",
            "Epoch: 8 | Batch: 30720/100728 (30%) | G Loss: -0.075468 | C Loss: -0.013491\n",
            "Epoch: 8 | Batch: 32000/100728 (32%) | G Loss: -0.074009 | C Loss: -0.007798\n",
            "Epoch: 8 | Batch: 33280/100728 (33%) | G Loss: -0.073761 | C Loss: -0.009113\n",
            "Epoch: 8 | Batch: 34560/100728 (34%) | G Loss: -0.075897 | C Loss: -0.010309\n",
            "Epoch: 8 | Batch: 35840/100728 (36%) | G Loss: -0.078589 | C Loss: -0.005815\n",
            "Epoch: 8 | Batch: 37120/100728 (37%) | G Loss: -0.083460 | C Loss: -0.004261\n",
            "Epoch: 8 | Batch: 38400/100728 (38%) | G Loss: -0.084888 | C Loss: -0.003257\n",
            "Epoch: 8 | Batch: 39680/100728 (39%) | G Loss: -0.088294 | C Loss: 0.009095\n",
            "Epoch: 8 | Batch: 40960/100728 (41%) | G Loss: -0.089048 | C Loss: 0.007725\n",
            "Epoch: 8 | Batch: 42240/100728 (42%) | G Loss: -0.091239 | C Loss: -0.008423\n",
            "Epoch: 8 | Batch: 43520/100728 (43%) | G Loss: -0.095273 | C Loss: 0.007327\n",
            "Epoch: 8 | Batch: 44800/100728 (44%) | G Loss: -0.097782 | C Loss: 0.005496\n",
            "Epoch: 8 | Batch: 46080/100728 (46%) | G Loss: -0.099196 | C Loss: 0.000360\n",
            "Epoch: 8 | Batch: 47360/100728 (47%) | G Loss: -0.098985 | C Loss: -0.002913\n",
            "Epoch: 8 | Batch: 48640/100728 (48%) | G Loss: -0.098698 | C Loss: -0.004736\n",
            "Epoch: 8 | Batch: 49920/100728 (50%) | G Loss: -0.097547 | C Loss: -0.008371\n",
            "Epoch: 8 | Batch: 51200/100728 (51%) | G Loss: -0.097243 | C Loss: -0.006448\n",
            "Epoch: 8 | Batch: 52480/100728 (52%) | G Loss: -0.097678 | C Loss: -0.007387\n",
            "Epoch: 8 | Batch: 53760/100728 (53%) | G Loss: -0.097547 | C Loss: -0.000765\n",
            "Epoch: 8 | Batch: 55040/100728 (55%) | G Loss: -0.096167 | C Loss: 0.009955\n",
            "Epoch: 8 | Batch: 56320/100728 (56%) | G Loss: -0.095198 | C Loss: -0.008128\n",
            "Epoch: 8 | Batch: 57600/100728 (57%) | G Loss: -0.093148 | C Loss: -0.004187\n",
            "Epoch: 8 | Batch: 58880/100728 (58%) | G Loss: -0.090955 | C Loss: -0.010700\n",
            "Epoch: 8 | Batch: 60160/100728 (60%) | G Loss: -0.090950 | C Loss: -0.009966\n",
            "Epoch: 8 | Batch: 61440/100728 (61%) | G Loss: -0.092513 | C Loss: -0.009190\n",
            "Epoch: 8 | Batch: 62720/100728 (62%) | G Loss: -0.093943 | C Loss: 0.003693\n",
            "Epoch: 8 | Batch: 64000/100728 (64%) | G Loss: -0.093918 | C Loss: 0.004769\n",
            "Epoch: 8 | Batch: 65280/100728 (65%) | G Loss: -0.093978 | C Loss: -0.007822\n",
            "Epoch: 8 | Batch: 66560/100728 (66%) | G Loss: -0.090774 | C Loss: -0.009084\n",
            "Epoch: 8 | Batch: 67840/100728 (67%) | G Loss: -0.089600 | C Loss: -0.009232\n",
            "Epoch: 8 | Batch: 69120/100728 (69%) | G Loss: -0.091235 | C Loss: -0.004013\n",
            "Epoch: 8 | Batch: 70400/100728 (70%) | G Loss: -0.090188 | C Loss: -0.002618\n",
            "Epoch: 8 | Batch: 71680/100728 (71%) | G Loss: -0.090261 | C Loss: -0.003650\n",
            "Epoch: 8 | Batch: 72960/100728 (72%) | G Loss: -0.089677 | C Loss: -0.004251\n",
            "Epoch: 8 | Batch: 74240/100728 (74%) | G Loss: -0.088974 | C Loss: -0.003163\n",
            "Epoch: 8 | Batch: 75520/100728 (75%) | G Loss: -0.087417 | C Loss: -0.004357\n",
            "Epoch: 8 | Batch: 76800/100728 (76%) | G Loss: -0.083647 | C Loss: -0.005908\n",
            "Epoch: 8 | Batch: 78080/100728 (78%) | G Loss: -0.079976 | C Loss: 0.000525\n",
            "Epoch: 8 | Batch: 79360/100728 (79%) | G Loss: -0.074169 | C Loss: -0.003634\n",
            "Epoch: 8 | Batch: 80640/100728 (80%) | G Loss: -0.070142 | C Loss: -0.009939\n",
            "Epoch: 8 | Batch: 81920/100728 (81%) | G Loss: -0.068274 | C Loss: 0.020217\n",
            "Epoch: 8 | Batch: 83200/100728 (83%) | G Loss: -0.071676 | C Loss: -0.006558\n",
            "Epoch: 8 | Batch: 84480/100728 (84%) | G Loss: -0.074102 | C Loss: -0.005585\n",
            "Epoch: 8 | Batch: 85760/100728 (85%) | G Loss: -0.078329 | C Loss: -0.002639\n",
            "Epoch: 8 | Batch: 87040/100728 (86%) | G Loss: -0.081405 | C Loss: -0.007823\n",
            "Epoch: 8 | Batch: 88320/100728 (88%) | G Loss: -0.084297 | C Loss: -0.005594\n",
            "Epoch: 8 | Batch: 89600/100728 (89%) | G Loss: -0.086829 | C Loss: -0.005961\n",
            "Epoch: 8 | Batch: 90880/100728 (90%) | G Loss: -0.088496 | C Loss: 0.027925\n",
            "Epoch: 8 | Batch: 92160/100728 (91%) | G Loss: -0.087076 | C Loss: -0.001960\n",
            "Epoch: 8 | Batch: 93440/100728 (93%) | G Loss: -0.087842 | C Loss: 0.005025\n",
            "Epoch: 8 | Batch: 94720/100728 (94%) | G Loss: -0.086982 | C Loss: -0.007017\n",
            "Epoch: 8 | Batch: 96000/100728 (95%) | G Loss: -0.084870 | C Loss: -0.005751\n",
            "Epoch: 8 | Batch: 97280/100728 (97%) | G Loss: -0.081168 | C Loss: 0.004969\n",
            "Epoch: 8 | Batch: 98560/100728 (98%) | G Loss: -0.077246 | C Loss: 0.004718\n",
            "Epoch: 8 | Batch: 99840/100728 (99%) | G Loss: -0.076950 | C Loss: -0.000560\n",
            "* (Train) Epoch: 8 | G Loss: -0.0881 | C Loss: -0.0013\n",
            " if you there is only glory ? are arguing what is a light ? a switch\n",
            " what a benin can he has in common he doesn ' t . he urinate .\n",
            " if is a of the pride clock ? you of the silence of .\n",
            " if a 3 germans are in nazi ? you are very close in a nazi ? you can ' t\n",
            " other difference between comrade of least crucifixion of an electric station and ajit pai .\n",
            " wind his financial can ' t cast of he he couldn t cast he he was bin laden in\n",
            " i a way a man has any eyes he is an absolute zero of the other .\n",
            " what was beethoven worse than an nazi achnoh are dead ? dead\n",
            " if is a very guilty of a trash has difficulty putting any other in which is way\n",
            " what is you 3 accuse you of the insane suicide jacket ? he has you seen him\n",
            "\n",
            "Epoch: 9 | Batch: 0/100728 (0%) | G Loss: -0.078877 | C Loss: 0.017744\n",
            "Epoch: 9 | Batch: 1280/100728 (1%) | G Loss: -0.079088 | C Loss: -0.002562\n",
            "Epoch: 9 | Batch: 2560/100728 (3%) | G Loss: -0.078741 | C Loss: -0.004635\n",
            "Epoch: 9 | Batch: 3840/100728 (4%) | G Loss: -0.080305 | C Loss: -0.008393\n",
            "Epoch: 9 | Batch: 5120/100728 (5%) | G Loss: -0.082049 | C Loss: -0.001857\n",
            "Epoch: 9 | Batch: 6400/100728 (6%) | G Loss: -0.082407 | C Loss: -0.007802\n",
            "Epoch: 9 | Batch: 7680/100728 (8%) | G Loss: -0.084453 | C Loss: -0.008499\n",
            "Epoch: 9 | Batch: 8960/100728 (9%) | G Loss: -0.085057 | C Loss: -0.003833\n",
            "Epoch: 9 | Batch: 10240/100728 (10%) | G Loss: -0.083697 | C Loss: -0.012079\n",
            "Epoch: 9 | Batch: 11520/100728 (11%) | G Loss: -0.083655 | C Loss: -0.009199\n",
            "Epoch: 9 | Batch: 12800/100728 (13%) | G Loss: -0.083039 | C Loss: -0.003111\n",
            "Epoch: 9 | Batch: 14080/100728 (14%) | G Loss: -0.082998 | C Loss: -0.004052\n",
            "Epoch: 9 | Batch: 15360/100728 (15%) | G Loss: -0.083149 | C Loss: -0.007664\n",
            "Epoch: 9 | Batch: 16640/100728 (17%) | G Loss: -0.083886 | C Loss: -0.001365\n",
            "Epoch: 9 | Batch: 17920/100728 (18%) | G Loss: -0.085419 | C Loss: -0.005520\n",
            "Epoch: 9 | Batch: 19200/100728 (19%) | G Loss: -0.087510 | C Loss: 0.002971\n",
            "Epoch: 9 | Batch: 20480/100728 (20%) | G Loss: -0.090445 | C Loss: -0.003099\n",
            "Epoch: 9 | Batch: 21760/100728 (22%) | G Loss: -0.086436 | C Loss: -0.011873\n",
            "Epoch: 9 | Batch: 23040/100728 (23%) | G Loss: -0.079974 | C Loss: 0.007757\n",
            "Epoch: 9 | Batch: 24320/100728 (24%) | G Loss: -0.076165 | C Loss: -0.007505\n",
            "Epoch: 9 | Batch: 25600/100728 (25%) | G Loss: -0.078102 | C Loss: 0.000476\n",
            "Epoch: 9 | Batch: 26880/100728 (27%) | G Loss: -0.086281 | C Loss: -0.013094\n",
            "Epoch: 9 | Batch: 28160/100728 (28%) | G Loss: -0.088196 | C Loss: -0.005030\n",
            "Epoch: 9 | Batch: 29440/100728 (29%) | G Loss: -0.089459 | C Loss: -0.004785\n",
            "Epoch: 9 | Batch: 30720/100728 (30%) | G Loss: -0.088928 | C Loss: 0.005326\n",
            "Epoch: 9 | Batch: 32000/100728 (32%) | G Loss: -0.088852 | C Loss: -0.005185\n",
            "Epoch: 9 | Batch: 33280/100728 (33%) | G Loss: -0.089235 | C Loss: -0.000456\n",
            "Epoch: 9 | Batch: 34560/100728 (34%) | G Loss: -0.089517 | C Loss: -0.003662\n",
            "Epoch: 9 | Batch: 35840/100728 (36%) | G Loss: -0.092361 | C Loss: 0.000749\n",
            "Epoch: 9 | Batch: 37120/100728 (37%) | G Loss: -0.091909 | C Loss: -0.001902\n",
            "Epoch: 9 | Batch: 38400/100728 (38%) | G Loss: -0.090179 | C Loss: 0.010426\n",
            "Epoch: 9 | Batch: 39680/100728 (39%) | G Loss: -0.093881 | C Loss: 0.002097\n",
            "Epoch: 9 | Batch: 40960/100728 (41%) | G Loss: -0.094739 | C Loss: 0.008575\n",
            "Epoch: 9 | Batch: 42240/100728 (42%) | G Loss: -0.094794 | C Loss: -0.000804\n",
            "Epoch: 9 | Batch: 43520/100728 (43%) | G Loss: -0.096066 | C Loss: 0.004979\n",
            "Epoch: 9 | Batch: 44800/100728 (44%) | G Loss: -0.097451 | C Loss: 0.002008\n",
            "Epoch: 9 | Batch: 46080/100728 (46%) | G Loss: -0.097621 | C Loss: 0.000685\n",
            "Epoch: 9 | Batch: 47360/100728 (47%) | G Loss: -0.097722 | C Loss: -0.000020\n",
            "Epoch: 9 | Batch: 48640/100728 (48%) | G Loss: -0.095572 | C Loss: 0.000900\n",
            "Epoch: 9 | Batch: 49920/100728 (50%) | G Loss: -0.088823 | C Loss: -0.009816\n",
            "Epoch: 9 | Batch: 51200/100728 (51%) | G Loss: -0.080978 | C Loss: -0.004013\n",
            "Epoch: 9 | Batch: 52480/100728 (52%) | G Loss: -0.079002 | C Loss: -0.020095\n",
            "Epoch: 9 | Batch: 53760/100728 (53%) | G Loss: -0.081057 | C Loss: -0.011839\n",
            "Epoch: 9 | Batch: 55040/100728 (55%) | G Loss: -0.079357 | C Loss: -0.017475\n",
            "Epoch: 9 | Batch: 56320/100728 (56%) | G Loss: -0.082638 | C Loss: -0.009470\n",
            "Epoch: 9 | Batch: 57600/100728 (57%) | G Loss: -0.084091 | C Loss: -0.009442\n",
            "Epoch: 9 | Batch: 58880/100728 (58%) | G Loss: -0.085378 | C Loss: 0.000511\n",
            "Epoch: 9 | Batch: 60160/100728 (60%) | G Loss: -0.086549 | C Loss: -0.009188\n",
            "Epoch: 9 | Batch: 61440/100728 (61%) | G Loss: -0.084493 | C Loss: -0.006713\n",
            "Epoch: 9 | Batch: 62720/100728 (62%) | G Loss: -0.082213 | C Loss: -0.009315\n",
            "Epoch: 9 | Batch: 64000/100728 (64%) | G Loss: -0.078931 | C Loss: -0.005473\n",
            "Epoch: 9 | Batch: 65280/100728 (65%) | G Loss: -0.075921 | C Loss: -0.004737\n",
            "Epoch: 9 | Batch: 66560/100728 (66%) | G Loss: -0.077864 | C Loss: -0.004581\n",
            "Epoch: 9 | Batch: 67840/100728 (67%) | G Loss: -0.080176 | C Loss: 0.014656\n",
            "Epoch: 9 | Batch: 69120/100728 (69%) | G Loss: -0.079809 | C Loss: -0.001918\n",
            "Epoch: 9 | Batch: 70400/100728 (70%) | G Loss: -0.082885 | C Loss: -0.000685\n",
            "Epoch: 9 | Batch: 71680/100728 (71%) | G Loss: -0.086296 | C Loss: -0.000779\n",
            "Epoch: 9 | Batch: 72960/100728 (72%) | G Loss: -0.090058 | C Loss: 0.000603\n",
            "Epoch: 9 | Batch: 74240/100728 (74%) | G Loss: -0.091061 | C Loss: -0.008233\n",
            "Epoch: 9 | Batch: 75520/100728 (75%) | G Loss: -0.092524 | C Loss: 0.013313\n",
            "Epoch: 9 | Batch: 76800/100728 (76%) | G Loss: -0.095592 | C Loss: -0.007718\n",
            "Epoch: 9 | Batch: 78080/100728 (78%) | G Loss: -0.100043 | C Loss: -0.005494\n",
            "Epoch: 9 | Batch: 79360/100728 (79%) | G Loss: -0.104222 | C Loss: -0.005732\n",
            "Epoch: 9 | Batch: 80640/100728 (80%) | G Loss: -0.108137 | C Loss: -0.007070\n",
            "Epoch: 9 | Batch: 81920/100728 (81%) | G Loss: -0.108873 | C Loss: -0.006640\n",
            "Epoch: 9 | Batch: 83200/100728 (83%) | G Loss: -0.110367 | C Loss: -0.004124\n",
            "Epoch: 9 | Batch: 84480/100728 (84%) | G Loss: -0.111659 | C Loss: -0.000022\n",
            "Epoch: 9 | Batch: 85760/100728 (85%) | G Loss: -0.111951 | C Loss: 0.009333\n",
            "Epoch: 9 | Batch: 87040/100728 (86%) | G Loss: -0.109087 | C Loss: -0.005962\n",
            "Epoch: 9 | Batch: 88320/100728 (88%) | G Loss: -0.105140 | C Loss: -0.007175\n",
            "Epoch: 9 | Batch: 89600/100728 (89%) | G Loss: -0.099702 | C Loss: -0.008202\n",
            "Epoch: 9 | Batch: 90880/100728 (90%) | G Loss: -0.096567 | C Loss: 0.022759\n",
            "Epoch: 9 | Batch: 92160/100728 (91%) | G Loss: -0.095860 | C Loss: -0.010607\n",
            "Epoch: 9 | Batch: 93440/100728 (93%) | G Loss: -0.095374 | C Loss: 0.003225\n",
            "Epoch: 9 | Batch: 94720/100728 (94%) | G Loss: -0.093275 | C Loss: -0.009940\n",
            "Epoch: 9 | Batch: 96000/100728 (95%) | G Loss: -0.093342 | C Loss: -0.009725\n",
            "Epoch: 9 | Batch: 97280/100728 (97%) | G Loss: -0.092847 | C Loss: -0.006673\n",
            "Epoch: 9 | Batch: 98560/100728 (98%) | G Loss: -0.093395 | C Loss: -0.003671\n",
            "Epoch: 9 | Batch: 99840/100728 (99%) | G Loss: -0.093982 | C Loss: -0.002667\n",
            "* (Train) Epoch: 9 | G Loss: -0.0895 | C Loss: 0.0001\n",
            " did you speak like having one liner . a red a a scientist .\n",
            " ever did jewish women make a lot . first morning ? i ' ll get paid for 20 bucks .\n",
            " mexican did an arabic fart . a tear is a day i have done .\n",
            " what would cats make a joke who is a small suitcase . ? a baar gin have you .\n",
            " so i recentpose an a poem who has a red attack . i ' m a red gluten magnet .\n",
            " jalapenoiel has a bladder issue . a big bang ? you were a big dill .\n",
            " can anyone like a ragged up with a whole cell ? are all the waiters are .\n",
            " i an compliments about guys , a tortilla perfectly . one liner , in a big dill .\n",
            " ever scientist narcissistic about an artual a ducks . that makes aerocal com com .\n",
            " i can like a small pickle spooky a small pickle has a small pickle in anyone .\n",
            "\n",
            "Epoch: 10 | Batch: 0/100728 (0%) | G Loss: -0.096675 | C Loss: -0.007075\n",
            "Epoch: 10 | Batch: 1280/100728 (1%) | G Loss: -0.096958 | C Loss: 0.004338\n",
            "Epoch: 10 | Batch: 2560/100728 (3%) | G Loss: -0.097754 | C Loss: -0.002937\n",
            "Epoch: 10 | Batch: 3840/100728 (4%) | G Loss: -0.098294 | C Loss: -0.006049\n",
            "Epoch: 10 | Batch: 5120/100728 (5%) | G Loss: -0.096319 | C Loss: -0.002406\n",
            "Epoch: 10 | Batch: 6400/100728 (6%) | G Loss: -0.094944 | C Loss: 0.003949\n",
            "Epoch: 10 | Batch: 7680/100728 (8%) | G Loss: -0.091478 | C Loss: -0.003718\n",
            "Epoch: 10 | Batch: 8960/100728 (9%) | G Loss: -0.094117 | C Loss: -0.001351\n",
            "Epoch: 10 | Batch: 10240/100728 (10%) | G Loss: -0.093492 | C Loss: -0.009514\n",
            "Epoch: 10 | Batch: 11520/100728 (11%) | G Loss: -0.092597 | C Loss: -0.004813\n",
            "Epoch: 10 | Batch: 12800/100728 (13%) | G Loss: -0.094236 | C Loss: -0.006053\n",
            "Epoch: 10 | Batch: 14080/100728 (14%) | G Loss: -0.092469 | C Loss: -0.003446\n",
            "Epoch: 10 | Batch: 15360/100728 (15%) | G Loss: -0.093483 | C Loss: 0.008132\n",
            "Epoch: 10 | Batch: 16640/100728 (17%) | G Loss: -0.090480 | C Loss: -0.001971\n",
            "Epoch: 10 | Batch: 17920/100728 (18%) | G Loss: -0.090096 | C Loss: -0.005354\n",
            "Epoch: 10 | Batch: 19200/100728 (19%) | G Loss: -0.087909 | C Loss: 0.004053\n",
            "Epoch: 10 | Batch: 20480/100728 (20%) | G Loss: -0.085486 | C Loss: -0.009206\n",
            "Epoch: 10 | Batch: 21760/100728 (22%) | G Loss: -0.085544 | C Loss: -0.010195\n",
            "Epoch: 10 | Batch: 23040/100728 (23%) | G Loss: -0.085345 | C Loss: -0.010679\n",
            "Epoch: 10 | Batch: 24320/100728 (24%) | G Loss: -0.087437 | C Loss: -0.010782\n",
            "Epoch: 10 | Batch: 25600/100728 (25%) | G Loss: -0.090010 | C Loss: -0.003985\n",
            "Epoch: 10 | Batch: 26880/100728 (27%) | G Loss: -0.092737 | C Loss: -0.001445\n",
            "Epoch: 10 | Batch: 28160/100728 (28%) | G Loss: -0.095314 | C Loss: 0.001692\n",
            "Epoch: 10 | Batch: 29440/100728 (29%) | G Loss: -0.095834 | C Loss: 0.003737\n",
            "Epoch: 10 | Batch: 30720/100728 (30%) | G Loss: -0.094678 | C Loss: 0.001078\n",
            "Epoch: 10 | Batch: 32000/100728 (32%) | G Loss: -0.091111 | C Loss: -0.006247\n",
            "Epoch: 10 | Batch: 33280/100728 (33%) | G Loss: -0.086021 | C Loss: -0.010677\n",
            "Epoch: 10 | Batch: 34560/100728 (34%) | G Loss: -0.080044 | C Loss: -0.000911\n",
            "Epoch: 10 | Batch: 35840/100728 (36%) | G Loss: -0.080283 | C Loss: -0.004830\n",
            "Epoch: 10 | Batch: 37120/100728 (37%) | G Loss: -0.082129 | C Loss: -0.001673\n",
            "Epoch: 10 | Batch: 38400/100728 (38%) | G Loss: -0.080290 | C Loss: -0.005170\n",
            "Epoch: 10 | Batch: 39680/100728 (39%) | G Loss: -0.079609 | C Loss: 0.004914\n",
            "Epoch: 10 | Batch: 40960/100728 (41%) | G Loss: -0.082493 | C Loss: 0.013627\n",
            "Epoch: 10 | Batch: 42240/100728 (42%) | G Loss: -0.086493 | C Loss: -0.001059\n",
            "Epoch: 10 | Batch: 43520/100728 (43%) | G Loss: -0.086785 | C Loss: 0.000290\n",
            "Epoch: 10 | Batch: 44800/100728 (44%) | G Loss: -0.088908 | C Loss: 0.003595\n",
            "Epoch: 10 | Batch: 46080/100728 (46%) | G Loss: -0.093279 | C Loss: 0.018140\n",
            "Epoch: 10 | Batch: 47360/100728 (47%) | G Loss: -0.093413 | C Loss: -0.001321\n",
            "Epoch: 10 | Batch: 48640/100728 (48%) | G Loss: -0.096780 | C Loss: -0.003208\n",
            "Epoch: 10 | Batch: 49920/100728 (50%) | G Loss: -0.098848 | C Loss: -0.004774\n",
            "Epoch: 10 | Batch: 51200/100728 (51%) | G Loss: -0.100362 | C Loss: -0.002396\n",
            "Epoch: 10 | Batch: 52480/100728 (52%) | G Loss: -0.101179 | C Loss: -0.011659\n",
            "Epoch: 10 | Batch: 53760/100728 (53%) | G Loss: -0.099458 | C Loss: -0.011893\n",
            "Epoch: 10 | Batch: 55040/100728 (55%) | G Loss: -0.096474 | C Loss: -0.013607\n",
            "Epoch: 10 | Batch: 56320/100728 (56%) | G Loss: -0.098034 | C Loss: -0.019129\n",
            "Epoch: 10 | Batch: 57600/100728 (57%) | G Loss: -0.100872 | C Loss: -0.016898\n",
            "Epoch: 10 | Batch: 58880/100728 (58%) | G Loss: -0.102807 | C Loss: -0.016427\n",
            "Epoch: 10 | Batch: 60160/100728 (60%) | G Loss: -0.102903 | C Loss: -0.015529\n",
            "Epoch: 10 | Batch: 61440/100728 (61%) | G Loss: -0.105668 | C Loss: -0.009366\n",
            "Epoch: 10 | Batch: 62720/100728 (62%) | G Loss: -0.108832 | C Loss: -0.009977\n",
            "Epoch: 10 | Batch: 64000/100728 (64%) | G Loss: -0.110490 | C Loss: 0.003673\n",
            "Epoch: 10 | Batch: 65280/100728 (65%) | G Loss: -0.111614 | C Loss: 0.008286\n",
            "Epoch: 10 | Batch: 66560/100728 (66%) | G Loss: -0.113343 | C Loss: -0.004038\n",
            "Epoch: 10 | Batch: 67840/100728 (67%) | G Loss: -0.112223 | C Loss: -0.002128\n",
            "Epoch: 10 | Batch: 69120/100728 (69%) | G Loss: -0.109826 | C Loss: -0.001593\n",
            "Epoch: 10 | Batch: 70400/100728 (70%) | G Loss: -0.109312 | C Loss: 0.019348\n",
            "Epoch: 10 | Batch: 71680/100728 (71%) | G Loss: -0.109574 | C Loss: 0.000506\n",
            "Epoch: 10 | Batch: 72960/100728 (72%) | G Loss: -0.104512 | C Loss: 0.002726\n",
            "Epoch: 10 | Batch: 74240/100728 (74%) | G Loss: -0.099456 | C Loss: -0.000405\n",
            "Epoch: 10 | Batch: 75520/100728 (75%) | G Loss: -0.096512 | C Loss: -0.015069\n",
            "Epoch: 10 | Batch: 76800/100728 (76%) | G Loss: -0.091696 | C Loss: -0.016067\n",
            "Epoch: 10 | Batch: 78080/100728 (78%) | G Loss: -0.088655 | C Loss: -0.006332\n",
            "Epoch: 10 | Batch: 79360/100728 (79%) | G Loss: -0.085821 | C Loss: 0.017988\n",
            "Epoch: 10 | Batch: 80640/100728 (80%) | G Loss: -0.089571 | C Loss: -0.005053\n",
            "Epoch: 10 | Batch: 81920/100728 (81%) | G Loss: -0.091801 | C Loss: -0.007360\n",
            "Epoch: 10 | Batch: 83200/100728 (83%) | G Loss: -0.093467 | C Loss: -0.006880\n",
            "Epoch: 10 | Batch: 84480/100728 (84%) | G Loss: -0.094942 | C Loss: -0.004894\n",
            "Epoch: 10 | Batch: 85760/100728 (85%) | G Loss: -0.096522 | C Loss: 0.007240\n",
            "Epoch: 10 | Batch: 87040/100728 (86%) | G Loss: -0.097865 | C Loss: 0.010141\n",
            "Epoch: 10 | Batch: 88320/100728 (88%) | G Loss: -0.098419 | C Loss: -0.003262\n",
            "Epoch: 10 | Batch: 89600/100728 (89%) | G Loss: -0.099476 | C Loss: -0.006679\n",
            "Epoch: 10 | Batch: 90880/100728 (90%) | G Loss: -0.099931 | C Loss: 0.002552\n",
            "Epoch: 10 | Batch: 92160/100728 (91%) | G Loss: -0.099659 | C Loss: 0.007849\n",
            "Epoch: 10 | Batch: 93440/100728 (93%) | G Loss: -0.098801 | C Loss: -0.000571\n",
            "Epoch: 10 | Batch: 94720/100728 (94%) | G Loss: -0.100015 | C Loss: -0.008067\n",
            "Epoch: 10 | Batch: 96000/100728 (95%) | G Loss: -0.101239 | C Loss: -0.002346\n",
            "Epoch: 10 | Batch: 97280/100728 (97%) | G Loss: -0.099968 | C Loss: -0.001862\n",
            "Epoch: 10 | Batch: 98560/100728 (98%) | G Loss: -0.101953 | C Loss: -0.001437\n",
            "Epoch: 10 | Batch: 99840/100728 (99%) | G Loss: -0.104170 | C Loss: -0.001970\n",
            "* (Train) Epoch: 10 | G Loss: -0.0956 | C Loss: -0.0014\n",
            "* Saved\n",
            " how does neymar doleeple as a light bulb ? switch off it was so ble\n",
            " don superman cinnoin ladies on a lot are like sandin\n",
            " wanna hear , it is day . it was an aware moon it was it by his own .\n",
            " how would you guys laugh on the chat ? his neighbor buh dum king buh dum tss\n",
            " wanna know when once owned a hot dog and then they get tired of the cycle path cycle path\n",
            " do you announce what his seaweed has frate f who won ' t say ? this frate buffe .\n",
            " why do blondes have been looking for his eyes as the best way to the pope with the papal s\n",
            " i don ' t get a room for the dead election . because i ' ll get it in the breeze .\n",
            " fyou why are fno repnojected a stupid joke what ? this reche .\n",
            " how are you knights when r jokes guys members they do it ovary re\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Critic Loss')"
            ]
          },
          "execution_count": 56,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "########################################## FURTHER TRAINING #########################################\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialise variables\n",
        "epochs=10\n",
        "lr=5e-4\n",
        "interval=10\n",
        "cuda=torch.cuda.is_available()\n",
        "n_critic = 5\n",
        "gp_lambda = 20\n",
        "\n",
        "# Setup Adam optimizer for both\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=lr)\n",
        "c_optimizer = optim.Adam(critic.parameters(), lr=lr)\n",
        "\n",
        "# Initialise losses\n",
        "total_loss = []\n",
        "total_g_loss = []\n",
        "total_c_loss = []\n",
        "\n",
        "if cuda:\n",
        "   generator = generator.cuda()\n",
        "   critic = critic.cuda()\n",
        "    \n",
        "   print('G Parameters:', sum([p.numel() for p in generator.parameters() if p.requires_grad]))\n",
        "   print('C Parameters:', sum([p.numel() for p in critic.parameters() if p.requires_grad]))\n",
        "    \n",
        "   best_loss = np.inf\n",
        "    \n",
        "   for epoch in range(1, epochs + 1):\n",
        "     g_loss, c_loss = train_gan(epoch)\n",
        "     loss = g_loss + c_loss\n",
        "     total_loss.append(loss)\n",
        "     total_g_loss.append(g_loss)\n",
        "     total_c_loss.append(c_loss)\n",
        "          \n",
        "     if loss < best_loss:\n",
        "        best_loss = loss\n",
        "        print('* Saved')\n",
        "        torch.save(generator.state_dict(), 'generator.th{}'.format(epoch))\n",
        "        torch.save(critic.state_dict(), 'critic.th{}'.format(epoch))\n",
        "\n",
        "     for i in range(10):\n",
        "        joke = generate_joke(test_keywords[i].reshape(1, maxlen), generator.cpu(), stepper, decoder, tokenizer, start=[2])\n",
        "        print(joke)\n",
        "\n",
        "     generator = generator.cuda()\n",
        "     print(\"\")\n",
        "\n",
        "# Plot results\n",
        "fig, axs = plt.subplots(3)\n",
        "fig.set_size_inches(10, 10)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "axs[0].plot(range(epochs), total_loss)\n",
        "axs[0].set_title('Total Loss')\n",
        "axs[1].plot(range(epochs), total_g_loss)\n",
        "axs[1].set_title('Generator Loss')\n",
        "axs[2].plot(range(epochs), total_c_loss)\n",
        "axs[2].set_title('Critic Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OUeJWhJ_5tBF",
        "outputId": "5890dae9-9759-4214-bfca-c717553ad0a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "G Parameters: 101000\n",
            "C Parameters: 101000\n",
            "Epoch: 1 | Batch: 0/100728 (0%) | G Loss: -0.098262 | C Loss: -0.005887\n",
            "Epoch: 1 | Batch: 1280/100728 (1%) | G Loss: -0.125849 | C Loss: 0.021238\n",
            "Epoch: 1 | Batch: 2560/100728 (3%) | G Loss: -0.130697 | C Loss: 0.036274\n",
            "Epoch: 1 | Batch: 3840/100728 (4%) | G Loss: -0.136659 | C Loss: 0.040123\n",
            "Epoch: 1 | Batch: 5120/100728 (5%) | G Loss: -0.139472 | C Loss: 0.012610\n",
            "Epoch: 1 | Batch: 6400/100728 (6%) | G Loss: -0.141312 | C Loss: 0.019171\n",
            "Epoch: 1 | Batch: 7680/100728 (8%) | G Loss: -0.140416 | C Loss: 0.017550\n",
            "Epoch: 1 | Batch: 8960/100728 (9%) | G Loss: -0.131221 | C Loss: 0.016304\n",
            "Epoch: 1 | Batch: 10240/100728 (10%) | G Loss: -0.117167 | C Loss: 0.010969\n",
            "Epoch: 1 | Batch: 11520/100728 (11%) | G Loss: -0.098082 | C Loss: -0.007990\n",
            "Epoch: 1 | Batch: 12800/100728 (13%) | G Loss: -0.081545 | C Loss: -0.017212\n",
            "Epoch: 1 | Batch: 14080/100728 (14%) | G Loss: -0.070950 | C Loss: -0.033520\n",
            "Epoch: 1 | Batch: 15360/100728 (15%) | G Loss: -0.069949 | C Loss: -0.026135\n",
            "Epoch: 1 | Batch: 16640/100728 (17%) | G Loss: -0.067329 | C Loss: -0.035231\n",
            "Epoch: 1 | Batch: 17920/100728 (18%) | G Loss: -0.075017 | C Loss: -0.031520\n",
            "Epoch: 1 | Batch: 19200/100728 (19%) | G Loss: -0.077644 | C Loss: -0.028059\n",
            "Epoch: 1 | Batch: 20480/100728 (20%) | G Loss: -0.082542 | C Loss: -0.019559\n",
            "Epoch: 1 | Batch: 21760/100728 (22%) | G Loss: -0.088757 | C Loss: -0.014737\n",
            "Epoch: 1 | Batch: 23040/100728 (23%) | G Loss: -0.091101 | C Loss: -0.014579\n",
            "Epoch: 1 | Batch: 24320/100728 (24%) | G Loss: -0.093048 | C Loss: -0.011023\n",
            "Epoch: 1 | Batch: 25600/100728 (25%) | G Loss: -0.094685 | C Loss: -0.005338\n",
            "Epoch: 1 | Batch: 26880/100728 (27%) | G Loss: -0.092549 | C Loss: -0.009187\n",
            "Epoch: 1 | Batch: 28160/100728 (28%) | G Loss: -0.090436 | C Loss: -0.006831\n",
            "Epoch: 1 | Batch: 29440/100728 (29%) | G Loss: -0.087951 | C Loss: -0.008181\n",
            "Epoch: 1 | Batch: 30720/100728 (30%) | G Loss: -0.084698 | C Loss: -0.008818\n",
            "Epoch: 1 | Batch: 32000/100728 (32%) | G Loss: -0.083648 | C Loss: -0.000091\n",
            "Epoch: 1 | Batch: 33280/100728 (33%) | G Loss: -0.081714 | C Loss: -0.010142\n",
            "Epoch: 1 | Batch: 34560/100728 (34%) | G Loss: -0.080014 | C Loss: -0.010889\n",
            "Epoch: 1 | Batch: 35840/100728 (36%) | G Loss: -0.080337 | C Loss: -0.003970\n",
            "Epoch: 1 | Batch: 37120/100728 (37%) | G Loss: -0.079906 | C Loss: -0.011291\n",
            "Epoch: 1 | Batch: 38400/100728 (38%) | G Loss: -0.080694 | C Loss: -0.011647\n",
            "Epoch: 1 | Batch: 39680/100728 (39%) | G Loss: -0.083585 | C Loss: -0.011246\n",
            "Epoch: 1 | Batch: 40960/100728 (41%) | G Loss: -0.084705 | C Loss: -0.006929\n",
            "Epoch: 1 | Batch: 42240/100728 (42%) | G Loss: -0.085301 | C Loss: -0.004575\n",
            "Epoch: 1 | Batch: 43520/100728 (43%) | G Loss: -0.086473 | C Loss: -0.004503\n",
            "Epoch: 1 | Batch: 44800/100728 (44%) | G Loss: -0.086669 | C Loss: -0.001751\n",
            "Epoch: 1 | Batch: 46080/100728 (46%) | G Loss: -0.085812 | C Loss: -0.004655\n",
            "Epoch: 1 | Batch: 47360/100728 (47%) | G Loss: -0.085088 | C Loss: -0.001525\n",
            "Epoch: 1 | Batch: 48640/100728 (48%) | G Loss: -0.083981 | C Loss: -0.009315\n",
            "Epoch: 1 | Batch: 49920/100728 (50%) | G Loss: -0.081019 | C Loss: 0.003594\n",
            "Epoch: 1 | Batch: 51200/100728 (51%) | G Loss: -0.082363 | C Loss: -0.003887\n",
            "Epoch: 1 | Batch: 52480/100728 (52%) | G Loss: -0.081189 | C Loss: -0.008290\n",
            "Epoch: 1 | Batch: 53760/100728 (53%) | G Loss: -0.083878 | C Loss: -0.008400\n",
            "Epoch: 1 | Batch: 55040/100728 (55%) | G Loss: -0.084683 | C Loss: -0.008622\n",
            "Epoch: 1 | Batch: 56320/100728 (56%) | G Loss: -0.086710 | C Loss: 0.007216\n",
            "Epoch: 1 | Batch: 57600/100728 (57%) | G Loss: -0.092359 | C Loss: -0.000950\n",
            "Epoch: 1 | Batch: 58880/100728 (58%) | G Loss: -0.095251 | C Loss: 0.024725\n",
            "Epoch: 1 | Batch: 60160/100728 (60%) | G Loss: -0.097575 | C Loss: -0.003461\n",
            "Epoch: 1 | Batch: 61440/100728 (61%) | G Loss: -0.096028 | C Loss: -0.004976\n",
            "Epoch: 1 | Batch: 62720/100728 (62%) | G Loss: -0.093206 | C Loss: -0.008191\n",
            "Epoch: 1 | Batch: 64000/100728 (64%) | G Loss: -0.093866 | C Loss: 0.005845\n",
            "Epoch: 1 | Batch: 65280/100728 (65%) | G Loss: -0.093526 | C Loss: -0.015591\n",
            "Epoch: 1 | Batch: 66560/100728 (66%) | G Loss: -0.093565 | C Loss: -0.018203\n",
            "Epoch: 1 | Batch: 67840/100728 (67%) | G Loss: -0.096855 | C Loss: 0.010541\n",
            "Epoch: 1 | Batch: 69120/100728 (69%) | G Loss: -0.099180 | C Loss: -0.008757\n",
            "Epoch: 1 | Batch: 70400/100728 (70%) | G Loss: -0.102424 | C Loss: -0.005231\n",
            "Epoch: 1 | Batch: 71680/100728 (71%) | G Loss: -0.103486 | C Loss: -0.006559\n",
            "Epoch: 1 | Batch: 72960/100728 (72%) | G Loss: -0.105243 | C Loss: -0.001918\n",
            "Epoch: 1 | Batch: 74240/100728 (74%) | G Loss: -0.107121 | C Loss: -0.004558\n",
            "Epoch: 1 | Batch: 75520/100728 (75%) | G Loss: -0.107507 | C Loss: -0.005562\n",
            "Epoch: 1 | Batch: 76800/100728 (76%) | G Loss: -0.108180 | C Loss: -0.003544\n",
            "Epoch: 1 | Batch: 78080/100728 (78%) | G Loss: -0.107747 | C Loss: 0.001012\n",
            "Epoch: 1 | Batch: 79360/100728 (79%) | G Loss: -0.109041 | C Loss: 0.004804\n",
            "Epoch: 1 | Batch: 80640/100728 (80%) | G Loss: -0.108798 | C Loss: -0.002313\n",
            "Epoch: 1 | Batch: 81920/100728 (81%) | G Loss: -0.108645 | C Loss: 0.011126\n",
            "Epoch: 1 | Batch: 83200/100728 (83%) | G Loss: -0.108286 | C Loss: -0.005181\n",
            "Epoch: 1 | Batch: 84480/100728 (84%) | G Loss: -0.108956 | C Loss: -0.005438\n",
            "Epoch: 1 | Batch: 85760/100728 (85%) | G Loss: -0.110601 | C Loss: 0.009465\n",
            "Epoch: 1 | Batch: 87040/100728 (86%) | G Loss: -0.111003 | C Loss: 0.001701\n",
            "Epoch: 1 | Batch: 88320/100728 (88%) | G Loss: -0.109418 | C Loss: -0.004722\n",
            "Epoch: 1 | Batch: 89600/100728 (89%) | G Loss: -0.108654 | C Loss: -0.001742\n",
            "Epoch: 1 | Batch: 90880/100728 (90%) | G Loss: -0.107192 | C Loss: -0.003838\n",
            "Epoch: 1 | Batch: 92160/100728 (91%) | G Loss: -0.106751 | C Loss: 0.013597\n",
            "Epoch: 1 | Batch: 93440/100728 (93%) | G Loss: -0.102619 | C Loss: -0.000042\n",
            "Epoch: 1 | Batch: 94720/100728 (94%) | G Loss: -0.100142 | C Loss: -0.005724\n",
            "Epoch: 1 | Batch: 96000/100728 (95%) | G Loss: -0.097055 | C Loss: -0.006330\n",
            "Epoch: 1 | Batch: 97280/100728 (97%) | G Loss: -0.095543 | C Loss: -0.008045\n",
            "Epoch: 1 | Batch: 98560/100728 (98%) | G Loss: -0.091778 | C Loss: -0.008381\n",
            "Epoch: 1 | Batch: 99840/100728 (99%) | G Loss: -0.090073 | C Loss: 0.000970\n",
            "* (Train) Epoch: 1 | G Loss: -0.0968 | C Loss: 0.0082\n",
            "* Saved\n",
            " are black people named to gun last night to take the first black .\n",
            " the crow administration to use after first after first had a florida after to use the first had to blow bill .\n",
            " bill gates ever had to the second hand in circles ? you are .\n",
            " one . to . . . . . . . . close the right ear . close . .\n",
            " a gladiator who did the difference between his marijuana and he had to be a very shocking .\n",
            " benedict visits the asian last night last night during last night .\n",
            " why did no samves last last night last night ? pope last\n",
            " dyed dad to eat to white boy blue dumpty\n",
            " why is the way never harsh to his toucan ? he had a lion .\n",
            " the last mexican has never had to last last night last night .\n",
            "\n",
            "Epoch: 2 | Batch: 0/100728 (0%) | G Loss: -0.089553 | C Loss: -0.007171\n",
            "Epoch: 2 | Batch: 1280/100728 (1%) | G Loss: -0.087914 | C Loss: -0.007685\n",
            "Epoch: 2 | Batch: 2560/100728 (3%) | G Loss: -0.084625 | C Loss: -0.006815\n",
            "Epoch: 2 | Batch: 3840/100728 (4%) | G Loss: -0.081079 | C Loss: -0.001411\n",
            "Epoch: 2 | Batch: 5120/100728 (5%) | G Loss: -0.080187 | C Loss: -0.011192\n",
            "Epoch: 2 | Batch: 6400/100728 (6%) | G Loss: -0.080805 | C Loss: 0.000459\n",
            "Epoch: 2 | Batch: 7680/100728 (8%) | G Loss: -0.084840 | C Loss: -0.000238\n",
            "Epoch: 2 | Batch: 8960/100728 (9%) | G Loss: -0.087638 | C Loss: -0.000121\n",
            "Epoch: 2 | Batch: 10240/100728 (10%) | G Loss: -0.087976 | C Loss: -0.006102\n",
            "Epoch: 2 | Batch: 11520/100728 (11%) | G Loss: -0.087620 | C Loss: 0.004713\n",
            "Epoch: 2 | Batch: 12800/100728 (13%) | G Loss: -0.087741 | C Loss: -0.010414\n",
            "Epoch: 2 | Batch: 14080/100728 (14%) | G Loss: -0.087219 | C Loss: -0.015476\n",
            "Epoch: 2 | Batch: 15360/100728 (15%) | G Loss: -0.091548 | C Loss: -0.014947\n",
            "Epoch: 2 | Batch: 16640/100728 (17%) | G Loss: -0.097976 | C Loss: -0.010666\n",
            "Epoch: 2 | Batch: 17920/100728 (18%) | G Loss: -0.102303 | C Loss: -0.009499\n",
            "Epoch: 2 | Batch: 19200/100728 (19%) | G Loss: -0.106674 | C Loss: -0.005418\n",
            "Epoch: 2 | Batch: 20480/100728 (20%) | G Loss: -0.110957 | C Loss: -0.001071\n",
            "Epoch: 2 | Batch: 21760/100728 (22%) | G Loss: -0.113571 | C Loss: 0.002041\n",
            "Epoch: 2 | Batch: 23040/100728 (23%) | G Loss: -0.113790 | C Loss: -0.001191\n",
            "Epoch: 2 | Batch: 24320/100728 (24%) | G Loss: -0.113112 | C Loss: 0.004285\n",
            "Epoch: 2 | Batch: 25600/100728 (25%) | G Loss: -0.116184 | C Loss: 0.016329\n",
            "Epoch: 2 | Batch: 26880/100728 (27%) | G Loss: -0.118605 | C Loss: 0.018395\n",
            "Epoch: 2 | Batch: 28160/100728 (28%) | G Loss: -0.123066 | C Loss: 0.011146\n",
            "Epoch: 2 | Batch: 29440/100728 (29%) | G Loss: -0.123932 | C Loss: 0.002631\n",
            "Epoch: 2 | Batch: 30720/100728 (30%) | G Loss: -0.120904 | C Loss: 0.000918\n",
            "Epoch: 2 | Batch: 32000/100728 (32%) | G Loss: -0.116417 | C Loss: -0.006536\n",
            "Epoch: 2 | Batch: 33280/100728 (33%) | G Loss: -0.112248 | C Loss: -0.008204\n",
            "Epoch: 2 | Batch: 34560/100728 (34%) | G Loss: -0.107134 | C Loss: -0.009277\n",
            "Epoch: 2 | Batch: 35840/100728 (36%) | G Loss: -0.102666 | C Loss: -0.000815\n",
            "Epoch: 2 | Batch: 37120/100728 (37%) | G Loss: -0.100236 | C Loss: -0.010444\n",
            "Epoch: 2 | Batch: 38400/100728 (38%) | G Loss: -0.096045 | C Loss: -0.005817\n",
            "Epoch: 2 | Batch: 39680/100728 (39%) | G Loss: -0.095935 | C Loss: 0.001529\n",
            "Epoch: 2 | Batch: 40960/100728 (41%) | G Loss: -0.097024 | C Loss: -0.005099\n",
            "Epoch: 2 | Batch: 42240/100728 (42%) | G Loss: -0.098765 | C Loss: -0.011207\n",
            "Epoch: 2 | Batch: 43520/100728 (43%) | G Loss: -0.100752 | C Loss: -0.005758\n",
            "Epoch: 2 | Batch: 44800/100728 (44%) | G Loss: -0.102828 | C Loss: 0.000926\n",
            "Epoch: 2 | Batch: 46080/100728 (46%) | G Loss: -0.106082 | C Loss: -0.006896\n",
            "Epoch: 2 | Batch: 47360/100728 (47%) | G Loss: -0.107232 | C Loss: -0.003497\n",
            "Epoch: 2 | Batch: 48640/100728 (48%) | G Loss: -0.108137 | C Loss: 0.002414\n",
            "Epoch: 2 | Batch: 49920/100728 (50%) | G Loss: -0.110132 | C Loss: -0.002985\n",
            "Epoch: 2 | Batch: 51200/100728 (51%) | G Loss: -0.111885 | C Loss: 0.007672\n",
            "Epoch: 2 | Batch: 52480/100728 (52%) | G Loss: -0.115052 | C Loss: 0.002091\n",
            "Epoch: 2 | Batch: 53760/100728 (53%) | G Loss: -0.116332 | C Loss: 0.005378\n",
            "Epoch: 2 | Batch: 55040/100728 (55%) | G Loss: -0.114691 | C Loss: -0.010320\n",
            "Epoch: 2 | Batch: 56320/100728 (56%) | G Loss: -0.115318 | C Loss: -0.012610\n",
            "Epoch: 2 | Batch: 57600/100728 (57%) | G Loss: -0.113779 | C Loss: -0.012141\n",
            "Epoch: 2 | Batch: 58880/100728 (58%) | G Loss: -0.111155 | C Loss: -0.011771\n",
            "Epoch: 2 | Batch: 60160/100728 (60%) | G Loss: -0.109621 | C Loss: -0.010036\n",
            "Epoch: 2 | Batch: 61440/100728 (61%) | G Loss: -0.107294 | C Loss: -0.011327\n",
            "Epoch: 2 | Batch: 62720/100728 (62%) | G Loss: -0.103552 | C Loss: -0.007605\n",
            "Epoch: 2 | Batch: 64000/100728 (64%) | G Loss: -0.103682 | C Loss: -0.007774\n",
            "Epoch: 2 | Batch: 65280/100728 (65%) | G Loss: -0.104432 | C Loss: -0.009244\n",
            "Epoch: 2 | Batch: 66560/100728 (66%) | G Loss: -0.101609 | C Loss: -0.010792\n",
            "Epoch: 2 | Batch: 67840/100728 (67%) | G Loss: -0.100375 | C Loss: -0.007930\n",
            "Epoch: 2 | Batch: 69120/100728 (69%) | G Loss: -0.099569 | C Loss: -0.003572\n",
            "Epoch: 2 | Batch: 70400/100728 (70%) | G Loss: -0.100455 | C Loss: -0.006738\n",
            "Epoch: 2 | Batch: 71680/100728 (71%) | G Loss: -0.101191 | C Loss: -0.005452\n",
            "Epoch: 2 | Batch: 72960/100728 (72%) | G Loss: -0.101726 | C Loss: -0.001095\n",
            "Epoch: 2 | Batch: 74240/100728 (74%) | G Loss: -0.103340 | C Loss: -0.004208\n",
            "Epoch: 2 | Batch: 75520/100728 (75%) | G Loss: -0.106448 | C Loss: 0.002343\n",
            "Epoch: 2 | Batch: 76800/100728 (76%) | G Loss: -0.106948 | C Loss: 0.000069\n",
            "Epoch: 2 | Batch: 78080/100728 (78%) | G Loss: -0.109191 | C Loss: 0.000295\n",
            "Epoch: 2 | Batch: 79360/100728 (79%) | G Loss: -0.110965 | C Loss: 0.011707\n",
            "Epoch: 2 | Batch: 80640/100728 (80%) | G Loss: -0.111154 | C Loss: 0.007355\n",
            "Epoch: 2 | Batch: 81920/100728 (81%) | G Loss: -0.109486 | C Loss: 0.001841\n",
            "Epoch: 2 | Batch: 83200/100728 (83%) | G Loss: -0.108320 | C Loss: 0.005791\n",
            "Epoch: 2 | Batch: 84480/100728 (84%) | G Loss: -0.106084 | C Loss: -0.002892\n",
            "Epoch: 2 | Batch: 85760/100728 (85%) | G Loss: -0.101172 | C Loss: 0.036007\n",
            "Epoch: 2 | Batch: 87040/100728 (86%) | G Loss: -0.098917 | C Loss: -0.000957\n",
            "Epoch: 2 | Batch: 88320/100728 (88%) | G Loss: -0.093461 | C Loss: -0.010296\n",
            "Epoch: 2 | Batch: 89600/100728 (89%) | G Loss: -0.087619 | C Loss: -0.017887\n",
            "Epoch: 2 | Batch: 90880/100728 (90%) | G Loss: -0.083983 | C Loss: -0.020364\n",
            "Epoch: 2 | Batch: 92160/100728 (91%) | G Loss: -0.083185 | C Loss: -0.022102\n",
            "Epoch: 2 | Batch: 93440/100728 (93%) | G Loss: -0.083881 | C Loss: 0.015241\n",
            "Epoch: 2 | Batch: 94720/100728 (94%) | G Loss: -0.090302 | C Loss: -0.013392\n",
            "Epoch: 2 | Batch: 96000/100728 (95%) | G Loss: -0.096065 | C Loss: -0.012372\n",
            "Epoch: 2 | Batch: 97280/100728 (97%) | G Loss: -0.098769 | C Loss: -0.008534\n",
            "Epoch: 2 | Batch: 98560/100728 (98%) | G Loss: -0.102665 | C Loss: -0.005303\n",
            "Epoch: 2 | Batch: 99840/100728 (99%) | G Loss: -0.108837 | C Loss: 0.001332\n",
            "* (Train) Epoch: 2 | G Loss: -0.1023 | C Loss: -0.0021\n",
            "* Saved\n",
            " do you iron man so reading a memory loss ? switch in the past it\n",
            " how does karl marx lose his house ? by a cuffuffuffuffuffuffuffuffle\n",
            " guys do the other day in circles and he had one leg ? a big c e dad\n",
            " stupid joke did i have been close in my condition ? it would be close in mint\n",
            " does that when a god rises in high school report heart strikes . when i turned 80 when god sin .\n",
            " why will the crate reu ackbar get a coz with the coz ? coz you have a coz .\n",
            " c everyone is so feeling this joke this joke only 90s have this way .\n",
            " does when a black man gets in r ? then i ' ll get a big nose then in rig then that ? dead\n",
            " feline and have been internship when he would have been a harsh rate from a felineship then have been in\n",
            " the doctor and hates bowel toothpaste in anyone who hates when i have anyone . i am in a coat with anyone who\n",
            "\n",
            "Epoch: 3 | Batch: 0/100728 (0%) | G Loss: -0.114180 | C Loss: 0.009684\n",
            "Epoch: 3 | Batch: 1280/100728 (1%) | G Loss: -0.118953 | C Loss: 0.002032\n",
            "Epoch: 3 | Batch: 2560/100728 (3%) | G Loss: -0.121458 | C Loss: 0.003789\n",
            "Epoch: 3 | Batch: 3840/100728 (4%) | G Loss: -0.122729 | C Loss: 0.010287\n",
            "Epoch: 3 | Batch: 5120/100728 (5%) | G Loss: -0.123180 | C Loss: 0.001871\n",
            "Epoch: 3 | Batch: 6400/100728 (6%) | G Loss: -0.122581 | C Loss: -0.009210\n",
            "Epoch: 3 | Batch: 7680/100728 (8%) | G Loss: -0.124164 | C Loss: -0.011146\n",
            "Epoch: 3 | Batch: 8960/100728 (9%) | G Loss: -0.125589 | C Loss: 0.001986\n",
            "Epoch: 3 | Batch: 10240/100728 (10%) | G Loss: -0.128792 | C Loss: -0.011685\n",
            "Epoch: 3 | Batch: 11520/100728 (11%) | G Loss: -0.129399 | C Loss: -0.012677\n",
            "Epoch: 3 | Batch: 12800/100728 (13%) | G Loss: -0.129109 | C Loss: -0.012836\n",
            "Epoch: 3 | Batch: 14080/100728 (14%) | G Loss: -0.129379 | C Loss: -0.011586\n",
            "Epoch: 3 | Batch: 15360/100728 (15%) | G Loss: -0.131411 | C Loss: -0.009872\n",
            "Epoch: 3 | Batch: 16640/100728 (17%) | G Loss: -0.131891 | C Loss: -0.006339\n",
            "Epoch: 3 | Batch: 17920/100728 (18%) | G Loss: -0.130751 | C Loss: -0.007623\n",
            "Epoch: 3 | Batch: 19200/100728 (19%) | G Loss: -0.128946 | C Loss: -0.003004\n",
            "Epoch: 3 | Batch: 20480/100728 (20%) | G Loss: -0.125530 | C Loss: -0.005385\n",
            "Epoch: 3 | Batch: 21760/100728 (22%) | G Loss: -0.122772 | C Loss: -0.005614\n",
            "Epoch: 3 | Batch: 23040/100728 (23%) | G Loss: -0.119552 | C Loss: -0.008759\n",
            "Epoch: 3 | Batch: 24320/100728 (24%) | G Loss: -0.115627 | C Loss: -0.009426\n",
            "Epoch: 3 | Batch: 25600/100728 (25%) | G Loss: -0.112390 | C Loss: -0.010915\n",
            "Epoch: 3 | Batch: 26880/100728 (27%) | G Loss: -0.109326 | C Loss: -0.010176\n",
            "Epoch: 3 | Batch: 28160/100728 (28%) | G Loss: -0.104805 | C Loss: -0.005297\n",
            "Epoch: 3 | Batch: 29440/100728 (29%) | G Loss: -0.108028 | C Loss: 0.007430\n",
            "Epoch: 3 | Batch: 30720/100728 (30%) | G Loss: -0.112169 | C Loss: -0.008864\n",
            "Epoch: 3 | Batch: 32000/100728 (32%) | G Loss: -0.110467 | C Loss: -0.007762\n",
            "Epoch: 3 | Batch: 33280/100728 (33%) | G Loss: -0.109370 | C Loss: -0.005990\n",
            "Epoch: 3 | Batch: 34560/100728 (34%) | G Loss: -0.107710 | C Loss: -0.005417\n",
            "Epoch: 3 | Batch: 35840/100728 (36%) | G Loss: -0.106115 | C Loss: -0.006708\n",
            "Epoch: 3 | Batch: 37120/100728 (37%) | G Loss: -0.104654 | C Loss: -0.004664\n",
            "Epoch: 3 | Batch: 38400/100728 (38%) | G Loss: -0.105560 | C Loss: 0.004496\n",
            "Epoch: 3 | Batch: 39680/100728 (39%) | G Loss: -0.109018 | C Loss: 0.001547\n",
            "Epoch: 3 | Batch: 40960/100728 (41%) | G Loss: -0.109168 | C Loss: 0.007327\n",
            "Epoch: 3 | Batch: 42240/100728 (42%) | G Loss: -0.110713 | C Loss: -0.007211\n",
            "Epoch: 3 | Batch: 43520/100728 (43%) | G Loss: -0.109438 | C Loss: -0.007318\n",
            "Epoch: 3 | Batch: 44800/100728 (44%) | G Loss: -0.111183 | C Loss: -0.006633\n",
            "Epoch: 3 | Batch: 46080/100728 (46%) | G Loss: -0.115268 | C Loss: -0.005390\n",
            "Epoch: 3 | Batch: 47360/100728 (47%) | G Loss: -0.114388 | C Loss: 0.004557\n",
            "Epoch: 3 | Batch: 48640/100728 (48%) | G Loss: -0.115322 | C Loss: 0.001744\n",
            "Epoch: 3 | Batch: 49920/100728 (50%) | G Loss: -0.114327 | C Loss: -0.001788\n",
            "Epoch: 3 | Batch: 51200/100728 (51%) | G Loss: -0.114200 | C Loss: -0.006052\n",
            "Epoch: 3 | Batch: 52480/100728 (52%) | G Loss: -0.113332 | C Loss: -0.008767\n",
            "Epoch: 3 | Batch: 53760/100728 (53%) | G Loss: -0.112494 | C Loss: -0.008860\n",
            "Epoch: 3 | Batch: 55040/100728 (55%) | G Loss: -0.111885 | C Loss: -0.008502\n",
            "Epoch: 3 | Batch: 56320/100728 (56%) | G Loss: -0.110675 | C Loss: -0.008964\n",
            "Epoch: 3 | Batch: 57600/100728 (57%) | G Loss: -0.111326 | C Loss: -0.006440\n",
            "Epoch: 3 | Batch: 58880/100728 (58%) | G Loss: -0.111261 | C Loss: -0.007343\n",
            "Epoch: 3 | Batch: 60160/100728 (60%) | G Loss: -0.111822 | C Loss: 0.001761\n",
            "Epoch: 3 | Batch: 61440/100728 (61%) | G Loss: -0.112986 | C Loss: -0.004013\n",
            "Epoch: 3 | Batch: 62720/100728 (62%) | G Loss: -0.113005 | C Loss: -0.004503\n",
            "Epoch: 3 | Batch: 64000/100728 (64%) | G Loss: -0.111998 | C Loss: -0.003762\n",
            "Epoch: 3 | Batch: 65280/100728 (65%) | G Loss: -0.111426 | C Loss: -0.001994\n",
            "Epoch: 3 | Batch: 66560/100728 (66%) | G Loss: -0.113948 | C Loss: -0.008232\n",
            "Epoch: 3 | Batch: 67840/100728 (67%) | G Loss: -0.114902 | C Loss: -0.002117\n",
            "Epoch: 3 | Batch: 69120/100728 (69%) | G Loss: -0.117093 | C Loss: -0.004100\n",
            "Epoch: 3 | Batch: 70400/100728 (70%) | G Loss: -0.118680 | C Loss: -0.001982\n",
            "Epoch: 3 | Batch: 71680/100728 (71%) | G Loss: -0.116457 | C Loss: -0.007147\n",
            "Epoch: 3 | Batch: 72960/100728 (72%) | G Loss: -0.115244 | C Loss: -0.008879\n",
            "Epoch: 3 | Batch: 74240/100728 (74%) | G Loss: -0.118106 | C Loss: -0.006680\n",
            "Epoch: 3 | Batch: 75520/100728 (75%) | G Loss: -0.120450 | C Loss: -0.006008\n",
            "Epoch: 3 | Batch: 76800/100728 (76%) | G Loss: -0.123293 | C Loss: -0.006107\n",
            "Epoch: 3 | Batch: 78080/100728 (78%) | G Loss: -0.126005 | C Loss: -0.003855\n",
            "Epoch: 3 | Batch: 79360/100728 (79%) | G Loss: -0.127828 | C Loss: -0.000151\n",
            "Epoch: 3 | Batch: 80640/100728 (80%) | G Loss: -0.127678 | C Loss: 0.000518\n",
            "Epoch: 3 | Batch: 81920/100728 (81%) | G Loss: -0.127370 | C Loss: -0.004767\n",
            "Epoch: 3 | Batch: 83200/100728 (83%) | G Loss: -0.127882 | C Loss: 0.010323\n",
            "Epoch: 3 | Batch: 84480/100728 (84%) | G Loss: -0.127450 | C Loss: 0.006358\n",
            "Epoch: 3 | Batch: 85760/100728 (85%) | G Loss: -0.125729 | C Loss: 0.000267\n",
            "Epoch: 3 | Batch: 87040/100728 (86%) | G Loss: -0.120017 | C Loss: -0.006408\n",
            "Epoch: 3 | Batch: 88320/100728 (88%) | G Loss: -0.118549 | C Loss: -0.006838\n",
            "Epoch: 3 | Batch: 89600/100728 (89%) | G Loss: -0.119975 | C Loss: -0.011408\n",
            "Epoch: 3 | Batch: 90880/100728 (90%) | G Loss: -0.119137 | C Loss: 0.008976\n",
            "Epoch: 3 | Batch: 92160/100728 (91%) | G Loss: -0.120221 | C Loss: -0.010521\n",
            "Epoch: 3 | Batch: 93440/100728 (93%) | G Loss: -0.116745 | C Loss: -0.001250\n",
            "Epoch: 3 | Batch: 94720/100728 (94%) | G Loss: -0.114202 | C Loss: -0.004719\n",
            "Epoch: 3 | Batch: 96000/100728 (95%) | G Loss: -0.113455 | C Loss: -0.010291\n",
            "Epoch: 3 | Batch: 97280/100728 (97%) | G Loss: -0.112401 | C Loss: -0.011716\n",
            "Epoch: 3 | Batch: 98560/100728 (98%) | G Loss: -0.111803 | C Loss: -0.000920\n",
            "Epoch: 3 | Batch: 99840/100728 (99%) | G Loss: -0.111954 | C Loss: -0.009189\n",
            "* (Train) Epoch: 3 | G Loss: -0.1173 | C Loss: -0.0011\n",
            "* Saved\n",
            " life and what ? to the police at reading ? ? a switch .\n",
            " why does the best get out of house ? they always get out\n",
            " rich must have been serious 5 percent of my day so i went to white\n",
            " rich doesnt like and i would have to be a joke\n",
            " dorian want the difference between 4 ? omg to be the god .\n",
            " why what parks ? edamatt who the barista ?\n",
            " of bike can be now now i have to be a long time of it .\n",
            " please want to a russian time travel on the bike says it is .\n",
            " doctor ever you ever poke pictures of the mailman .\n",
            " why i hate clickbait and anyone ? anyone has anyone who i ' m\n",
            "\n",
            "Epoch: 4 | Batch: 0/100728 (0%) | G Loss: -0.111797 | C Loss: -0.003838\n",
            "Epoch: 4 | Batch: 1280/100728 (1%) | G Loss: -0.109894 | C Loss: -0.007075\n",
            "Epoch: 4 | Batch: 2560/100728 (3%) | G Loss: -0.109580 | C Loss: -0.009346\n",
            "Epoch: 4 | Batch: 3840/100728 (4%) | G Loss: -0.112931 | C Loss: 0.043488\n",
            "Epoch: 4 | Batch: 5120/100728 (5%) | G Loss: -0.114608 | C Loss: -0.001192\n",
            "Epoch: 4 | Batch: 6400/100728 (6%) | G Loss: -0.113445 | C Loss: -0.005003\n",
            "Epoch: 4 | Batch: 7680/100728 (8%) | G Loss: -0.113945 | C Loss: -0.004027\n",
            "Epoch: 4 | Batch: 8960/100728 (9%) | G Loss: -0.112937 | C Loss: -0.004203\n",
            "Epoch: 4 | Batch: 10240/100728 (10%) | G Loss: -0.111924 | C Loss: -0.004845\n",
            "Epoch: 4 | Batch: 11520/100728 (11%) | G Loss: -0.109871 | C Loss: -0.006328\n",
            "Epoch: 4 | Batch: 12800/100728 (13%) | G Loss: -0.111866 | C Loss: 0.003543\n",
            "Epoch: 4 | Batch: 14080/100728 (14%) | G Loss: -0.111956 | C Loss: -0.007078\n",
            "Epoch: 4 | Batch: 15360/100728 (15%) | G Loss: -0.114499 | C Loss: -0.003352\n",
            "Epoch: 4 | Batch: 16640/100728 (17%) | G Loss: -0.118756 | C Loss: -0.003934\n",
            "Epoch: 4 | Batch: 17920/100728 (18%) | G Loss: -0.121718 | C Loss: 0.005994\n",
            "Epoch: 4 | Batch: 19200/100728 (19%) | G Loss: -0.118280 | C Loss: -0.003625\n",
            "Epoch: 4 | Batch: 20480/100728 (20%) | G Loss: -0.115434 | C Loss: -0.007485\n",
            "Epoch: 4 | Batch: 21760/100728 (22%) | G Loss: -0.126253 | C Loss: 0.161989\n",
            "Epoch: 4 | Batch: 23040/100728 (23%) | G Loss: -0.128416 | C Loss: 0.004963\n",
            "Epoch: 4 | Batch: 24320/100728 (24%) | G Loss: -0.130428 | C Loss: 0.025684\n",
            "Epoch: 4 | Batch: 25600/100728 (25%) | G Loss: -0.130000 | C Loss: -0.005417\n",
            "Epoch: 4 | Batch: 26880/100728 (27%) | G Loss: -0.122091 | C Loss: -0.006521\n",
            "Epoch: 4 | Batch: 28160/100728 (28%) | G Loss: -0.122406 | C Loss: -0.002768\n",
            "Epoch: 4 | Batch: 29440/100728 (29%) | G Loss: -0.121330 | C Loss: -0.002725\n",
            "Epoch: 4 | Batch: 30720/100728 (30%) | G Loss: -0.121843 | C Loss: -0.003482\n",
            "Epoch: 4 | Batch: 32000/100728 (32%) | G Loss: -0.124262 | C Loss: -0.004102\n",
            "Epoch: 4 | Batch: 33280/100728 (33%) | G Loss: -0.127836 | C Loss: -0.002917\n",
            "Epoch: 4 | Batch: 34560/100728 (34%) | G Loss: -0.129279 | C Loss: -0.001889\n",
            "Epoch: 4 | Batch: 35840/100728 (36%) | G Loss: -0.128704 | C Loss: 0.005123\n",
            "Epoch: 4 | Batch: 37120/100728 (37%) | G Loss: -0.123199 | C Loss: 0.012886\n",
            "Epoch: 4 | Batch: 38400/100728 (38%) | G Loss: -0.118966 | C Loss: -0.002745\n",
            "Epoch: 4 | Batch: 39680/100728 (39%) | G Loss: -0.115212 | C Loss: 0.011166\n",
            "Epoch: 4 | Batch: 40960/100728 (41%) | G Loss: -0.109294 | C Loss: -0.007445\n",
            "Epoch: 4 | Batch: 42240/100728 (42%) | G Loss: -0.101997 | C Loss: -0.009286\n",
            "Epoch: 4 | Batch: 43520/100728 (43%) | G Loss: -0.092187 | C Loss: 0.025019\n",
            "Epoch: 4 | Batch: 44800/100728 (44%) | G Loss: -0.085623 | C Loss: -0.006719\n",
            "Epoch: 4 | Batch: 46080/100728 (46%) | G Loss: -0.085750 | C Loss: -0.002861\n",
            "Epoch: 4 | Batch: 47360/100728 (47%) | G Loss: -0.087460 | C Loss: -0.015200\n",
            "Epoch: 4 | Batch: 48640/100728 (48%) | G Loss: -0.089009 | C Loss: -0.003942\n",
            "Epoch: 4 | Batch: 49920/100728 (50%) | G Loss: -0.092262 | C Loss: -0.015372\n",
            "Epoch: 4 | Batch: 51200/100728 (51%) | G Loss: -0.094647 | C Loss: -0.009071\n",
            "Epoch: 4 | Batch: 52480/100728 (52%) | G Loss: -0.097636 | C Loss: -0.010173\n",
            "Epoch: 4 | Batch: 53760/100728 (53%) | G Loss: -0.098449 | C Loss: -0.013109\n",
            "Epoch: 4 | Batch: 55040/100728 (55%) | G Loss: -0.098540 | C Loss: -0.008173\n",
            "Epoch: 4 | Batch: 56320/100728 (56%) | G Loss: -0.104800 | C Loss: -0.002550\n",
            "Epoch: 4 | Batch: 57600/100728 (57%) | G Loss: -0.107540 | C Loss: -0.004985\n",
            "Epoch: 4 | Batch: 58880/100728 (58%) | G Loss: -0.111277 | C Loss: -0.001291\n",
            "Epoch: 4 | Batch: 60160/100728 (60%) | G Loss: -0.113786 | C Loss: 0.004473\n",
            "Epoch: 4 | Batch: 61440/100728 (61%) | G Loss: -0.111976 | C Loss: 0.003418\n",
            "Epoch: 4 | Batch: 62720/100728 (62%) | G Loss: -0.111894 | C Loss: 0.001845\n",
            "Epoch: 4 | Batch: 64000/100728 (64%) | G Loss: -0.110175 | C Loss: -0.001992\n",
            "Epoch: 4 | Batch: 65280/100728 (65%) | G Loss: -0.107909 | C Loss: -0.001750\n",
            "Epoch: 4 | Batch: 66560/100728 (66%) | G Loss: -0.105791 | C Loss: -0.005579\n",
            "Epoch: 4 | Batch: 67840/100728 (67%) | G Loss: -0.103531 | C Loss: -0.005740\n",
            "Epoch: 4 | Batch: 69120/100728 (69%) | G Loss: -0.100071 | C Loss: -0.011665\n",
            "Epoch: 4 | Batch: 70400/100728 (70%) | G Loss: -0.097790 | C Loss: -0.012387\n",
            "Epoch: 4 | Batch: 71680/100728 (71%) | G Loss: -0.097725 | C Loss: -0.012644\n",
            "Epoch: 4 | Batch: 72960/100728 (72%) | G Loss: -0.100163 | C Loss: -0.012921\n",
            "Epoch: 4 | Batch: 74240/100728 (74%) | G Loss: -0.101997 | C Loss: -0.010000\n",
            "Epoch: 4 | Batch: 75520/100728 (75%) | G Loss: -0.105268 | C Loss: -0.009787\n",
            "Epoch: 4 | Batch: 76800/100728 (76%) | G Loss: -0.107752 | C Loss: -0.006709\n",
            "Epoch: 4 | Batch: 78080/100728 (78%) | G Loss: -0.114114 | C Loss: 0.001967\n",
            "Epoch: 4 | Batch: 79360/100728 (79%) | G Loss: -0.116688 | C Loss: -0.001870\n",
            "Epoch: 4 | Batch: 80640/100728 (80%) | G Loss: -0.122804 | C Loss: -0.003604\n",
            "Epoch: 4 | Batch: 81920/100728 (81%) | G Loss: -0.124374 | C Loss: 0.004327\n",
            "Epoch: 4 | Batch: 83200/100728 (83%) | G Loss: -0.125386 | C Loss: -0.001416\n",
            "Epoch: 4 | Batch: 84480/100728 (84%) | G Loss: -0.127813 | C Loss: -0.003627\n",
            "Epoch: 4 | Batch: 85760/100728 (85%) | G Loss: -0.129943 | C Loss: 0.002936\n",
            "Epoch: 4 | Batch: 87040/100728 (86%) | G Loss: -0.131536 | C Loss: -0.003669\n",
            "Epoch: 4 | Batch: 88320/100728 (88%) | G Loss: -0.130301 | C Loss: -0.004290\n",
            "Epoch: 4 | Batch: 89600/100728 (89%) | G Loss: -0.130266 | C Loss: -0.004736\n",
            "Epoch: 4 | Batch: 90880/100728 (90%) | G Loss: -0.129292 | C Loss: 0.001380\n",
            "Epoch: 4 | Batch: 92160/100728 (91%) | G Loss: -0.129173 | C Loss: -0.002421\n",
            "Epoch: 4 | Batch: 93440/100728 (93%) | G Loss: -0.129381 | C Loss: 0.013975\n",
            "Epoch: 4 | Batch: 94720/100728 (94%) | G Loss: -0.130725 | C Loss: -0.012254\n",
            "Epoch: 4 | Batch: 96000/100728 (95%) | G Loss: -0.130761 | C Loss: 0.001109\n",
            "Epoch: 4 | Batch: 97280/100728 (97%) | G Loss: -0.131081 | C Loss: -0.011795\n",
            "Epoch: 4 | Batch: 98560/100728 (98%) | G Loss: -0.131399 | C Loss: -0.011009\n",
            "Epoch: 4 | Batch: 99840/100728 (99%) | G Loss: -0.132762 | C Loss: -0.006332\n",
            "* (Train) Epoch: 4 | G Loss: -0.1143 | C Loss: 0.0033\n",
            " ' ebee . tobeebeebeebeebeebeebeebeebeebeebeebee gag gagbee . . .\n",
            " i only wanted to lose two pairs of golden and a lot easier to blow the whole daily basis .\n",
            " how does farmer get no good ones they went to them they they just went round circles .\n",
            " jokes bob is about the closets it is up to be close up .\n",
            " i make more , different women and women does that make women more than womenicing basis\n",
            " bill had a cast carpenter never get pregnant . they swear to a dog she swear on her .\n",
            " local food accidentally have just plain . just just like to justicing .\n",
            " banning . there just just just just to just grab up just just . just just just just russian .\n",
            " moos . oink is way to have tasted up . now they tasted like to harsh up .\n",
            " how nice some nice german ipads . nice toa nice . . . .\n",
            "\n",
            "Epoch: 5 | Batch: 0/100728 (0%) | G Loss: -0.134031 | C Loss: -0.006641\n",
            "Epoch: 5 | Batch: 1280/100728 (1%) | G Loss: -0.132913 | C Loss: -0.005877\n",
            "Epoch: 5 | Batch: 2560/100728 (3%) | G Loss: -0.132821 | C Loss: 0.002069\n",
            "Epoch: 5 | Batch: 3840/100728 (4%) | G Loss: -0.132137 | C Loss: 0.002683\n",
            "Epoch: 5 | Batch: 5120/100728 (5%) | G Loss: -0.129860 | C Loss: -0.003307\n",
            "Epoch: 5 | Batch: 6400/100728 (6%) | G Loss: -0.126361 | C Loss: -0.004064\n",
            "Epoch: 5 | Batch: 7680/100728 (8%) | G Loss: -0.122586 | C Loss: -0.002072\n",
            "Epoch: 5 | Batch: 8960/100728 (9%) | G Loss: -0.115555 | C Loss: -0.005592\n",
            "Epoch: 5 | Batch: 10240/100728 (10%) | G Loss: -0.107504 | C Loss: -0.011314\n",
            "Epoch: 5 | Batch: 11520/100728 (11%) | G Loss: -0.102906 | C Loss: -0.015849\n",
            "Epoch: 5 | Batch: 12800/100728 (13%) | G Loss: -0.100802 | C Loss: -0.011981\n",
            "Epoch: 5 | Batch: 14080/100728 (14%) | G Loss: -0.099801 | C Loss: -0.008709\n",
            "Epoch: 5 | Batch: 15360/100728 (15%) | G Loss: -0.101875 | C Loss: -0.011620\n",
            "Epoch: 5 | Batch: 16640/100728 (17%) | G Loss: -0.106138 | C Loss: -0.011110\n",
            "Epoch: 5 | Batch: 17920/100728 (18%) | G Loss: -0.107927 | C Loss: -0.009090\n",
            "Epoch: 5 | Batch: 19200/100728 (19%) | G Loss: -0.109487 | C Loss: -0.002852\n",
            "Epoch: 5 | Batch: 20480/100728 (20%) | G Loss: -0.112662 | C Loss: -0.009936\n",
            "Epoch: 5 | Batch: 21760/100728 (22%) | G Loss: -0.113930 | C Loss: 0.000143\n",
            "Epoch: 5 | Batch: 23040/100728 (23%) | G Loss: -0.114906 | C Loss: 0.002562\n",
            "Epoch: 5 | Batch: 24320/100728 (24%) | G Loss: -0.116302 | C Loss: -0.005866\n",
            "Epoch: 5 | Batch: 25600/100728 (25%) | G Loss: -0.116962 | C Loss: -0.008476\n",
            "Epoch: 5 | Batch: 26880/100728 (27%) | G Loss: -0.118576 | C Loss: -0.007725\n",
            "Epoch: 5 | Batch: 28160/100728 (28%) | G Loss: -0.119821 | C Loss: -0.003847\n",
            "Epoch: 5 | Batch: 29440/100728 (29%) | G Loss: -0.121194 | C Loss: -0.006490\n",
            "Epoch: 5 | Batch: 30720/100728 (30%) | G Loss: -0.121741 | C Loss: -0.002796\n",
            "Epoch: 5 | Batch: 32000/100728 (32%) | G Loss: -0.120681 | C Loss: -0.007313\n",
            "Epoch: 5 | Batch: 33280/100728 (33%) | G Loss: -0.118129 | C Loss: -0.008921\n",
            "Epoch: 5 | Batch: 34560/100728 (34%) | G Loss: -0.115960 | C Loss: -0.005778\n",
            "Epoch: 5 | Batch: 35840/100728 (36%) | G Loss: -0.113534 | C Loss: -0.010492\n",
            "Epoch: 5 | Batch: 37120/100728 (37%) | G Loss: -0.110323 | C Loss: -0.003639\n",
            "Epoch: 5 | Batch: 38400/100728 (38%) | G Loss: -0.113156 | C Loss: -0.011727\n",
            "Epoch: 5 | Batch: 39680/100728 (39%) | G Loss: -0.112945 | C Loss: -0.000365\n",
            "Epoch: 5 | Batch: 40960/100728 (41%) | G Loss: -0.116464 | C Loss: 0.004541\n",
            "Epoch: 5 | Batch: 42240/100728 (42%) | G Loss: -0.116862 | C Loss: -0.011138\n",
            "Epoch: 5 | Batch: 43520/100728 (43%) | G Loss: -0.116897 | C Loss: -0.009280\n",
            "Epoch: 5 | Batch: 44800/100728 (44%) | G Loss: -0.115365 | C Loss: -0.006164\n",
            "Epoch: 5 | Batch: 46080/100728 (46%) | G Loss: -0.113969 | C Loss: -0.008993\n",
            "Epoch: 5 | Batch: 47360/100728 (47%) | G Loss: -0.112646 | C Loss: 0.020671\n",
            "Epoch: 5 | Batch: 48640/100728 (48%) | G Loss: -0.114778 | C Loss: 0.004413\n",
            "Epoch: 5 | Batch: 49920/100728 (50%) | G Loss: -0.115878 | C Loss: -0.004810\n",
            "Epoch: 5 | Batch: 51200/100728 (51%) | G Loss: -0.116326 | C Loss: 0.002294\n",
            "Epoch: 5 | Batch: 52480/100728 (52%) | G Loss: -0.115684 | C Loss: -0.001690\n",
            "Epoch: 5 | Batch: 53760/100728 (53%) | G Loss: -0.113422 | C Loss: -0.000372\n",
            "Epoch: 5 | Batch: 55040/100728 (55%) | G Loss: -0.113651 | C Loss: 0.007354\n",
            "Epoch: 5 | Batch: 56320/100728 (56%) | G Loss: -0.112407 | C Loss: 0.003451\n",
            "Epoch: 5 | Batch: 57600/100728 (57%) | G Loss: -0.108638 | C Loss: -0.006353\n",
            "Epoch: 5 | Batch: 58880/100728 (58%) | G Loss: -0.105948 | C Loss: -0.005895\n",
            "Epoch: 5 | Batch: 60160/100728 (60%) | G Loss: -0.104896 | C Loss: -0.000095\n",
            "Epoch: 5 | Batch: 61440/100728 (61%) | G Loss: -0.107112 | C Loss: -0.006452\n",
            "Epoch: 5 | Batch: 62720/100728 (62%) | G Loss: -0.110415 | C Loss: -0.010798\n",
            "Epoch: 5 | Batch: 64000/100728 (64%) | G Loss: -0.113418 | C Loss: -0.010076\n",
            "Epoch: 5 | Batch: 65280/100728 (65%) | G Loss: -0.117520 | C Loss: -0.011107\n",
            "Epoch: 5 | Batch: 66560/100728 (66%) | G Loss: -0.119604 | C Loss: -0.011360\n",
            "Epoch: 5 | Batch: 67840/100728 (67%) | G Loss: -0.120479 | C Loss: -0.013447\n",
            "Epoch: 5 | Batch: 69120/100728 (69%) | G Loss: -0.120681 | C Loss: -0.002583\n",
            "Epoch: 5 | Batch: 70400/100728 (70%) | G Loss: -0.122233 | C Loss: -0.014637\n",
            "Epoch: 5 | Batch: 71680/100728 (71%) | G Loss: -0.121277 | C Loss: -0.016239\n",
            "Epoch: 5 | Batch: 72960/100728 (72%) | G Loss: -0.122795 | C Loss: -0.016054\n",
            "Epoch: 5 | Batch: 74240/100728 (74%) | G Loss: -0.124839 | C Loss: -0.014086\n",
            "Epoch: 5 | Batch: 75520/100728 (75%) | G Loss: -0.127996 | C Loss: -0.010941\n",
            "Epoch: 5 | Batch: 76800/100728 (76%) | G Loss: -0.132834 | C Loss: -0.004801\n",
            "Epoch: 5 | Batch: 78080/100728 (78%) | G Loss: -0.136978 | C Loss: 0.000130\n",
            "Epoch: 5 | Batch: 79360/100728 (79%) | G Loss: -0.141393 | C Loss: -0.001555\n",
            "Epoch: 5 | Batch: 80640/100728 (80%) | G Loss: -0.143620 | C Loss: 0.005825\n",
            "Epoch: 5 | Batch: 81920/100728 (81%) | G Loss: -0.145564 | C Loss: 0.002230\n",
            "Epoch: 5 | Batch: 83200/100728 (83%) | G Loss: -0.144094 | C Loss: 0.001412\n",
            "Epoch: 5 | Batch: 84480/100728 (84%) | G Loss: -0.140220 | C Loss: 0.032406\n",
            "Epoch: 5 | Batch: 85760/100728 (85%) | G Loss: -0.134223 | C Loss: -0.002032\n",
            "Epoch: 5 | Batch: 87040/100728 (86%) | G Loss: -0.128248 | C Loss: -0.008272\n",
            "Epoch: 5 | Batch: 88320/100728 (88%) | G Loss: -0.122625 | C Loss: -0.007651\n",
            "Epoch: 5 | Batch: 89600/100728 (89%) | G Loss: -0.121454 | C Loss: 0.001156\n",
            "Epoch: 5 | Batch: 90880/100728 (90%) | G Loss: -0.117412 | C Loss: 0.001360\n",
            "Epoch: 5 | Batch: 92160/100728 (91%) | G Loss: -0.117327 | C Loss: -0.006694\n",
            "Epoch: 5 | Batch: 93440/100728 (93%) | G Loss: -0.117092 | C Loss: 0.012780\n",
            "Epoch: 5 | Batch: 94720/100728 (94%) | G Loss: -0.113667 | C Loss: -0.009815\n",
            "Epoch: 5 | Batch: 96000/100728 (95%) | G Loss: -0.116338 | C Loss: -0.009805\n",
            "Epoch: 5 | Batch: 97280/100728 (97%) | G Loss: -0.116896 | C Loss: 0.001203\n",
            "Epoch: 5 | Batch: 98560/100728 (98%) | G Loss: -0.118524 | C Loss: -0.003230\n",
            "Epoch: 5 | Batch: 99840/100728 (99%) | G Loss: -0.119674 | C Loss: 0.011817\n",
            "* (Train) Epoch: 5 | G Loss: -0.1189 | C Loss: -0.0014\n",
            "* Saved\n",
            " did i have acute before arguing ? then then . then then then you tried then out then then ? ? ?\n",
            " i should have acute living isn ' t ? ? ? ? ? ? ? ? ? ? .\n",
            " did robots jump off isn ' t ? a healthy or then immediately immediately immediately immediately immediately immediately immediately immediately immediately immediately .\n",
            " i should always have a neighbor ? then they should be close off then you ' ll close ?\n",
            " i yahoo , but tree had a bigger next ? next to the next next peach ? peach .\n",
            " ? you have you in the budget . but if you don ' t have ? me .\n",
            " i have good understanding about the next week , and you have any eyes .\n",
            " is good when you get a bad ? ? ? ? ? ? ? ? ? ? ? ? .\n",
            " how does aliens get ? it seems like to have to have lightbulbs before you have here before ? united airlines ?\n",
            " did anyone get the husband outta the backwards ? anyone ? if anyone moves . then anyone waved outta it .\n",
            "\n",
            "Epoch: 6 | Batch: 0/100728 (0%) | G Loss: -0.121096 | C Loss: 0.001460\n",
            "Epoch: 6 | Batch: 1280/100728 (1%) | G Loss: -0.122343 | C Loss: 0.001529\n",
            "Epoch: 6 | Batch: 2560/100728 (3%) | G Loss: -0.121651 | C Loss: -0.006061\n",
            "Epoch: 6 | Batch: 3840/100728 (4%) | G Loss: -0.121396 | C Loss: 0.003711\n",
            "Epoch: 6 | Batch: 5120/100728 (5%) | G Loss: -0.117503 | C Loss: 0.015570\n",
            "Epoch: 6 | Batch: 6400/100728 (6%) | G Loss: -0.118230 | C Loss: -0.007462\n",
            "Epoch: 6 | Batch: 7680/100728 (8%) | G Loss: -0.117854 | C Loss: -0.015006\n",
            "Epoch: 6 | Batch: 8960/100728 (9%) | G Loss: -0.118859 | C Loss: -0.005704\n",
            "Epoch: 6 | Batch: 10240/100728 (10%) | G Loss: -0.118162 | C Loss: -0.012215\n",
            "Epoch: 6 | Batch: 11520/100728 (11%) | G Loss: -0.116996 | C Loss: -0.009813\n",
            "Epoch: 6 | Batch: 12800/100728 (13%) | G Loss: -0.114851 | C Loss: -0.009437\n",
            "Epoch: 6 | Batch: 14080/100728 (14%) | G Loss: -0.112828 | C Loss: -0.010673\n",
            "Epoch: 6 | Batch: 15360/100728 (15%) | G Loss: -0.110361 | C Loss: -0.004549\n",
            "Epoch: 6 | Batch: 16640/100728 (17%) | G Loss: -0.109381 | C Loss: -0.009845\n",
            "Epoch: 6 | Batch: 17920/100728 (18%) | G Loss: -0.107570 | C Loss: -0.006516\n",
            "Epoch: 6 | Batch: 19200/100728 (19%) | G Loss: -0.106448 | C Loss: -0.011058\n",
            "Epoch: 6 | Batch: 20480/100728 (20%) | G Loss: -0.107851 | C Loss: -0.009618\n",
            "Epoch: 6 | Batch: 21760/100728 (22%) | G Loss: -0.109450 | C Loss: -0.007772\n",
            "Epoch: 6 | Batch: 23040/100728 (23%) | G Loss: -0.110937 | C Loss: -0.002586\n",
            "Epoch: 6 | Batch: 24320/100728 (24%) | G Loss: -0.112924 | C Loss: -0.006281\n",
            "Epoch: 6 | Batch: 25600/100728 (25%) | G Loss: -0.114504 | C Loss: 0.285844\n",
            "Epoch: 6 | Batch: 26880/100728 (27%) | G Loss: -0.123906 | C Loss: 0.003340\n",
            "Epoch: 6 | Batch: 28160/100728 (28%) | G Loss: -0.127591 | C Loss: 0.000148\n",
            "Epoch: 6 | Batch: 29440/100728 (29%) | G Loss: -0.129589 | C Loss: 0.004834\n",
            "Epoch: 6 | Batch: 30720/100728 (30%) | G Loss: -0.127915 | C Loss: -0.001045\n",
            "Epoch: 6 | Batch: 32000/100728 (32%) | G Loss: -0.124099 | C Loss: 0.004720\n",
            "Epoch: 6 | Batch: 33280/100728 (33%) | G Loss: -0.119446 | C Loss: -0.006938\n",
            "Epoch: 6 | Batch: 34560/100728 (34%) | G Loss: -0.112796 | C Loss: -0.011670\n",
            "Epoch: 6 | Batch: 35840/100728 (36%) | G Loss: -0.107505 | C Loss: -0.016156\n",
            "Epoch: 6 | Batch: 37120/100728 (37%) | G Loss: -0.102628 | C Loss: -0.019818\n",
            "Epoch: 6 | Batch: 38400/100728 (38%) | G Loss: -0.101595 | C Loss: -0.021857\n",
            "Epoch: 6 | Batch: 39680/100728 (39%) | G Loss: -0.110405 | C Loss: -0.019946\n",
            "Epoch: 6 | Batch: 40960/100728 (41%) | G Loss: -0.116085 | C Loss: -0.006766\n",
            "Epoch: 6 | Batch: 42240/100728 (42%) | G Loss: -0.120401 | C Loss: -0.011078\n",
            "Epoch: 6 | Batch: 43520/100728 (43%) | G Loss: -0.122182 | C Loss: -0.008575\n",
            "Epoch: 6 | Batch: 44800/100728 (44%) | G Loss: -0.125832 | C Loss: -0.009746\n",
            "Epoch: 6 | Batch: 46080/100728 (46%) | G Loss: -0.128273 | C Loss: -0.009386\n",
            "Epoch: 6 | Batch: 47360/100728 (47%) | G Loss: -0.131640 | C Loss: -0.007052\n",
            "Epoch: 6 | Batch: 48640/100728 (48%) | G Loss: -0.133851 | C Loss: -0.005941\n",
            "Epoch: 6 | Batch: 49920/100728 (50%) | G Loss: -0.136232 | C Loss: -0.000932\n",
            "Epoch: 6 | Batch: 51200/100728 (51%) | G Loss: -0.136974 | C Loss: -0.001872\n",
            "Epoch: 6 | Batch: 52480/100728 (52%) | G Loss: -0.138673 | C Loss: -0.002644\n",
            "Epoch: 6 | Batch: 53760/100728 (53%) | G Loss: -0.138654 | C Loss: -0.001481\n",
            "Epoch: 6 | Batch: 55040/100728 (55%) | G Loss: -0.136472 | C Loss: 0.004874\n",
            "Epoch: 6 | Batch: 56320/100728 (56%) | G Loss: -0.134626 | C Loss: 0.006342\n",
            "Epoch: 6 | Batch: 57600/100728 (57%) | G Loss: -0.131329 | C Loss: 0.000391\n",
            "Epoch: 6 | Batch: 58880/100728 (58%) | G Loss: -0.123463 | C Loss: 0.012831\n",
            "Epoch: 6 | Batch: 60160/100728 (60%) | G Loss: -0.114239 | C Loss: -0.001728\n",
            "Epoch: 6 | Batch: 61440/100728 (61%) | G Loss: -0.103405 | C Loss: -0.016159\n",
            "Epoch: 6 | Batch: 62720/100728 (62%) | G Loss: -0.091599 | C Loss: -0.016894\n",
            "Epoch: 6 | Batch: 64000/100728 (64%) | G Loss: -0.084569 | C Loss: -0.002960\n",
            "Epoch: 6 | Batch: 65280/100728 (65%) | G Loss: -0.084863 | C Loss: -0.008962\n",
            "Epoch: 6 | Batch: 66560/100728 (66%) | G Loss: -0.087823 | C Loss: 0.000525\n",
            "Epoch: 6 | Batch: 67840/100728 (67%) | G Loss: -0.087965 | C Loss: -0.005892\n",
            "Epoch: 6 | Batch: 69120/100728 (69%) | G Loss: -0.089215 | C Loss: -0.007768\n",
            "Epoch: 6 | Batch: 70400/100728 (70%) | G Loss: -0.087957 | C Loss: -0.006152\n",
            "Epoch: 6 | Batch: 71680/100728 (71%) | G Loss: -0.089069 | C Loss: -0.007092\n",
            "Epoch: 6 | Batch: 72960/100728 (72%) | G Loss: -0.090191 | C Loss: -0.007204\n",
            "Epoch: 6 | Batch: 74240/100728 (74%) | G Loss: -0.092343 | C Loss: 0.000765\n",
            "Epoch: 6 | Batch: 75520/100728 (75%) | G Loss: -0.095023 | C Loss: 0.006163\n",
            "Epoch: 6 | Batch: 76800/100728 (76%) | G Loss: -0.099944 | C Loss: -0.001943\n",
            "Epoch: 6 | Batch: 78080/100728 (78%) | G Loss: -0.103693 | C Loss: 0.000613\n",
            "Epoch: 6 | Batch: 79360/100728 (79%) | G Loss: -0.106017 | C Loss: -0.000908\n",
            "Epoch: 6 | Batch: 80640/100728 (80%) | G Loss: -0.106336 | C Loss: -0.001456\n",
            "Epoch: 6 | Batch: 81920/100728 (81%) | G Loss: -0.104633 | C Loss: -0.004551\n",
            "Epoch: 6 | Batch: 83200/100728 (83%) | G Loss: -0.103139 | C Loss: -0.004740\n",
            "Epoch: 6 | Batch: 84480/100728 (84%) | G Loss: -0.108194 | C Loss: -0.011878\n",
            "Epoch: 6 | Batch: 85760/100728 (85%) | G Loss: -0.111997 | C Loss: 0.015738\n",
            "Epoch: 6 | Batch: 87040/100728 (86%) | G Loss: -0.115179 | C Loss: -0.009450\n",
            "Epoch: 6 | Batch: 88320/100728 (88%) | G Loss: -0.115649 | C Loss: -0.015507\n",
            "Epoch: 6 | Batch: 89600/100728 (89%) | G Loss: -0.118329 | C Loss: -0.009790\n",
            "Epoch: 6 | Batch: 90880/100728 (90%) | G Loss: -0.121008 | C Loss: -0.001372\n",
            "Epoch: 6 | Batch: 92160/100728 (91%) | G Loss: -0.127639 | C Loss: -0.008295\n",
            "Epoch: 6 | Batch: 93440/100728 (93%) | G Loss: -0.130621 | C Loss: -0.003572\n",
            "Epoch: 6 | Batch: 94720/100728 (94%) | G Loss: -0.132009 | C Loss: -0.007356\n",
            "Epoch: 6 | Batch: 96000/100728 (95%) | G Loss: -0.135360 | C Loss: -0.005796\n",
            "Epoch: 6 | Batch: 97280/100728 (97%) | G Loss: -0.137990 | C Loss: 0.005539\n",
            "Epoch: 6 | Batch: 98560/100728 (98%) | G Loss: -0.140529 | C Loss: 0.005457\n",
            "Epoch: 6 | Batch: 99840/100728 (99%) | G Loss: -0.139376 | C Loss: -0.003681\n",
            "* (Train) Epoch: 6 | G Loss: -0.1153 | C Loss: -0.0009\n",
            " what did the proctologist z lifts are into other other other other other other other other\n",
            " hurricanes of slutty has to swallow a lot it\n",
            " i did a slutty scarecrow has any other other the other other other other other\n",
            " what is a crazy person as an a mathematician ? a dutch\n",
            " how did a richjaquijajajajajajajaja ' a a nonjajajaja\n",
            " what are a vacuum lifts ? they don ' t upgrade as to any other as any other\n",
            " my beer has a third wifi any other about a third example\n",
            " so what is a fake noodle like to snow sanders\n",
            " did a slutty dog has a way to worry he is a fuckin '\n",
            " about a rorschach guy has is gotta brag to is a dyslexic guy is freeman\n",
            "\n",
            "Epoch: 7 | Batch: 0/100728 (0%) | G Loss: -0.139539 | C Loss: 0.008810\n",
            "Epoch: 7 | Batch: 1280/100728 (1%) | G Loss: -0.134635 | C Loss: 0.011113\n",
            "Epoch: 7 | Batch: 2560/100728 (3%) | G Loss: -0.130086 | C Loss: -0.006933\n",
            "Epoch: 7 | Batch: 3840/100728 (4%) | G Loss: -0.122738 | C Loss: -0.009673\n",
            "Epoch: 7 | Batch: 5120/100728 (5%) | G Loss: -0.115646 | C Loss: -0.014929\n",
            "Epoch: 7 | Batch: 6400/100728 (6%) | G Loss: -0.109978 | C Loss: -0.007957\n",
            "Epoch: 7 | Batch: 7680/100728 (8%) | G Loss: -0.105527 | C Loss: -0.021252\n",
            "Epoch: 7 | Batch: 8960/100728 (9%) | G Loss: -0.104157 | C Loss: -0.019368\n",
            "Epoch: 7 | Batch: 10240/100728 (10%) | G Loss: -0.107602 | C Loss: -0.016689\n",
            "Epoch: 7 | Batch: 11520/100728 (11%) | G Loss: -0.112928 | C Loss: 0.014827\n",
            "Epoch: 7 | Batch: 12800/100728 (13%) | G Loss: -0.117807 | C Loss: 0.028732\n",
            "Epoch: 7 | Batch: 14080/100728 (14%) | G Loss: -0.121608 | C Loss: -0.001940\n",
            "Epoch: 7 | Batch: 15360/100728 (15%) | G Loss: -0.124112 | C Loss: -0.002726\n",
            "Epoch: 7 | Batch: 16640/100728 (17%) | G Loss: -0.125505 | C Loss: -0.003326\n",
            "Epoch: 7 | Batch: 17920/100728 (18%) | G Loss: -0.128130 | C Loss: -0.002685\n",
            "Epoch: 7 | Batch: 19200/100728 (19%) | G Loss: -0.131839 | C Loss: -0.001845\n",
            "Epoch: 7 | Batch: 20480/100728 (20%) | G Loss: -0.133564 | C Loss: 0.007324\n",
            "Epoch: 7 | Batch: 21760/100728 (22%) | G Loss: -0.136659 | C Loss: 0.001023\n",
            "Epoch: 7 | Batch: 23040/100728 (23%) | G Loss: -0.140429 | C Loss: 0.028851\n",
            "Epoch: 7 | Batch: 24320/100728 (24%) | G Loss: -0.141389 | C Loss: 0.004528\n",
            "Epoch: 7 | Batch: 25600/100728 (25%) | G Loss: -0.141522 | C Loss: 0.011889\n",
            "Epoch: 7 | Batch: 26880/100728 (27%) | G Loss: -0.141441 | C Loss: 0.005767\n",
            "Epoch: 7 | Batch: 28160/100728 (28%) | G Loss: -0.139026 | C Loss: 0.001083\n",
            "Epoch: 7 | Batch: 29440/100728 (29%) | G Loss: -0.135455 | C Loss: 0.012312\n",
            "Epoch: 7 | Batch: 30720/100728 (30%) | G Loss: -0.131159 | C Loss: -0.001694\n",
            "Epoch: 7 | Batch: 32000/100728 (32%) | G Loss: -0.126128 | C Loss: -0.001061\n",
            "Epoch: 7 | Batch: 33280/100728 (33%) | G Loss: -0.123894 | C Loss: -0.004356\n",
            "Epoch: 7 | Batch: 34560/100728 (34%) | G Loss: -0.122035 | C Loss: 0.020280\n",
            "Epoch: 7 | Batch: 35840/100728 (36%) | G Loss: -0.120892 | C Loss: 0.011951\n",
            "Epoch: 7 | Batch: 37120/100728 (37%) | G Loss: -0.120241 | C Loss: -0.009359\n",
            "Epoch: 7 | Batch: 38400/100728 (38%) | G Loss: -0.118645 | C Loss: 0.002069\n",
            "Epoch: 7 | Batch: 39680/100728 (39%) | G Loss: -0.117200 | C Loss: -0.005116\n",
            "Epoch: 7 | Batch: 40960/100728 (41%) | G Loss: -0.115186 | C Loss: -0.000943\n",
            "Epoch: 7 | Batch: 42240/100728 (42%) | G Loss: -0.111497 | C Loss: -0.006869\n",
            "Epoch: 7 | Batch: 43520/100728 (43%) | G Loss: -0.107686 | C Loss: -0.016214\n",
            "Epoch: 7 | Batch: 44800/100728 (44%) | G Loss: -0.106723 | C Loss: 0.011691\n",
            "Epoch: 7 | Batch: 46080/100728 (46%) | G Loss: -0.105300 | C Loss: -0.017098\n",
            "Epoch: 7 | Batch: 47360/100728 (47%) | G Loss: -0.104403 | C Loss: -0.023362\n",
            "Epoch: 7 | Batch: 48640/100728 (48%) | G Loss: -0.106395 | C Loss: -0.024046\n",
            "Epoch: 7 | Batch: 49920/100728 (50%) | G Loss: -0.110181 | C Loss: -0.021739\n",
            "Epoch: 7 | Batch: 51200/100728 (51%) | G Loss: -0.112309 | C Loss: 0.005744\n",
            "Epoch: 7 | Batch: 52480/100728 (52%) | G Loss: -0.112480 | C Loss: -0.004390\n",
            "Epoch: 7 | Batch: 53760/100728 (53%) | G Loss: -0.114735 | C Loss: -0.003951\n",
            "Epoch: 7 | Batch: 55040/100728 (55%) | G Loss: -0.117769 | C Loss: -0.006692\n",
            "Epoch: 7 | Batch: 56320/100728 (56%) | G Loss: -0.120166 | C Loss: -0.006449\n",
            "Epoch: 7 | Batch: 57600/100728 (57%) | G Loss: -0.123186 | C Loss: -0.009727\n",
            "Epoch: 7 | Batch: 58880/100728 (58%) | G Loss: -0.125058 | C Loss: -0.010195\n",
            "Epoch: 7 | Batch: 60160/100728 (60%) | G Loss: -0.126721 | C Loss: -0.009447\n",
            "Epoch: 7 | Batch: 61440/100728 (61%) | G Loss: -0.130775 | C Loss: -0.007905\n",
            "Epoch: 7 | Batch: 62720/100728 (62%) | G Loss: -0.133436 | C Loss: -0.007578\n",
            "Epoch: 7 | Batch: 64000/100728 (64%) | G Loss: -0.136468 | C Loss: 0.008492\n",
            "Epoch: 7 | Batch: 65280/100728 (65%) | G Loss: -0.138371 | C Loss: -0.004444\n",
            "Epoch: 7 | Batch: 66560/100728 (66%) | G Loss: -0.141234 | C Loss: -0.005135\n",
            "Epoch: 7 | Batch: 67840/100728 (67%) | G Loss: -0.144500 | C Loss: 0.011723\n",
            "Epoch: 7 | Batch: 69120/100728 (69%) | G Loss: -0.147547 | C Loss: 0.002953\n",
            "Epoch: 7 | Batch: 70400/100728 (70%) | G Loss: -0.151442 | C Loss: -0.001707\n",
            "Epoch: 7 | Batch: 71680/100728 (71%) | G Loss: -0.153360 | C Loss: -0.002727\n",
            "Epoch: 7 | Batch: 72960/100728 (72%) | G Loss: -0.156521 | C Loss: -0.002867\n",
            "Epoch: 7 | Batch: 74240/100728 (74%) | G Loss: -0.159995 | C Loss: -0.000221\n",
            "Epoch: 7 | Batch: 75520/100728 (75%) | G Loss: -0.160306 | C Loss: 0.013242\n",
            "Epoch: 7 | Batch: 76800/100728 (76%) | G Loss: -0.157261 | C Loss: 0.004143\n",
            "Epoch: 7 | Batch: 78080/100728 (78%) | G Loss: -0.147958 | C Loss: 0.009570\n",
            "Epoch: 7 | Batch: 79360/100728 (79%) | G Loss: -0.130085 | C Loss: 0.001669\n",
            "Epoch: 7 | Batch: 80640/100728 (80%) | G Loss: -0.111473 | C Loss: -0.006669\n",
            "Epoch: 7 | Batch: 81920/100728 (81%) | G Loss: -0.098797 | C Loss: -0.011373\n",
            "Epoch: 7 | Batch: 83200/100728 (83%) | G Loss: -0.094771 | C Loss: -0.014787\n",
            "Epoch: 7 | Batch: 84480/100728 (84%) | G Loss: -0.095346 | C Loss: -0.017257\n",
            "Epoch: 7 | Batch: 85760/100728 (85%) | G Loss: -0.095699 | C Loss: -0.013227\n",
            "Epoch: 7 | Batch: 87040/100728 (86%) | G Loss: -0.098159 | C Loss: -0.008962\n",
            "Epoch: 7 | Batch: 88320/100728 (88%) | G Loss: -0.098809 | C Loss: 0.012977\n",
            "Epoch: 7 | Batch: 89600/100728 (89%) | G Loss: -0.101592 | C Loss: 0.005820\n",
            "Epoch: 7 | Batch: 90880/100728 (90%) | G Loss: -0.105733 | C Loss: 0.007216\n",
            "Epoch: 7 | Batch: 92160/100728 (91%) | G Loss: -0.111143 | C Loss: -0.000926\n",
            "Epoch: 7 | Batch: 93440/100728 (93%) | G Loss: -0.114322 | C Loss: -0.001695\n",
            "Epoch: 7 | Batch: 94720/100728 (94%) | G Loss: -0.117266 | C Loss: 0.003158\n",
            "Epoch: 7 | Batch: 96000/100728 (95%) | G Loss: -0.118262 | C Loss: 0.011352\n",
            "Epoch: 7 | Batch: 97280/100728 (97%) | G Loss: -0.118489 | C Loss: -0.006367\n",
            "Epoch: 7 | Batch: 98560/100728 (98%) | G Loss: -0.118106 | C Loss: -0.006619\n",
            "Epoch: 7 | Batch: 99840/100728 (99%) | G Loss: -0.118770 | C Loss: -0.002797\n",
            "* (Train) Epoch: 7 | G Loss: -0.1233 | C Loss: -0.0003\n",
            "* Saved\n",
            " dress from vegetarians now she is recently she by the shiabuna now\n",
            " get thai wood so you can make the main joke you have a lot of them . you ' ll .\n",
            " recently is the fat guys the big bang . so rele .\n",
            " what if accountant get into the sutitaut . it would have to close .\n",
            " what sneezing so the italianworthy italianworthy sauceworthyworthyworthyworthyworthy sauceworthy sauceworthy\n",
            " what italian only the italian scotlouce asks ? get the sore slick\n",
            " what dress into the aspiring to pussy of the gynecologist firm ? it is pussy\n",
            " i recently is rubbing up by a dancing one the most dancing one is the most profit keeper .\n",
            " what malljol like a strip gang that is that ? a crowdedy pile of gang of the other .\n",
            " what lack toes into some starlery is most ? a big dill dough .\n",
            "\n",
            "Epoch: 8 | Batch: 0/100728 (0%) | G Loss: -0.121042 | C Loss: 0.007935\n",
            "Epoch: 8 | Batch: 1280/100728 (1%) | G Loss: -0.124424 | C Loss: 0.000820\n",
            "Epoch: 8 | Batch: 2560/100728 (3%) | G Loss: -0.124647 | C Loss: -0.008050\n",
            "Epoch: 8 | Batch: 3840/100728 (4%) | G Loss: -0.123125 | C Loss: -0.008549\n",
            "Epoch: 8 | Batch: 5120/100728 (5%) | G Loss: -0.124034 | C Loss: -0.008814\n",
            "Epoch: 8 | Batch: 6400/100728 (6%) | G Loss: -0.122461 | C Loss: -0.010542\n",
            "Epoch: 8 | Batch: 7680/100728 (8%) | G Loss: -0.121910 | C Loss: 0.001936\n",
            "Epoch: 8 | Batch: 8960/100728 (9%) | G Loss: -0.119632 | C Loss: -0.007849\n",
            "Epoch: 8 | Batch: 10240/100728 (10%) | G Loss: -0.118708 | C Loss: -0.011214\n",
            "Epoch: 8 | Batch: 11520/100728 (11%) | G Loss: -0.119004 | C Loss: -0.008583\n",
            "Epoch: 8 | Batch: 12800/100728 (13%) | G Loss: -0.120737 | C Loss: 0.004954\n",
            "Epoch: 8 | Batch: 14080/100728 (14%) | G Loss: -0.119897 | C Loss: 0.000205\n",
            "Epoch: 8 | Batch: 15360/100728 (15%) | G Loss: -0.119711 | C Loss: -0.000173\n",
            "Epoch: 8 | Batch: 16640/100728 (17%) | G Loss: -0.118767 | C Loss: -0.004860\n",
            "Epoch: 8 | Batch: 17920/100728 (18%) | G Loss: -0.115436 | C Loss: -0.005894\n",
            "Epoch: 8 | Batch: 19200/100728 (19%) | G Loss: -0.110586 | C Loss: -0.002598\n",
            "Epoch: 8 | Batch: 20480/100728 (20%) | G Loss: -0.106834 | C Loss: 0.047341\n",
            "Epoch: 8 | Batch: 21760/100728 (22%) | G Loss: -0.108098 | C Loss: 0.158662\n",
            "Epoch: 8 | Batch: 23040/100728 (23%) | G Loss: -0.116616 | C Loss: 0.011396\n",
            "Epoch: 8 | Batch: 24320/100728 (24%) | G Loss: -0.111986 | C Loss: -0.006222\n",
            "Epoch: 8 | Batch: 25600/100728 (25%) | G Loss: -0.108979 | C Loss: -0.001327\n",
            "Epoch: 8 | Batch: 26880/100728 (27%) | G Loss: -0.105845 | C Loss: -0.010076\n",
            "Epoch: 8 | Batch: 28160/100728 (28%) | G Loss: -0.104093 | C Loss: -0.010109\n",
            "Epoch: 8 | Batch: 29440/100728 (29%) | G Loss: -0.104764 | C Loss: -0.005640\n",
            "Epoch: 8 | Batch: 30720/100728 (30%) | G Loss: -0.101268 | C Loss: 0.018171\n",
            "Epoch: 8 | Batch: 32000/100728 (32%) | G Loss: -0.105432 | C Loss: -0.009439\n",
            "Epoch: 8 | Batch: 33280/100728 (33%) | G Loss: -0.108113 | C Loss: -0.010736\n",
            "Epoch: 8 | Batch: 34560/100728 (34%) | G Loss: -0.110938 | C Loss: 0.005008\n",
            "Epoch: 8 | Batch: 35840/100728 (36%) | G Loss: -0.115616 | C Loss: 0.004502\n",
            "Epoch: 8 | Batch: 37120/100728 (37%) | G Loss: -0.118742 | C Loss: -0.002776\n",
            "Epoch: 8 | Batch: 38400/100728 (38%) | G Loss: -0.123693 | C Loss: -0.002188\n",
            "Epoch: 8 | Batch: 39680/100728 (39%) | G Loss: -0.126837 | C Loss: 0.001947\n",
            "Epoch: 8 | Batch: 40960/100728 (41%) | G Loss: -0.127550 | C Loss: 0.035307\n",
            "Epoch: 8 | Batch: 42240/100728 (42%) | G Loss: -0.126292 | C Loss: 0.008805\n",
            "Epoch: 8 | Batch: 43520/100728 (43%) | G Loss: -0.122415 | C Loss: -0.005383\n",
            "Epoch: 8 | Batch: 44800/100728 (44%) | G Loss: -0.118101 | C Loss: -0.006874\n",
            "Epoch: 8 | Batch: 46080/100728 (46%) | G Loss: -0.112137 | C Loss: -0.012000\n",
            "Epoch: 8 | Batch: 47360/100728 (47%) | G Loss: -0.108382 | C Loss: 0.032398\n",
            "Epoch: 8 | Batch: 48640/100728 (48%) | G Loss: -0.106317 | C Loss: 0.007664\n",
            "Epoch: 8 | Batch: 49920/100728 (50%) | G Loss: -0.101341 | C Loss: -0.011222\n",
            "Epoch: 8 | Batch: 51200/100728 (51%) | G Loss: -0.098493 | C Loss: -0.011529\n",
            "Epoch: 8 | Batch: 52480/100728 (52%) | G Loss: -0.098515 | C Loss: -0.011932\n",
            "Epoch: 8 | Batch: 53760/100728 (53%) | G Loss: -0.096172 | C Loss: -0.005063\n",
            "Epoch: 8 | Batch: 55040/100728 (55%) | G Loss: -0.097669 | C Loss: -0.006690\n",
            "Epoch: 8 | Batch: 56320/100728 (56%) | G Loss: -0.101810 | C Loss: 0.000761\n",
            "Epoch: 8 | Batch: 57600/100728 (57%) | G Loss: -0.100889 | C Loss: -0.001837\n",
            "Epoch: 8 | Batch: 58880/100728 (58%) | G Loss: -0.102824 | C Loss: -0.009579\n",
            "Epoch: 8 | Batch: 60160/100728 (60%) | G Loss: -0.106223 | C Loss: -0.008032\n",
            "Epoch: 8 | Batch: 61440/100728 (61%) | G Loss: -0.108198 | C Loss: -0.004994\n",
            "Epoch: 8 | Batch: 62720/100728 (62%) | G Loss: -0.109220 | C Loss: -0.006506\n",
            "Epoch: 8 | Batch: 64000/100728 (64%) | G Loss: -0.111461 | C Loss: -0.003524\n",
            "Epoch: 8 | Batch: 65280/100728 (65%) | G Loss: -0.114084 | C Loss: -0.001454\n",
            "Epoch: 8 | Batch: 66560/100728 (66%) | G Loss: -0.116173 | C Loss: 0.001443\n",
            "Epoch: 8 | Batch: 67840/100728 (67%) | G Loss: -0.116533 | C Loss: -0.002113\n",
            "Epoch: 8 | Batch: 69120/100728 (69%) | G Loss: -0.119895 | C Loss: 0.020610\n",
            "Epoch: 8 | Batch: 70400/100728 (70%) | G Loss: -0.122281 | C Loss: -0.001969\n",
            "Epoch: 8 | Batch: 71680/100728 (71%) | G Loss: -0.125040 | C Loss: -0.003407\n",
            "Epoch: 8 | Batch: 72960/100728 (72%) | G Loss: -0.124954 | C Loss: -0.004317\n",
            "Epoch: 8 | Batch: 74240/100728 (74%) | G Loss: -0.124783 | C Loss: -0.003794\n",
            "Epoch: 8 | Batch: 75520/100728 (75%) | G Loss: -0.123727 | C Loss: -0.002699\n",
            "Epoch: 8 | Batch: 76800/100728 (76%) | G Loss: -0.121459 | C Loss: -0.008586\n",
            "Epoch: 8 | Batch: 78080/100728 (78%) | G Loss: -0.121150 | C Loss: -0.007406\n",
            "Epoch: 8 | Batch: 79360/100728 (79%) | G Loss: -0.119582 | C Loss: -0.013320\n",
            "Epoch: 8 | Batch: 80640/100728 (80%) | G Loss: -0.118761 | C Loss: -0.014572\n",
            "Epoch: 8 | Batch: 81920/100728 (81%) | G Loss: -0.121039 | C Loss: -0.011636\n",
            "Epoch: 8 | Batch: 83200/100728 (83%) | G Loss: -0.121691 | C Loss: 0.001588\n",
            "Epoch: 8 | Batch: 84480/100728 (84%) | G Loss: -0.121795 | C Loss: -0.010064\n",
            "Epoch: 8 | Batch: 85760/100728 (85%) | G Loss: -0.121178 | C Loss: -0.006840\n",
            "Epoch: 8 | Batch: 87040/100728 (86%) | G Loss: -0.118396 | C Loss: -0.007655\n",
            "Epoch: 8 | Batch: 88320/100728 (88%) | G Loss: -0.114218 | C Loss: -0.012143\n",
            "Epoch: 8 | Batch: 89600/100728 (89%) | G Loss: -0.112697 | C Loss: 0.018947\n",
            "Epoch: 8 | Batch: 90880/100728 (90%) | G Loss: -0.118514 | C Loss: -0.007324\n",
            "Epoch: 8 | Batch: 92160/100728 (91%) | G Loss: -0.117954 | C Loss: -0.009790\n",
            "Epoch: 8 | Batch: 93440/100728 (93%) | G Loss: -0.115933 | C Loss: -0.009817\n",
            "Epoch: 8 | Batch: 94720/100728 (94%) | G Loss: -0.111614 | C Loss: -0.004901\n",
            "Epoch: 8 | Batch: 96000/100728 (95%) | G Loss: -0.105195 | C Loss: -0.007416\n",
            "Epoch: 8 | Batch: 97280/100728 (97%) | G Loss: -0.101483 | C Loss: -0.012690\n",
            "Epoch: 8 | Batch: 98560/100728 (98%) | G Loss: -0.101827 | C Loss: 0.059765\n",
            "Epoch: 8 | Batch: 99840/100728 (99%) | G Loss: -0.103027 | C Loss: 0.001077\n",
            "* (Train) Epoch: 8 | G Loss: -0.1143 | C Loss: -0.0004\n",
            " scientist dreamed i had to change a cool ? by arguing ? ? ? ? ? i ' m honor ?\n",
            " cook my hate to change a russian diet , to do you get the shiin .\n",
            " one just had a bladder assistant by the only fat assistant that servesgan e\n",
            " i just had a recent neighbor for cremation nudes intolerant i just have eually cleaning eually eually eually esually agree\n",
            " i overheard a german so fat people wage gape fat people from puinee\n",
            " friend kicked a random cannibals who swear i swear i swear i swear i swear a drug dealer\n",
            " like i had a woman with a way ? ? ? ? ? ? ? ? ? ? ? ? ? ? nom .\n",
            " studies cook my class to be class every receptionist i always wondered why the class tend to get the class removed .\n",
            " so i had a jewish math class ? ? i thought ? ? ? ? ? ? i thought ? ? ? ? ? are ?\n",
            " cardi bros to the fairy ? ? ? ? ? phlouce ? ? ? ? ?\n",
            "\n",
            "Epoch: 9 | Batch: 0/100728 (0%) | G Loss: -0.106686 | C Loss: -0.005956\n",
            "Epoch: 9 | Batch: 1280/100728 (1%) | G Loss: -0.104435 | C Loss: -0.005727\n",
            "Epoch: 9 | Batch: 2560/100728 (3%) | G Loss: -0.101969 | C Loss: -0.005350\n",
            "Epoch: 9 | Batch: 3840/100728 (4%) | G Loss: -0.100810 | C Loss: -0.001533\n",
            "Epoch: 9 | Batch: 5120/100728 (5%) | G Loss: -0.098491 | C Loss: 0.000707\n",
            "Epoch: 9 | Batch: 6400/100728 (6%) | G Loss: -0.095386 | C Loss: -0.003950\n",
            "Epoch: 9 | Batch: 7680/100728 (8%) | G Loss: -0.092795 | C Loss: 0.009157\n",
            "Epoch: 9 | Batch: 8960/100728 (9%) | G Loss: -0.091090 | C Loss: 0.005970\n",
            "Epoch: 9 | Batch: 10240/100728 (10%) | G Loss: -0.091212 | C Loss: -0.008566\n",
            "Epoch: 9 | Batch: 11520/100728 (11%) | G Loss: -0.091104 | C Loss: -0.007670\n",
            "Epoch: 9 | Batch: 12800/100728 (13%) | G Loss: -0.093157 | C Loss: -0.008170\n",
            "Epoch: 9 | Batch: 14080/100728 (14%) | G Loss: -0.091552 | C Loss: -0.002840\n",
            "Epoch: 9 | Batch: 15360/100728 (15%) | G Loss: -0.089247 | C Loss: -0.007424\n",
            "Epoch: 9 | Batch: 16640/100728 (17%) | G Loss: -0.087448 | C Loss: -0.009907\n",
            "Epoch: 9 | Batch: 17920/100728 (18%) | G Loss: -0.086375 | C Loss: -0.011375\n",
            "Epoch: 9 | Batch: 19200/100728 (19%) | G Loss: -0.086147 | C Loss: -0.006038\n",
            "Epoch: 9 | Batch: 20480/100728 (20%) | G Loss: -0.091139 | C Loss: -0.003157\n",
            "Epoch: 9 | Batch: 21760/100728 (22%) | G Loss: -0.095654 | C Loss: 0.005697\n",
            "Epoch: 9 | Batch: 23040/100728 (23%) | G Loss: -0.098122 | C Loss: -0.009054\n",
            "Epoch: 9 | Batch: 24320/100728 (24%) | G Loss: -0.102066 | C Loss: -0.008260\n",
            "Epoch: 9 | Batch: 25600/100728 (25%) | G Loss: -0.107433 | C Loss: -0.007442\n",
            "Epoch: 9 | Batch: 26880/100728 (27%) | G Loss: -0.111384 | C Loss: -0.005844\n",
            "Epoch: 9 | Batch: 28160/100728 (28%) | G Loss: -0.115450 | C Loss: -0.002558\n",
            "Epoch: 9 | Batch: 29440/100728 (29%) | G Loss: -0.118932 | C Loss: -0.006787\n",
            "Epoch: 9 | Batch: 30720/100728 (30%) | G Loss: -0.124346 | C Loss: -0.000756\n",
            "Epoch: 9 | Batch: 32000/100728 (32%) | G Loss: -0.128352 | C Loss: -0.003081\n",
            "Epoch: 9 | Batch: 33280/100728 (33%) | G Loss: -0.133843 | C Loss: -0.006480\n",
            "Epoch: 9 | Batch: 34560/100728 (34%) | G Loss: -0.138129 | C Loss: -0.000412\n",
            "Epoch: 9 | Batch: 35840/100728 (36%) | G Loss: -0.139610 | C Loss: -0.003342\n",
            "Epoch: 9 | Batch: 37120/100728 (37%) | G Loss: -0.141214 | C Loss: -0.005217\n",
            "Epoch: 9 | Batch: 38400/100728 (38%) | G Loss: -0.138336 | C Loss: 0.030936\n",
            "Epoch: 9 | Batch: 39680/100728 (39%) | G Loss: -0.135002 | C Loss: 0.007987\n",
            "Epoch: 9 | Batch: 40960/100728 (41%) | G Loss: -0.132504 | C Loss: -0.007823\n",
            "Epoch: 9 | Batch: 42240/100728 (42%) | G Loss: -0.128196 | C Loss: -0.016375\n",
            "Epoch: 9 | Batch: 43520/100728 (43%) | G Loss: -0.124588 | C Loss: -0.018735\n",
            "Epoch: 9 | Batch: 44800/100728 (44%) | G Loss: -0.122859 | C Loss: -0.016696\n",
            "Epoch: 9 | Batch: 46080/100728 (46%) | G Loss: -0.124129 | C Loss: -0.011631\n",
            "Epoch: 9 | Batch: 47360/100728 (47%) | G Loss: -0.128556 | C Loss: -0.013951\n",
            "Epoch: 9 | Batch: 48640/100728 (48%) | G Loss: -0.131592 | C Loss: 0.006948\n",
            "Epoch: 9 | Batch: 49920/100728 (50%) | G Loss: -0.135250 | C Loss: -0.006798\n",
            "Epoch: 9 | Batch: 51200/100728 (51%) | G Loss: -0.137995 | C Loss: -0.005316\n",
            "Epoch: 9 | Batch: 52480/100728 (52%) | G Loss: -0.139537 | C Loss: -0.003038\n",
            "Epoch: 9 | Batch: 53760/100728 (53%) | G Loss: -0.139683 | C Loss: -0.000353\n",
            "Epoch: 9 | Batch: 55040/100728 (55%) | G Loss: -0.141167 | C Loss: 0.003068\n",
            "Epoch: 9 | Batch: 56320/100728 (56%) | G Loss: -0.142846 | C Loss: 0.003981\n",
            "Epoch: 9 | Batch: 57600/100728 (57%) | G Loss: -0.143362 | C Loss: 0.001660\n",
            "Epoch: 9 | Batch: 58880/100728 (58%) | G Loss: -0.141347 | C Loss: -0.002064\n",
            "Epoch: 9 | Batch: 60160/100728 (60%) | G Loss: -0.135778 | C Loss: 0.006422\n",
            "Epoch: 9 | Batch: 61440/100728 (61%) | G Loss: -0.128219 | C Loss: 0.002540\n",
            "Epoch: 9 | Batch: 62720/100728 (62%) | G Loss: -0.117674 | C Loss: -0.003273\n",
            "Epoch: 9 | Batch: 64000/100728 (64%) | G Loss: -0.112145 | C Loss: 0.011382\n",
            "Epoch: 9 | Batch: 65280/100728 (65%) | G Loss: -0.099935 | C Loss: 0.045931\n",
            "Epoch: 9 | Batch: 66560/100728 (66%) | G Loss: -0.099086 | C Loss: 0.002481\n",
            "Epoch: 9 | Batch: 67840/100728 (67%) | G Loss: -0.098313 | C Loss: -0.011425\n",
            "Epoch: 9 | Batch: 69120/100728 (69%) | G Loss: -0.099074 | C Loss: 0.003487\n",
            "Epoch: 9 | Batch: 70400/100728 (70%) | G Loss: -0.106520 | C Loss: 0.011056\n",
            "Epoch: 9 | Batch: 71680/100728 (71%) | G Loss: -0.108589 | C Loss: -0.010420\n",
            "Epoch: 9 | Batch: 72960/100728 (72%) | G Loss: -0.109577 | C Loss: -0.007693\n",
            "Epoch: 9 | Batch: 74240/100728 (74%) | G Loss: -0.111465 | C Loss: -0.008255\n",
            "Epoch: 9 | Batch: 75520/100728 (75%) | G Loss: -0.114328 | C Loss: -0.000656\n",
            "Epoch: 9 | Batch: 76800/100728 (76%) | G Loss: -0.115001 | C Loss: 0.000370\n",
            "Epoch: 9 | Batch: 78080/100728 (78%) | G Loss: -0.117258 | C Loss: 0.010915\n",
            "Epoch: 9 | Batch: 79360/100728 (79%) | G Loss: -0.115421 | C Loss: 0.010380\n",
            "Epoch: 9 | Batch: 80640/100728 (80%) | G Loss: -0.115803 | C Loss: -0.001932\n",
            "Epoch: 9 | Batch: 81920/100728 (81%) | G Loss: -0.115531 | C Loss: -0.004252\n",
            "Epoch: 9 | Batch: 83200/100728 (83%) | G Loss: -0.116319 | C Loss: -0.000149\n",
            "Epoch: 9 | Batch: 84480/100728 (84%) | G Loss: -0.116595 | C Loss: -0.006595\n",
            "Epoch: 9 | Batch: 85760/100728 (85%) | G Loss: -0.121062 | C Loss: 0.838213\n",
            "Epoch: 9 | Batch: 87040/100728 (86%) | G Loss: -0.131430 | C Loss: 0.129268\n",
            "Epoch: 9 | Batch: 88320/100728 (88%) | G Loss: -0.122947 | C Loss: 0.019699\n",
            "Epoch: 9 | Batch: 89600/100728 (89%) | G Loss: -0.125475 | C Loss: 0.020947\n",
            "Epoch: 9 | Batch: 90880/100728 (90%) | G Loss: -0.126839 | C Loss: 0.012502\n",
            "Epoch: 9 | Batch: 92160/100728 (91%) | G Loss: -0.124806 | C Loss: 0.013787\n",
            "Epoch: 9 | Batch: 93440/100728 (93%) | G Loss: -0.114751 | C Loss: 0.007991\n",
            "Epoch: 9 | Batch: 94720/100728 (94%) | G Loss: -0.099091 | C Loss: -0.002527\n",
            "Epoch: 9 | Batch: 96000/100728 (95%) | G Loss: -0.088323 | C Loss: 0.018306\n",
            "Epoch: 9 | Batch: 97280/100728 (97%) | G Loss: -0.088549 | C Loss: -0.003239\n",
            "Epoch: 9 | Batch: 98560/100728 (98%) | G Loss: -0.084760 | C Loss: -0.006179\n",
            "Epoch: 9 | Batch: 99840/100728 (99%) | G Loss: -0.083521 | C Loss: -0.024215\n",
            "* (Train) Epoch: 9 | G Loss: -0.1138 | C Loss: 0.0062\n",
            " i so i who insult this one pilot who always pee in one boy in one pilot this boy\n",
            "tile so in that he always had in commonricks to blow his laughing before he chopped down\n",
            " i ' insult this most that in circles . but you always laughing in circles .\n",
            " passenger did dad cena pull his self lawyer repair meeting in the urinal and always repairs that really repair engines ? his neighbor .\n",
            "key did what louis ck repairs and his broken pussy ? repair pee repair pee repair winner that it improved that pee pee .\n",
            " how dolip boy insult his broken coat ? he swear loudly in the who who always bone his pee .\n",
            " what is my really always always always poke ? it always hits in it . it coming .\n",
            " what do did masturbation insult ahead ahead in broken in the counter counter baiter and always calm baiters in broken balls broken elementary school counter engine engine winner\n",
            " do ? why ? billy asian reptile repair engines ? ? really ? really ? really ? really loudly ? that ? really ?\n",
            " nsfw how did ' quadriplegic reallylip boy and his broken coat ? who always repair his broken coat repair ? who ? repair pee sumo pee ?\n",
            "\n",
            "Epoch: 10 | Batch: 0/100728 (0%) | G Loss: -0.084674 | C Loss: -0.021937\n",
            "Epoch: 10 | Batch: 1280/100728 (1%) | G Loss: -0.081564 | C Loss: -0.027250\n",
            "Epoch: 10 | Batch: 2560/100728 (3%) | G Loss: -0.080544 | C Loss: -0.027085\n",
            "Epoch: 10 | Batch: 3840/100728 (4%) | G Loss: -0.086963 | C Loss: -0.022423\n",
            "Epoch: 10 | Batch: 5120/100728 (5%) | G Loss: -0.088965 | C Loss: -0.023139\n",
            "Epoch: 10 | Batch: 6400/100728 (6%) | G Loss: -0.093632 | C Loss: -0.014940\n",
            "Epoch: 10 | Batch: 7680/100728 (8%) | G Loss: -0.096537 | C Loss: -0.014771\n",
            "Epoch: 10 | Batch: 8960/100728 (9%) | G Loss: -0.099445 | C Loss: -0.011191\n",
            "Epoch: 10 | Batch: 10240/100728 (10%) | G Loss: -0.100631 | C Loss: -0.009075\n",
            "Epoch: 10 | Batch: 11520/100728 (11%) | G Loss: -0.101249 | C Loss: -0.005667\n",
            "Epoch: 10 | Batch: 12800/100728 (13%) | G Loss: -0.100766 | C Loss: -0.006834\n",
            "Epoch: 10 | Batch: 14080/100728 (14%) | G Loss: -0.100547 | C Loss: -0.006159\n",
            "Epoch: 10 | Batch: 15360/100728 (15%) | G Loss: -0.100881 | C Loss: -0.004473\n",
            "Epoch: 10 | Batch: 16640/100728 (17%) | G Loss: -0.100785 | C Loss: 0.000025\n",
            "Epoch: 10 | Batch: 17920/100728 (18%) | G Loss: -0.100281 | C Loss: -0.004527\n",
            "Epoch: 10 | Batch: 19200/100728 (19%) | G Loss: -0.100508 | C Loss: -0.000894\n",
            "Epoch: 10 | Batch: 20480/100728 (20%) | G Loss: -0.099109 | C Loss: 0.003251\n",
            "Epoch: 10 | Batch: 21760/100728 (22%) | G Loss: -0.095915 | C Loss: -0.001846\n",
            "Epoch: 10 | Batch: 23040/100728 (23%) | G Loss: -0.092080 | C Loss: 0.020752\n",
            "Epoch: 10 | Batch: 24320/100728 (24%) | G Loss: -0.092309 | C Loss: -0.002932\n",
            "Epoch: 10 | Batch: 25600/100728 (25%) | G Loss: -0.089922 | C Loss: 0.000001\n",
            "Epoch: 10 | Batch: 26880/100728 (27%) | G Loss: -0.092456 | C Loss: -0.001851\n",
            "Epoch: 10 | Batch: 28160/100728 (28%) | G Loss: -0.092673 | C Loss: -0.012806\n",
            "Epoch: 10 | Batch: 29440/100728 (29%) | G Loss: -0.094988 | C Loss: -0.011168\n",
            "Epoch: 10 | Batch: 30720/100728 (30%) | G Loss: -0.097776 | C Loss: -0.008776\n",
            "Epoch: 10 | Batch: 32000/100728 (32%) | G Loss: -0.099477 | C Loss: -0.009895\n",
            "Epoch: 10 | Batch: 33280/100728 (33%) | G Loss: -0.098675 | C Loss: -0.004733\n",
            "Epoch: 10 | Batch: 34560/100728 (34%) | G Loss: -0.098916 | C Loss: 0.024700\n",
            "Epoch: 10 | Batch: 35840/100728 (36%) | G Loss: -0.099077 | C Loss: -0.005691\n",
            "Epoch: 10 | Batch: 37120/100728 (37%) | G Loss: -0.102739 | C Loss: -0.001552\n",
            "Epoch: 10 | Batch: 38400/100728 (38%) | G Loss: -0.102478 | C Loss: -0.009533\n",
            "Epoch: 10 | Batch: 39680/100728 (39%) | G Loss: -0.102391 | C Loss: -0.009584\n",
            "Epoch: 10 | Batch: 40960/100728 (41%) | G Loss: -0.104360 | C Loss: -0.007461\n",
            "Epoch: 10 | Batch: 42240/100728 (42%) | G Loss: -0.105620 | C Loss: -0.006590\n",
            "Epoch: 10 | Batch: 43520/100728 (43%) | G Loss: -0.104936 | C Loss: -0.009679\n",
            "Epoch: 10 | Batch: 44800/100728 (44%) | G Loss: -0.106413 | C Loss: -0.009022\n",
            "Epoch: 10 | Batch: 46080/100728 (46%) | G Loss: -0.108128 | C Loss: -0.008377\n",
            "Epoch: 10 | Batch: 47360/100728 (47%) | G Loss: -0.107398 | C Loss: 0.003843\n",
            "Epoch: 10 | Batch: 48640/100728 (48%) | G Loss: -0.109411 | C Loss: 0.001111\n",
            "Epoch: 10 | Batch: 49920/100728 (50%) | G Loss: -0.111290 | C Loss: -0.003731\n",
            "Epoch: 10 | Batch: 51200/100728 (51%) | G Loss: -0.113222 | C Loss: -0.003975\n",
            "Epoch: 10 | Batch: 52480/100728 (52%) | G Loss: -0.113286 | C Loss: 0.004907\n",
            "Epoch: 10 | Batch: 53760/100728 (53%) | G Loss: -0.112211 | C Loss: -0.004014\n",
            "Epoch: 10 | Batch: 55040/100728 (55%) | G Loss: -0.111779 | C Loss: 0.001653\n",
            "Epoch: 10 | Batch: 56320/100728 (56%) | G Loss: -0.106835 | C Loss: 0.002999\n",
            "Epoch: 10 | Batch: 57600/100728 (57%) | G Loss: -0.107161 | C Loss: -0.006058\n",
            "Epoch: 10 | Batch: 58880/100728 (58%) | G Loss: -0.104676 | C Loss: -0.012054\n",
            "Epoch: 10 | Batch: 60160/100728 (60%) | G Loss: -0.106138 | C Loss: -0.013132\n",
            "Epoch: 10 | Batch: 61440/100728 (61%) | G Loss: -0.107150 | C Loss: 0.006930\n",
            "Epoch: 10 | Batch: 62720/100728 (62%) | G Loss: -0.112659 | C Loss: 0.002159\n",
            "Epoch: 10 | Batch: 64000/100728 (64%) | G Loss: -0.116264 | C Loss: -0.004920\n",
            "Epoch: 10 | Batch: 65280/100728 (65%) | G Loss: -0.118669 | C Loss: -0.007786\n",
            "Epoch: 10 | Batch: 66560/100728 (66%) | G Loss: -0.121087 | C Loss: -0.004991\n",
            "Epoch: 10 | Batch: 67840/100728 (67%) | G Loss: -0.124219 | C Loss: -0.006922\n",
            "Epoch: 10 | Batch: 69120/100728 (69%) | G Loss: -0.125636 | C Loss: -0.006807\n",
            "Epoch: 10 | Batch: 70400/100728 (70%) | G Loss: -0.126553 | C Loss: -0.005603\n",
            "Epoch: 10 | Batch: 71680/100728 (71%) | G Loss: -0.127045 | C Loss: -0.005698\n",
            "Epoch: 10 | Batch: 72960/100728 (72%) | G Loss: -0.126497 | C Loss: -0.005048\n",
            "Epoch: 10 | Batch: 74240/100728 (74%) | G Loss: -0.125382 | C Loss: -0.004614\n",
            "Epoch: 10 | Batch: 75520/100728 (75%) | G Loss: -0.124402 | C Loss: -0.006138\n",
            "Epoch: 10 | Batch: 76800/100728 (76%) | G Loss: -0.122755 | C Loss: -0.004391\n",
            "Epoch: 10 | Batch: 78080/100728 (78%) | G Loss: -0.121239 | C Loss: 0.000784\n",
            "Epoch: 10 | Batch: 79360/100728 (79%) | G Loss: -0.119643 | C Loss: -0.003245\n",
            "Epoch: 10 | Batch: 80640/100728 (80%) | G Loss: -0.119926 | C Loss: -0.007761\n",
            "Epoch: 10 | Batch: 81920/100728 (81%) | G Loss: -0.118642 | C Loss: -0.008464\n",
            "Epoch: 10 | Batch: 83200/100728 (83%) | G Loss: -0.116591 | C Loss: -0.008123\n",
            "Epoch: 10 | Batch: 84480/100728 (84%) | G Loss: -0.116011 | C Loss: -0.003155\n",
            "Epoch: 10 | Batch: 85760/100728 (85%) | G Loss: -0.116581 | C Loss: -0.008904\n",
            "Epoch: 10 | Batch: 87040/100728 (86%) | G Loss: -0.120158 | C Loss: 0.025901\n",
            "Epoch: 10 | Batch: 88320/100728 (88%) | G Loss: -0.122125 | C Loss: -0.005872\n",
            "Epoch: 10 | Batch: 89600/100728 (89%) | G Loss: -0.122225 | C Loss: -0.006140\n",
            "Epoch: 10 | Batch: 90880/100728 (90%) | G Loss: -0.124832 | C Loss: -0.002806\n",
            "Epoch: 10 | Batch: 92160/100728 (91%) | G Loss: -0.124383 | C Loss: -0.002511\n",
            "Epoch: 10 | Batch: 93440/100728 (93%) | G Loss: -0.125137 | C Loss: -0.000199\n",
            "Epoch: 10 | Batch: 94720/100728 (94%) | G Loss: -0.124325 | C Loss: -0.001307\n",
            "Epoch: 10 | Batch: 96000/100728 (95%) | G Loss: -0.124601 | C Loss: 0.000708\n",
            "Epoch: 10 | Batch: 97280/100728 (97%) | G Loss: -0.123488 | C Loss: -0.000716\n",
            "Epoch: 10 | Batch: 98560/100728 (98%) | G Loss: -0.120048 | C Loss: -0.003894\n",
            "Epoch: 10 | Batch: 99840/100728 (99%) | G Loss: -0.118298 | C Loss: -0.007743\n",
            "* (Train) Epoch: 10 | G Loss: -0.1084 | C Loss: -0.0034\n",
            " what does the light of gay center of light to light other to each other ? just switchers .\n",
            " men can to make their house supporters after they are both only to .\n",
            " do pornstars of our supporters seems taller optimist seems taller . don ' t feel taller until they have to make directions .\n",
            " whore for trump supporting me to be the third price for a quat ? neighbor ?\n",
            " ad straw just just just just stamp just particular .\n",
            " kardashian of the sperm of the worlds supporter of they are only to cast .\n",
            " of theworthyworthy states she seems as she wants to produce the legal .\n",
            " if male whale is the dead female . you are all of dead female from dead men .\n",
            " do albino use to make bagels after each other is just likeworthyworthyworthy .\n",
            " woman for ethiopian immigrants had never kinder hillary clinton supporters never tease hillary she never had to chernobyl her division .\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Critic Loss')"
            ]
          },
          "execution_count": 58,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "########################################## EVEN FURTHER TRAINING #########################################\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialise variables\n",
        "epochs=10\n",
        "lr=5e-4\n",
        "interval=10\n",
        "cuda=torch.cuda.is_available()\n",
        "n_critic = 5\n",
        "gp_lambda = 20\n",
        "\n",
        "# Setup Adam optimizer for both\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=lr)\n",
        "c_optimizer = optim.Adam(critic.parameters(), lr=lr)\n",
        "\n",
        "# Initialise losses\n",
        "total_loss = []\n",
        "total_g_loss = []\n",
        "total_c_loss = []\n",
        "\n",
        "if cuda:\n",
        "   generator = generator.cuda()\n",
        "   critic = critic.cuda()\n",
        "    \n",
        "   print('G Parameters:', sum([p.numel() for p in generator.parameters() if p.requires_grad]))\n",
        "   print('C Parameters:', sum([p.numel() for p in critic.parameters() if p.requires_grad]))\n",
        "    \n",
        "   best_loss = np.inf\n",
        "    \n",
        "   for epoch in range(1, epochs + 1):\n",
        "     g_loss, c_loss = train_gan(epoch)\n",
        "     loss = g_loss + c_loss\n",
        "     total_loss.append(loss)\n",
        "     total_g_loss.append(g_loss)\n",
        "     total_c_loss.append(c_loss)\n",
        "          \n",
        "     if loss < best_loss:\n",
        "        best_loss = loss\n",
        "        print('* Saved')\n",
        "        torch.save(generator.state_dict(), 'generator.th{}'.format(epoch))\n",
        "        torch.save(critic.state_dict(), 'critic.th{}'.format(epoch))\n",
        "\n",
        "     for i in range(10):\n",
        "        joke = generate_joke(test_keywords[i].reshape(1, maxlen), generator.cpu(), stepper, decoder, tokenizer, start=[2])\n",
        "        print(joke)\n",
        "\n",
        "     generator = generator.cuda()\n",
        "     print(\"\")\n",
        "\n",
        "# Plot results\n",
        "fig, axs = plt.subplots(3)\n",
        "fig.set_size_inches(10, 10)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "axs[0].plot(range(epochs), total_loss)\n",
        "axs[0].set_title('Total Loss')\n",
        "axs[1].plot(range(epochs), total_g_loss)\n",
        "axs[1].set_title('Generator Loss')\n",
        "axs[2].plot(range(epochs), total_c_loss)\n",
        "axs[2].set_title('Critic Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhXWYK2H4PCR"
      },
      "outputs": [],
      "source": [
        "torch.save(generator.state_dict(), 'generator.th')\n",
        "torch.save(critic.state_dict(), 'critic.th')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90UcVcaa1k62"
      },
      "outputs": [],
      "source": [
        "############################### CREATE MODELS AND LOAD WEIGHTS ############################\n",
        "n_layers = 5\n",
        "block_dim = 100\n",
        "\n",
        "# Create model and load weights\n",
        "generator = Generator(n_layers, block_dim)\n",
        "generator.eval()\n",
        "generator.load_state_dict(torch.load('/content/generator.th', map_location='cpu'))\n",
        "model, encoder, stepper, decoder = r_seq2seq(weights='/content/reconstruction_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS4sNlPFtMbY",
        "outputId": "8890c874-f012-4380-c21b-54202dc08da4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KEYWORDS: switch light arguing\n",
            "TRUE: how do you end two deaf persons ' arguing ? switch off the light .\n",
            "GENERATED  how can you switch as fadinburgach ness are like bbq style from the light ? a switch .\n",
            "\n",
            "KEYWORDS: suckin lot lose hurricane house first common blowin blonde\n",
            "TRUE: what does a blonde have in common with a hurricane ? first there is a lot of suckin and blowin , then you lose your house .\n",
            "GENERATED  the ukraine if you are with the rain moth ? it ? ? ? ? ? a rain moth blue and then\n",
            "\n",
            "KEYWORDS: went floats day circles\n",
            "TRUE: i went to a white pride parade the other day . the floats just kept going around in circles about 200 miles per hour .\n",
            "GENERATED  wanna rich on the other day they went on one side of the other day they\n",
            "\n",
            "KEYWORDS: would neighbor joke home close\n",
            "TRUE: i would make a joke about my neighbor . but it would be too close to home\n",
            "GENERATED  did you think his neighbor loves to be his swedishpical cycle like you are always in south east swedish\n",
            "\n",
            "KEYWORDS: god everything difference\n",
            "TRUE: what is the difference between god and you ex wife ? god only wants 10 things . your ex wife wants half of everything .\n",
            "GENERATED  why has been an inspiration when a hotdog driver away away by pets . otherwise they murdered it .\n",
            "\n",
            "KEYWORDS: swear castrate\n",
            "TRUE: i swear , i will castrate you do it , you won t . no balls bro .\n",
            "GENERATED  why do you tie rich on his king ? because they were on king cycle on him .\n",
            "\n",
            "KEYWORDS: woman way tits looking eyes checks\n",
            "TRUE: the first thing a man notices about a woman is her eyes and when he made sure it is not looking his way , he checks out her\n",
            "GENERATED  canram doramno identify if the it gets away because it gets away because it grows away from\n",
            "\n",
            "KEYWORDS: get dead\n",
            "TRUE: what is your favourite insult joke ? i will get it started 2090 called , you are dead and nobody misses you\n",
            "GENERATED  what do geologist call once with the vaxx land ? are putin blown away his dead\n",
            "\n",
            "KEYWORDS: way thought mall harsh\n",
            "TRUE: trump hows that mexican mall going ? mall ? we thought you said wall trump no way that is harsh , also hows that muslim band looking\n",
            "GENERATED  how belongs to it if it belongs first airach clip it belongs ? it belongs was you are .\n",
            "\n",
            "KEYWORDS: anyone\n",
            "TRUE: keanu reeves donates so much blood that anyone who has ever received donor blood is at least 6 keanu reeves .\n",
            "GENERATED  why do you listen to anyone who don ' t get rich ? because they don ' t like it . in the tents .\n",
            "\n",
            "KEYWORDS: sneezes\n",
            "TRUE: what does a nut say when he sneezes ? ca shew\n",
            "GENERATED  you can t write air ba dumds it has it cycle it it cycle it cycle it\n",
            "\n",
            "KEYWORDS: nose man ejaculating arrested\n",
            "TRUE: a man was arrested for ejaculating out his nose but he did nutting wrong\n",
            "GENERATED  you if if they noticed it might peek the own .\n",
            "\n",
            "KEYWORDS: write called\n",
            "TRUE: my girlfriend asked me to write an inspirational poem about our love life . i called it , the load less swallowed\n",
            "GENERATED  how does neymar want when he has it ? the coldest man it was called his pee .\n",
            "\n",
            "KEYWORDS: understand talk heroin\n",
            "TRUE: my local police chief does a talk on heroin so you can ' t understand any of it .\n",
            "GENERATED  milk why do you name your golden bride away ? because it has your own\n",
            "\n",
            "KEYWORDS: used thought think telling look brain\n",
            "TRUE: i used to think the brain was the most important organ . then i thought , look what is telling me that .\n",
            "GENERATED  think what the look election of red clucky are not silly but you think they were not used by the brain\n",
            "\n",
            "KEYWORDS: tumblr trending saw dashboard\n",
            "TRUE: so i saw that princess diana is trending on tumblr . she is all over the dashboard\n",
            "GENERATED  wanna know why the sad complimenty isn ' t inside the nut has smiley or nut bworthy\n",
            "\n",
            "KEYWORDS: unless speed multiply light energy\n",
            "TRUE: unless you multiply yourself by the speed of light then you energy .\n",
            "GENERATED  youtube poem roses are so it doesn ' t remove it because it puts it on my own .\n",
            "\n",
            "KEYWORDS: hollow hillary head\n",
            "TRUE: what is more hollow than donald trump is head ? hillary is diazepam pen .\n",
            "GENERATED  can you hear what has hillary belonged home before they are in ? a .\n",
            "\n",
            "KEYWORDS: dog boat\n",
            "TRUE: why does a dog on a you boat have a deep bark ? because he is a sub woofer .\n",
            "GENERATED  moon cycle can ' t vicious cycleary cycle pathdiess on a boat is boat\n",
            "\n",
            "KEYWORDS: reaction\n",
            "TRUE: why don ' t people tell chemistry jokes ? because they never get a reaction .\n",
            "GENERATED  i donated your reaction on cyky swedish tape are not one swedish tapey .\n",
            "\n",
            "KEYWORDS: yet woman w q infront cow back\n",
            "TRUE: q what is infront of the woman , yet , at the back of the cow ? a w\n",
            "GENERATED  how do superman hate circumgo ' king dunk ? q francis are you da dunking ?\n",
            "\n",
            "KEYWORDS: nazi followers coming\n",
            "TRUE: when hitler killed himself his followers did nazi that coming\n",
            "GENERATED  how suh do if manual to rollerbs ? it is not warm to run on once air brakes\n",
            "\n",
            "KEYWORDS: \n",
            "TRUE: \n",
            "GENERATED  know why did one blondes say hi on the blunder ? because he was juan on him .\n",
            "\n",
            "KEYWORDS: sperm directions ask\n",
            "TRUE: why does it take millions of sperm to fertilize one egg ? because they won ' t ask for directions\n",
            "GENERATED  youtube once owned when a suicide remover was done to ask the ones it was done by the reports i was done a puppy\n",
            "\n",
            "KEYWORDS: experience belittling attacked\n",
            "TRUE: i was attacked by tiny bees . the experience was belittling .\n",
            "GENERATED  seems are you attacked when it attacked bungee cycle pathtricies\n",
            "\n",
            "KEYWORDS: spent proud pays lot life brothels bills\n",
            "TRUE: i have spent a lot of my life in brothels . i am not proud of it , but it pays the bills .\n",
            "GENERATED  wanna know the bottle has on air conditioning on artificial hands on a house ? it pays on\n",
            "\n",
            "KEYWORDS: went tiers even cake\n",
            "TRUE: i went to a really depressing wedding recently . even the cake was in tiers .\n",
            "GENERATED  why do a giant dog throw into a louwordary dog ? it was .\n",
            "\n",
            "KEYWORDS: song catchy\n",
            "TRUE: a stormtrooper walks into a cantina stormtrooper damn this song is catchy\n",
            "GENERATED  how are you heading from like cybery milk on one east ? they are on davs\n",
            "\n",
            "KEYWORDS: whens door ajar\n",
            "TRUE: whens a door not a door ? when its ajar .\n",
            "GENERATED  how do blondes want to landmine is a saudisman ? a saudis .\n",
            "\n",
            "KEYWORDS: little difference\n",
            "TRUE: what is the difference between ancient religious texts and fake news ? a little over 2000 years\n",
            "GENERATED  why has does ramsay remove on ed on a cycle path ? that is a cycle path\n",
            "\n",
            "KEYWORDS: call\n",
            "TRUE: what do you call a graduated spider ? a web designer\n",
            "GENERATED  how peanuts call peanuts licking the pillsbury dough stones it scares his breath as it scares it\n",
            "\n",
            "KEYWORDS: see mother father beauty\n",
            "TRUE: a son asks his father . a son asks his father dad , what is beauty ? do you see your mother ? yes well that is not it\n",
            "GENERATED  why do rich people only see on a black hole crist bleading it will see the cycle\n",
            "\n",
            "KEYWORDS: rapist predator call\n",
            "TRUE: what do you call an immigrant fighting a rapist ? alien vs . predator\n",
            "GENERATED  what should you call on motherie the vote ? because you have a mother away on your mother\n",
            "\n",
            "KEYWORDS: groups even\n",
            "TRUE: why do white girls always walk in groups with odd numbers ? they can ' t even\n",
            "GENERATED you why do nasa make if they don ' t own on on the enterprise\n",
            "\n",
            "KEYWORDS: rest made funeral awkward\n",
            "TRUE: got caught sniffing my sisters panties yesterday it made the rest of her funeral very awkward .\n",
            "GENERATED  blondes douchay on your funeral as your grandma let him peasant nuts\n",
            "\n",
            "KEYWORDS: want making joke hear\n",
            "TRUE: you want to hear a joke ? me making it on the front page .\n",
            "GENERATED  can douchetrude as on air force tulips on ? they are making on the cycle path cycle\n",
            "\n",
            "KEYWORDS: week set 100\n",
            "TRUE: set your wifi password to 100 so when someone ask tell them it is how many times a week this gets reposted .\n",
            "GENERATED  why did because set of the rain parats but it is a rigged cycle\n",
            "\n",
            "KEYWORDS: fascist faggot call axe\n",
            "TRUE: what do you call a faggot with an axe ? a fascist\n",
            "GENERATED  can you do with president trump supporters ? because they are a fascist you only have faggot\n",
            "\n",
            "KEYWORDS: vegetables thumbs people know fingers\n",
            "TRUE: you know how all thumbs are fingers , but not all fingers are thumbs ? some people can be vegetables , but vegetables can ' t be people .\n",
            "GENERATED  how can you know air cycle cycle cycle cycle cycle on saudi arabia only are you juan brist\n",
            "\n",
            "KEYWORDS: marc homosexual group friends\n",
            "TRUE: they say one in ten men are homosexual in my group of friends i ' m pretty sure it is marc . he is really cute\n",
            "GENERATED  how can you know why tribe res are getting a bitter taste ? they are both\n",
            "\n",
            "KEYWORDS: engineers\n",
            "TRUE: a good joke for the engineers out there free time\n",
            "GENERATED  how does white guys do when they put one swedish holes in his bleb ? trains\n",
            "\n",
            "KEYWORDS: writing song getting end\n",
            "TRUE: i ' m writing a song about getting my front door lock replaced . there is a lovely key change at the end .\n",
            "GENERATED  forty blondes do rich franberries are when you wave blue coatranberries it is\n",
            "\n",
            "KEYWORDS: charge\n",
            "TRUE: i gave away all of my dead batteries free of charge .\n",
            "GENERATED  how can dodger do you get pride ? because they can file you haven t like cum\n",
            "\n",
            "KEYWORDS: point life diarrhea 80\n",
            "TRUE: studies show that 80 of redditors suffer from diarrhea at some point in life then why are the rest enjoying it ?\n",
            "GENERATED  wanna hear if his 80 did hill worry about the brick wall on it ? it was tearable .\n",
            "\n",
            "KEYWORDS: someone makes cents call\n",
            "TRUE: what do you call a bad european banker that talks gibberish ? someone that makes no cents .\n",
            "GENERATED  wanna call what on her own a female ride ? they are on her hee on her broom\n",
            "\n",
            "KEYWORDS: win olympics logic chance\n",
            "TRUE: to win the olympics , you must go big or go home . by that logic , the refugee team never had a chance .\n",
            "GENERATED  why do you allow air conditioning a chance of united airlines ? they can t get a chance\n",
            "\n",
            "KEYWORDS: frank burn\n",
            "TRUE: why won ' t people let hitler go to the bar bq ? he ' ll just burn the frank ' s\n",
            "GENERATED  how do white people do on ? they are frank on frank ? frank ?\n",
            "\n",
            "KEYWORDS: porn disabled\n",
            "TRUE: is all your porn here disabled ? no it is regular porn you sick fuck .\n",
            "GENERATED  his grandfather blown away his car insurance through the disabled zone because he was disabled . he won ' t run away\n",
            "\n",
            "KEYWORDS: lazy descirbe\n",
            "TRUE: i can descirbe myself in just two words . lazy .\n",
            "GENERATED  how many luck . he isn ' t debelbell . he was deber\n",
            "\n",
            "KEYWORDS: wife tequila cliff\n",
            "TRUE: why did the mexican man throw his wife off of a cliff ? tequila\n",
            "GENERATED  can i do as like air conditioning on bakery ? throw on a cliff on bakery buh buh dum tism\n",
            "\n",
            "KEYWORDS: nuts heard guy glitter dipped\n",
            "TRUE: have you heard about the guy who dipped his nuts in glitter ? pretty ballsy\n",
            "GENERATED  slutty ladies do they do when they are crazy about nuts they barely destroy an nuts\n",
            "\n",
            "KEYWORDS: reason politicians diapers common\n",
            "TRUE: politicians and diapers have one thing in common . they should both be changed regularly , and for the same reason .\n",
            "GENERATED  man which reason for the fdelors force fdelors were not in it ?\n",
            "\n",
            "KEYWORDS: married friends\n",
            "TRUE: why couldn ' t stevie wonder see his friends ? because he was married\n",
            "GENERATED  rich rich darn if an fleptures are fleas bleomary bleaks\n",
            "\n",
            "KEYWORDS: sex problem given example\n",
            "TRUE: nsfw houston , we have a problem i feel like porn has me given such unrealistic expectations about sex for example , having it with another person .\n",
            "GENERATED  guys want they are given the problem for example they are given to entering for example .\n",
            "\n",
            "KEYWORDS: required president know duck\n",
            "TRUE: did you know the secret service is no longer allowed to say get down when the president is getting attacked ? now they are required to say donald ,\n",
            "GENERATED  how can painter know if you are like licking you know if you know if you are palm .\n",
            "\n",
            "KEYWORDS: \n",
            "TRUE: whom did the boston strangler choke last ? the atlanta falcons .\n",
            "GENERATED  detective as two asianswood gets away they can t get awayfaces\n",
            "\n",
            "KEYWORDS: got friend farm cieio\n",
            "TRUE: my friend just got a new job heading up old macdonald is farm . he is the cieio\n",
            "GENERATED  wouldn tts are on a cieior on july ? because they got on a caler on that\n",
            "\n",
            "KEYWORDS: want library hang\n",
            "TRUE: what is the best part of the library to hang out if you want to get laid ? adult friction .\n",
            "GENERATED  can you want climb on suicide on mountyou are on it ? b\n",
            "\n",
            "KEYWORDS: wife pants morning happy got found\n",
            "TRUE: i got in my wife is pants this morning . she wasn ' t too happy once she found out .\n",
            "GENERATED  did you listen to girlfriends watch away as are the cycle pathdies away ? because they got a smaller state .\n",
            "\n",
            "KEYWORDS: ex eat asshole\n",
            "TRUE: if you are what you eat then that would explain why my ex is such an asshole .\n",
            "GENERATED  how do you keep to eat a dog ? they are trained until you eat a car away\n",
            "\n",
            "KEYWORDS: call\n",
            "TRUE: what do you call a testicle outside earth ? a space nut\n",
            "GENERATED  why do you storm truck spray roses on shadreeze if you are a pinole coat\n",
            "\n",
            "KEYWORDS: work used taking fired days couple\n",
            "TRUE: i used to work in a calender factory but i was fired for taking a couple of days off .\n",
            "GENERATED  how can you hear the other swedish astronaut jar jar jar jar ? they are fired\n",
            "\n",
            "KEYWORDS: plenty percs make\n",
            "TRUE: being a drug dealer is a tough job . but it has plenty of percs to make up for it .\n",
            "GENERATED  how far can t make on than his car nuts on a king as you won t make it\n",
            "\n",
            "KEYWORDS: really insomniac hear dyslexic dog agnostic\n",
            "TRUE: did you hear about the dyslexic , agnostic , insomniac ? he was up all night wondering if there really was a dog .\n",
            "GENERATED  the dog who do enkado of enhange day ? a dog is .\n",
            "\n",
            "KEYWORDS: mum found concieved\n",
            "TRUE: i found i out i was concieved at my grandmothers funeral appearently , my mum was trying comfort him . stupid mourning wood .\n",
            "GENERATED  what do you buck thenobmentary , she found it has found her in concie ?\n",
            "\n",
            "KEYWORDS: ransomware know\n",
            "TRUE: hey officer , how did the hackers escape ? i don ' t know , they just ransomware .\n",
            "GENERATED  how masolds and hypical b were ble ? we were blush .\n",
            "\n",
            "KEYWORDS: ridiculous health even bad\n",
            "TRUE: it is ridiculous that there was such a long debate whether smoking would be bad for the health . even the nazis knew it is .\n",
            "GENERATED  how do you call the jindh of roses ? are all my breath ? ?\n",
            "\n",
            "KEYWORDS: works fertilizer entremanure call\n",
            "TRUE: what do you call a self employed individual who works with fertilizer ? an entremanure .\n",
            "GENERATED  does\n",
            "\n",
            "KEYWORDS: tomorrow tell take ehh change\n",
            "TRUE: how many procrastinators does it take to change a light bulb ? ehh , i ' ll tell you tomorrow .\n",
            "GENERATED  why do seaweed roses holes on female female female female female female ? it ' ll tell your fh\n",
            "\n",
            "KEYWORDS: time\n",
            "TRUE: child psychologists hear touching stories from time to time .\n",
            "GENERATED  wanna do dad as weed pumped husbands because they are always getting high asians\n",
            "\n",
            "KEYWORDS: laptop difference consultant butt\n",
            "TRUE: what is the difference between an it consultant and a catholic priest ? the it consultant is laptop has no butt .\n",
            "GENERATED  can you have a car cycle of land mines away on a land rover ? it is land\n",
            "\n",
            "KEYWORDS: want sticking means meaning many lot figured\n",
            "TRUE: thanks everyone i want to thank everyone for sticking with me while i figured out the meaning of many . it means a lot .\n",
            "GENERATED  whose has bigfoot . because when they are pouring away because they only couldn ' t rain because it is his own .\n",
            "\n",
            "KEYWORDS: exactly\n",
            "TRUE: me hey bro someone said you sound like an owl bro who ? me exactly\n",
            "GENERATED  wanna hear banana away when you are exactly what they say ness volcano ? exactly .\n",
            "\n",
            "KEYWORDS: whey claims bodybuilder\n",
            "TRUE: does anyone believe the bodybuilder who claims he never used protein suppliments ? no whey .\n",
            "GENERATED  how does you never forget the new pair of dairy monsters before they are busy southea\n",
            "\n",
            "KEYWORDS: \n",
            "TRUE: what do you call 2000 mockingbirds ? 2kilo mocking birds .\n",
            "GENERATED  how can t windthomno identify if a blowjob isn ' t worry ? it was not my nan\n",
            "\n",
            "KEYWORDS: masturbate hard easy choose\n",
            "TRUE: we choose to masturbate , not because it is easy , but because it is hard .\n",
            "GENERATED  how are you can masturbate to masturbate they can ' t masturbate by they ? they masturbate .\n",
            "\n",
            "KEYWORDS: aula\n",
            "TRUE: knock knock who is there ? aula . aula who ? allah huakbar\n",
            "GENERATED  do you call arnold schwarzenegger if it won t land . because it won a link infection .\n",
            "\n",
            "KEYWORDS: suicide nevermind leave joke hanging ah\n",
            "TRUE: wanna hear a joke about suicide ? ah , nevermind , i ' ll leave you hanging\n",
            "GENERATED  why has 22 throw knights on r jokes before you play poker because it was the white black guys\n",
            "\n",
            "KEYWORDS: pirate charge arr\n",
            "TRUE: i ' m not often hired to be a pirate but when i am , i charge by the ' arr '\n",
            "GENERATED  can triangles are like nice wine so they are in a nice blub\n",
            "\n",
            "KEYWORDS: sleep saw money\n",
            "TRUE: was about to sleep when i saw the robber last night in my house searching for money . i immediately got up . and searched alongside with him\n",
            "GENERATED  howyou do castle brush tape castle swedish ? if they saw your air . it only took away .\n",
            "\n",
            "KEYWORDS: road\n",
            "TRUE: why did the dinosaur cross the road ? what road ?\n",
            "GENERATED  can you hear if people say pearl jam ? it was like road buh dum tis dum king cycle\n",
            "\n",
            "KEYWORDS: vegan proud meals call\n",
            "TRUE: i am proud to call myself a vegan but only in between meals .\n",
            "GENERATED  like do you do fat , white because it has been so nice because you are so proud of your meals in\n",
            "\n",
            "KEYWORDS: trying transporting tell package messed mailman joke delivery\n",
            "TRUE: a mailman was trying to tell a joke while transporting a package but he messed up the delivery\n",
            "GENERATED  ever blunder dropped their b away and trying to be\n",
            "\n",
            "KEYWORDS: paint\n",
            "TRUE: who is this rorschach guy and why does he paint so many penises ?\n",
            "GENERATED  how can you brush on paint than kurt cobain coatrace cycle coats ? it has cycle .\n",
            "\n",
            "KEYWORDS: \n",
            "TRUE: how does harry potter order tequila shots ? patron us\n",
            "GENERATED  how does we do , car nuts ? they are not sentient , and don t worry , they are fuckin tr\n",
            "\n",
            "KEYWORDS: wet soft pink hard goes dry comes\n",
            "TRUE: what is pink ? ? ? goes in hard and dry and comes out soft and wet a bubble gum\n",
            "GENERATED  offensive why does the blue moon blush for flying away class are a very angryame cadad .\n",
            "\n",
            "KEYWORDS: urination pee land country\n",
            "TRUE: what did the un say to the land of pee when it officially became a country ? urination .\n",
            "GENERATED  fireman call me the country cycle because they are very pressing\n",
            "\n",
            "KEYWORDS: understand told ex\n",
            "TRUE: i told the ambulance guys the wrong blood type for my ex now she should understand what rejection feels like .\n",
            "GENERATED  anyone know why do you understand how much had a glub at ? they are the fleas option\n",
            "\n",
            "KEYWORDS: thanks see guess booming\n",
            "TRUE: thanks to recent events i guess you could say the pressure cooker business is booming i ' ll see myself out now .\n",
            "GENERATED  me thanks how thanks without the red paint brush your boom your boom and boom your booming\n",
            "\n",
            "KEYWORDS: women way stick like hot em dick\n",
            "TRUE: i like my coffee like i like my women not too hot . that way i can stick my dick in em .\n",
            "GENERATED  how does the women freeze his dick when you stick ? stick em are it\n",
            "\n",
            "KEYWORDS: world see need guy collided anymore\n",
            "TRUE: ever since i had that car accident i see the world with different eyes shoutout to the guy i collided with who doesn ' t need them anymore\n",
            "GENERATED  people do at king arthur once they are only on they don t like his metro\n",
            "\n",
            "KEYWORDS: play get\n",
            "TRUE: what do you get when you play a country music record backwards ? you get your wife back , your dog back , your truck back\n",
            "GENERATED  why do you know if your girlfriend insists outside a country outside ? it was a blow job\n",
            "\n",
            "KEYWORDS: salad man\n",
            "TRUE: an italian man walks into a mental hospital with salad . man it is getting caprese in here\n",
            "GENERATED  why does pinocchio rush if ships on ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
            "\n",
            "KEYWORDS: night dick black ass\n",
            "TRUE: what is 8 inches long , and black as the night ? the dick up your ass\n",
            "GENERATED  why do people call a black president like the breeze away they are so micheal away in the\n",
            "\n",
            "KEYWORDS: shot bird\n",
            "TRUE: what did the awkward adolescent say when he shot a bird ? pew birdy puberty\n",
            "GENERATED  moon can trooper identify as a bird salon run away because they can ' t bird away that is a cardinal sin\n",
            "\n",
            "KEYWORDS: turned around addicted\n",
            "TRUE: i was addicted to the hokey pokey but , i turned myself around .\n",
            "GENERATED  why do you blondes walk into the bad cruise ? it turned from the bad ba dum tis\n",
            "\n",
            "KEYWORDS: hell feedback\n",
            "TRUE: what brand microphone did kurt cobain use ? remingtoni head the feedback was hell .\n",
            "GENERATED  youram rich boy boy , donut shop becomes the nobel prize because they were in smaller\n",
            "\n",
            "KEYWORDS: see\n",
            "TRUE: at your next helloween party expect to see the typical costumes . the sexy nurse , the sexy nun and the sexist judge .\n",
            "GENERATED  can you do soul of 4 mentisnohts like christmas ? because leather paint has been to see that mid thonrat\n",
            "\n",
            "KEYWORDS: allowed\n",
            "TRUE: i envy women they are allowed to have big titties and i ' m not\n",
            "GENERATED  how are you allowed to stick 65 mondays ? he isn t allowed .\n",
            "\n",
            "KEYWORDS: great alright\n",
            "TRUE: i think greta thunberg is alright but dyslexics think she is great\n",
            "GENERATED  do rich people know what swedish bleughty swedish ble b bughty\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(100):\n",
        "  input = test_seq[i]\n",
        "  kw = test_keywords[i]\n",
        "  true = detokenize(input, tokenizer)\n",
        "  kw2 = detokenize(kw, tokenizer)\n",
        "  print(\"KEYWORDS:\", ' '.join([x for x in kw2 if x != '[PAD]' and x != '[START]']))\n",
        "  print(\"TRUE:\", ' '.join([x for x in true if x != '[PAD]' and x != '[START]']))\n",
        "  joke = generate_joke(kw.reshape(1, maxlen),generator.cpu(), stepper, decoder, tokenizer, start=[2])\n",
        "  print('GENERATED',joke)\n",
        "  print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN_CHsOy1gqQ"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLajWzH5-asw"
      },
      "outputs": [],
      "source": [
        "# Load Gan\n",
        "n_layers = 5\n",
        "block_dim = 100\n",
        "\n",
        "# Create model and load weights for GAN\n",
        "generator = Generator(n_layers, block_dim)\n",
        "generator.eval()\n",
        "generator.load_state_dict(torch.load('/content/generator.th', map_location='cpu'))\n",
        "model, encoder, stepper, decoder = r_seq2seq(weights='/content/reconstruction_weights.h5')\n",
        "\n",
        "# Load VAE\n",
        "vae_enc, vae_dec = vae(weights_e='/content/vae_enc_weights.h5', \n",
        "                weights_d='/content/vae_dec_weights.h5')\n",
        "\n",
        "# Load Seq2Seq\n",
        "s2s_enc, s2s_dec = seq2seq(weights='/content/seq2seq_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YOPpwp2jJbc",
        "outputId": "2fb0048b-d0d0-41aa-a1d5-8d26d46bbb82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KEYWORDS: switch light arguing\n",
            "TRUE: how do you end two deaf persons ' arguing ? switch off the light .\n",
            "GAN:  the ambulance has onefullyy so you can switche by one direction this one fleb\n",
            "VAE:  if arguing with a switch , 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 000\n",
            "S2S:  two people are arguing with a light bulb . just won ' t switch off the switch .\n",
            "\n",
            "KEYWORDS: suckin lot lose hurricane house first common blowin blonde\n",
            "TRUE: what does a blonde have in common with a hurricane ? first there is a lot of suckin and blowin , then you lose your house .\n",
            "GAN:  howyou can sidesin when the 2016 presidential election has been the first state cin brin b .\n",
            "VAE:  what does a hurricane and a hurricane have in common ? they both suck at first , they both suck .\n",
            "S2S:  what do a blonde and a lot have in common ? they both both moan at the house .\n",
            "\n",
            "KEYWORDS: went floats day circles\n",
            "TRUE: i went to a white pride parade the other day . the floats just kept going around in circles about 200 miles per hour .\n",
            "GAN:  has you wanna hear 11 drivers ? it went the day blub it by it floatsl\n",
            "VAE:  i went to the other day and a day keeps going around in circles .\n",
            "S2S:  i went to the round of the other day i went round i went round in circles .\n",
            "\n",
            "KEYWORDS: would neighbor joke home close\n",
            "TRUE: i would make a joke about my neighbor . but it would be too close to home\n",
            "GAN:  blondes are confusing till what they are expensive till they are the best edest ride they are close at home\n",
            "VAE:  why is the best part about being a joke ? because if it would be home , i can close it home .\n",
            "S2S:  i would tell a joke about my neighbor is door . i would be a close to the home .\n",
            "\n",
            "KEYWORDS: god everything difference\n",
            "TRUE: what is the difference between god and you ex wife ? god only wants 10 things . your ex wife wants half of everything .\n",
            "GAN:  why did kenk shout in chukh bukh buk\n",
            "VAE:  what is the difference between god and god ? god is a god .\n",
            "S2S:  what is the difference between god and god ? god doesn ' t make everything .\n",
            "\n",
            "KEYWORDS: swear castrate\n",
            "TRUE: i swear , i will castrate you do it , you won t . no balls bro .\n",
            "GAN:  has you can t cast rich content with tristary ? they are a castrate to cast\n",
            "VAE:  what is the easiest way to castrate a boat ? swear .\n",
            "S2S:  i swear my actors i have a castrate bridge . i ' m a castrate .\n",
            "\n",
            "KEYWORDS: woman way tits looking eyes checks\n",
            "TRUE: the first thing a man notices about a woman is her eyes and when he made sure it is not looking his way , he checks out her\n",
            "GAN:  did you want through the eyes ? because it was the only way on a way on the it because it checks air\n",
            "VAE:  i ' m looking for a woman with no eyes i ' m looking for her eyes . i ' ll never forget it checks out .\n",
            "S2S:  i ' m looking for a woman with her tits . she gets mad when she gets it when she gets it on her eyes .\n",
            "\n",
            "KEYWORDS: get dead\n",
            "TRUE: what is your favourite insult joke ? i will get it started 2090 called , you are dead and nobody misses you\n",
            "GAN:  can t eat it for eyes but it is the dead taste . it is dead\n",
            "VAE:  why do you get a pterodactyl laugh ? because they are dead\n",
            "S2S:  what do you get when you cross a dead dead musician ? dead .\n",
            "\n",
            "KEYWORDS: way thought mall harsh\n",
            "TRUE: trump hows that mexican mall going ? mall ? we thought you said wall trump no way that is harsh , also hows that muslim band looking\n",
            "GAN:  wanna hear michael jordan strip compliments so many are it . because it is like , it is probably a bigger .\n",
            "VAE:  why did the blonde fail algebra ? because she thought he was too harsh .\n",
            "S2S:  i thought that was the same way to be a mall but i thought it was a pretty reich .\n",
            "\n",
            "KEYWORDS: anyone\n",
            "TRUE: keanu reeves donates so much blood that anyone who has ever received donor blood is at least 6 keanu reeves .\n",
            "GAN:  you can land with jeff 198 , man ? jeffher darth vader , i get angry with anyone\n",
            "VAE:  anyone who is the best part about anyone ? anyone who is a good idea .\n",
            "S2S:  anyone who is a lot like a new year old ? anyone who can ' t have a good partner .\n",
            "\n",
            "KEYWORDS: sneezes\n",
            "TRUE: what does a nut say when he sneezes ? ca shew\n",
            "GAN:  wanna do rich man vote on his breeze seaweed ? it doesn t like 911 cycle on your b on it cycle on\n",
            "VAE:  what does a nosey pepper sneezes ? a little whine\n",
            "S2S:  what does a fly fly when a fly sneezes ? a dead centipede .\n",
            "\n",
            "KEYWORDS: nose man ejaculating arrested\n",
            "TRUE: a man was arrested for ejaculating out his nose but he did nutting wrong\n",
            "GAN:  who couldn t you know why forgot the best way to have been arrested\n",
            "VAE:  a man was arrested for a man . he was arrested for a man .\n",
            "S2S:  a man was arrested over his nose he was arrested over .\n",
            "\n",
            "KEYWORDS: write called\n",
            "TRUE: my girlfriend asked me to write an inspirational poem about our love life . i called it , the load less swallowed\n",
            "GAN:  chuck norris gays rover do condoms on female ? they called a female ride they called all they all do\n",
            "VAE:  what is it called when you write a new car ? a little bit\n",
            "S2S:  what is it called when you write a bladder infection ? a ginger belt\n",
            "\n",
            "KEYWORDS: understand talk heroin\n",
            "TRUE: my local police chief does a talk on heroin so you can ' t understand any of it .\n",
            "GAN:  how do you understand emweom , are you not ? because it has double nuts\n",
            "VAE:  i don ' t understand why people talk to the shower . but i don ' t understand why they are shower .\n",
            "S2S:  i don ' t understand my doctor is heroin addict , i ' m a lot like me .\n",
            "\n",
            "KEYWORDS: used thought think telling look brain\n",
            "TRUE: i used to think the brain was the most important organ . then i thought , look what is telling me that .\n",
            "GAN:  printer obama has been jerking off the clorist because it is been stuck on his blorist blorist\n",
            "VAE:  i think i was telling my brain to look for telling my brain . i can ' t look at the right answer .\n",
            "S2S:  i used to look at my brain but i think i would look at the right ahead of my brain . i think i ' m telling me that\n",
            "\n",
            "KEYWORDS: tumblr trending saw dashboard\n",
            "TRUE: so i saw that princess diana is trending on tumblr . she is all over the dashboard\n",
            "GAN:  moon must use if they expired on the election they just saw the only nut on the nut .\n",
            "VAE:  what did the slotan say when he saw the on his life ? a trans transpting .\n",
            "S2S:  i saw on tumblr on tumblr but i saw her with flint .\n",
            "\n",
            "KEYWORDS: unless speed multiply light energy\n",
            "TRUE: unless you multiply yourself by the speed of light then you energy .\n",
            "GAN:  why do blondes go to my light on it ? because it doesn ' t take . .\n",
            "VAE:  you shouldn ' t multiply your light up and then multiply up .\n",
            "S2S:  life is like speed , then multiply yourself unless you multiply yourself . unless you multiply yourself .\n",
            "\n",
            "KEYWORDS: hollow hillary head\n",
            "TRUE: what is more hollow than donald trump is head ? hillary is diazepam pen .\n",
            "GAN:  chuck norrischesches when you are rain circumchesamel ? you are .\n",
            "VAE:  how do monica lewinsky make hillary clinton ? phish and a head .\n",
            "S2S:  why does hillary clinton have longer than a bad joke ? she is a longer bottle .\n",
            "\n",
            "KEYWORDS: dog boat\n",
            "TRUE: why does a dog on a you boat have a deep bark ? because he is a sub woofer .\n",
            "GAN:  wanna hear what the average female brist is boat ? it is a bit of the bitch\n",
            "VAE:  what is a dog is favorite kind of boat ? a dog .\n",
            "S2S:  why did the dog get into the boat ? because he fell forward to the boat .\n",
            "\n",
            "KEYWORDS: reaction\n",
            "TRUE: why don ' t people tell chemistry jokes ? because they never get a reaction .\n",
            "GAN:  how can youadad on ukraine on ukraine ? because they haven ' t finished on breath\n",
            "VAE:  chemistry jokes are reaction .\n",
            "S2S:  chemistry joke is such a lot like food ? no reaction .\n",
            "\n",
            "KEYWORDS: yet woman w q infront cow back\n",
            "TRUE: q what is infront of the woman , yet , at the back of the cow ? a w\n",
            "GAN:  people who do on the blub on a blub ? they are on , and not on it\n",
            "VAE:  a man that is a lot of wuck a woman is a lot of a woman is back .\n",
            "S2S:  q what did the cow say when she was in a cow ? q what did the cow say when she is in a cow ? a cow is\n",
            "\n",
            "KEYWORDS: nazi followers coming\n",
            "TRUE: when hitler killed himself his followers did nazi that coming\n",
            "GAN:  how do you carnoines as a facebook tree on twitter it doesn ' t you throw on a wall that you are coming .\n",
            "VAE:  what does a nazi say to the other nazi ? a nazi .\n",
            "S2S:  why did hitler not not a lot of traditional colors ? he kept coming out of his browser .\n",
            "\n",
            "KEYWORDS: \n",
            "TRUE: \n",
            "GAN:  how do you announce his dog ambulance homeschin ? he won t worry he won t smell it\n",
            "VAE:  what is the best part about a gay man ? a little whine\n",
            "S2S:  what did the pirate say to the other ? aye matey\n",
            "\n",
            "KEYWORDS: sperm directions ask\n",
            "TRUE: why does it take millions of sperm to fertilize one egg ? because they won ' t ask for directions\n",
            "GAN:  nsfw some people think of one side of a sperm banks it is a one liner than the other .\n",
            "VAE:  sperm are directions . they ask me for directions .\n",
            "S2S:  sperm banks are like a sperm bank , i have to ask them for directions .\n",
            "\n",
            "KEYWORDS: experience belittling attacked\n",
            "TRUE: i was attacked by tiny bees . the experience was belittling .\n",
            "GAN:  do rich men focus on pachin rides are you on your breath ? smell arthritis\n",
            "VAE:  my experience is attacked by a belbs . be a touchy subject .\n",
            "S2S:  i was attacked by a non man , but i was attacked by a few years ago . be attacked .\n",
            "\n",
            "KEYWORDS: spent proud pays lot life brothels bills\n",
            "TRUE: i have spent a lot of my life in brothels . i am not proud of it , but it pays the bills .\n",
            "GAN:  offensive guys ground mocking camping before you are the wall zone zone . they have spent his life in that it\n",
            "VAE:  i ' m proud of a brothel who has been kidnapped by the iphones . but i have been the best place to be the first time .\n",
            "S2S:  i spent a brothel that is proud of the brothels . i have spent a lot of money .\n",
            "\n",
            "KEYWORDS: went tiers even cake\n",
            "TRUE: i went to a really depressing wedding recently . even the cake was in tiers .\n",
            "GAN:  wanna hear they were on one direction swedish boy we only one day your other day\n",
            "VAE:  i went to a wedding today . even the cake was in tiers .\n",
            "S2S:  i went to the cake was the cake was the cake was the cake was the cake was the cake was the cake .\n",
            "\n",
            "KEYWORDS: song catchy\n",
            "TRUE: a stormtrooper walks into a cantina stormtrooper damn this song is catchy\n",
            "GAN:  why does you know bmw ambulance ambulance ambulance ed ? because it doesn ' t catch him because you are on juan . happy birthday .\n",
            "VAE:  what song does a french man get to catch a song ? a little hoarse\n",
            "S2S:  what song did the song say to catch a song ? catchy\n",
            "\n",
            "KEYWORDS: whens door ajar\n",
            "TRUE: whens a door not a door ? when its ajar .\n",
            "GAN:  how do repnolds smell like your door ? it is heading inside your door .\n",
            "VAE:  when is a door not a door ? it is ajar .\n",
            "S2S:  when is a door is favorite kind of door ? when it is ajar .\n",
            "\n",
            "KEYWORDS: little difference\n",
            "TRUE: what is the difference between ancient religious texts and fake news ? a little over 2000 years\n",
            "GAN:  can you blondes say when it has been in disneyland don ' t like it .\n",
            "VAE:  what is the difference between a little wine and a little chinese ? a little little little pricks are both little .\n",
            "S2S:  what is the difference between a little newton and a little more than a little more than a little more than a little more than a little little\n",
            "\n",
            "KEYWORDS: call\n",
            "TRUE: what do you call a graduated spider ? a web designer\n",
            "GAN:  you call ground the cycleary cycle for vertary cycle if you call it a cycle path cycle path cycle path cycle path .\n",
            "VAE:  what do you call a gay man ? a receding hare line\n",
            "S2S:  what do you call a gay midget ? a boo bees\n",
            "\n",
            "KEYWORDS: see mother father beauty\n",
            "TRUE: a son asks his father . a son asks his father dad , what is beauty ? do you see your mother ? yes well that is not it\n",
            "GAN:  gypsy can see why they are on men let me see men let you see men in the mother\n",
            "VAE:  my father is father is father is father is best .\n",
            "S2S:  if your mother is a lot of children is mother , i see her father .\n",
            "\n",
            "KEYWORDS: rapist predator call\n",
            "TRUE: what do you call an immigrant fighting a rapist ? alien vs . predator\n",
            "GAN:  why do you really hate ? because he has a perfanoxious as the magical machine . predator coat\n",
            "VAE:  what do you call a rapist that gets into a rapist ? alien vs predator\n",
            "S2S:  what do you call a rapist with a rapist ? alien vs predator\n",
            "\n",
            "KEYWORDS: groups even\n",
            "TRUE: why do white girls always walk in groups with odd numbers ? they can ' t even\n",
            "GAN:  you call ukraine of king arthur has reported his badgeral ackbar\n",
            "VAE:  why teenagers travel in groups of shortens ? because they can ' t even not even .\n",
            "S2S:  why cant groups of numbers travel ? because they can ' t even .\n",
            "\n",
            "KEYWORDS: rest made funeral awkward\n",
            "TRUE: got caught sniffing my sisters panties yesterday it made the rest of her funeral very awkward .\n",
            "GAN:  how does you moon ambulance ambulance ambulance ambulance ambulance ambulance ambulance , they are like you because they made away the rest away\n",
            "VAE:  i made a funeral for a funeral . the rest of the rest of the rest of the rest of the rest of the rest .\n",
            "S2S:  i made a funeral tomorrow i made the rest of the funeral .\n",
            "\n",
            "KEYWORDS: want making joke hear\n",
            "TRUE: you want to hear a joke ? me making it on the front page .\n",
            "GAN:  why do pets like when you want ? because they can get away on the cycle path cycle path cycle .\n",
            "VAE:  want to hear a joke about making a joke ? it is a joke about it .\n",
            "S2S:  did you hear about the joke about making a joke ? it is making a joke .\n",
            "\n",
            "KEYWORDS: week set 100\n",
            "TRUE: set your wifi password to 100 so when someone ask tell them it is how many times a week this gets reposted .\n",
            "GAN:  how does glens , play on his b ? they set a b on the week\n",
            "VAE:  i set a week in a week but i ' m a week .\n",
            "S2S:  how did the schizophrenic executive go to the trash ? because he is a 100 , but 100 , but 100 , but 100 100 100 100 100 100\n",
            "\n",
            "KEYWORDS: fascist faggot call axe\n",
            "TRUE: what do you call a faggot with an axe ? a fascist\n",
            "GAN:  can you call an f , franbide cycley a fascist are on a fascist ? faggot\n",
            "VAE:  what do you call a fascist in a fascist ? a fascist\n",
            "S2S:  what do you call a fascist tree who is an axe ? axe mate .\n",
            "\n",
            "KEYWORDS: vegetables thumbs people know fingers\n",
            "TRUE: you know how all thumbs are fingers , but not all fingers are thumbs ? some people can be vegetables , but vegetables can ' t be people .\n",
            "GAN:  why does people do more than your hole when they only have good strawberry nice ?\n",
            "VAE:  people who can ' t tell the people who can fruits vegetables .\n",
            "S2S:  i don ' t know why the jokes about their vegetables so i can ' t stopplays .\n",
            "\n",
            "KEYWORDS: marc homosexual group friends\n",
            "TRUE: they say one in ten men are homosexual in my group of friends i ' m pretty sure it is marc . he is really cute\n",
            "GAN:  how many potatoes celebrate when you are getting ready ? the fastest source in his marcr\n",
            "VAE:  what is the best thing about a group of friends ? marcrcrcrcrcrcrcrcr\n",
            "S2S:  what group of friends do you call a group of friends ? marcrculosis\n",
            "\n",
            "KEYWORDS: engineers\n",
            "TRUE: a good joke for the engineers out there free time\n",
            "GAN:  mapical cycle , thomas because it has been leaked air conditioning don ' t worry .\n",
            "VAE:  why do engineers like engineers ? they have engineers\n",
            "S2S:  what is the most common language ? they are both engineers .\n",
            "\n",
            "KEYWORDS: writing song getting end\n",
            "TRUE: i ' m writing a song about getting my front door lock replaced . there is a lovely key change at the end .\n",
            "GAN:  how slutty do you like getting laid on ? getting laid\n",
            "VAE:  what song did the drummer say to the writing ? getting a song .\n",
            "S2S:  what song is the most popular part about the song about the end of the end of the song ? the end of the decade\n",
            "\n",
            "KEYWORDS: charge\n",
            "TRUE: i gave away all of my dead batteries free of charge .\n",
            "GAN:  how do you throw 1000 as a careries on particular car ? juan on charge\n",
            "VAE:  why did the electrons go to charge ? because electrons was resisting a charge\n",
            "S2S:  why did the neutron receive a nipple pierced ? because of charge .\n",
            "\n",
            "KEYWORDS: point life diarrhea 80\n",
            "TRUE: studies show that 80 of redditors suffer from diarrhea at some point in life then why are the rest enjoying it ?\n",
            "GAN:  how can you switch on the beach when it was a cycle path cycle on a point ?\n",
            "VAE:  my life is a point of diarrhea . but i have a point .\n",
            "S2S:  the only one benefit of the vinyl solution in the vinyl solution , the other is the point of the people .\n",
            "\n",
            "KEYWORDS: someone makes cents call\n",
            "TRUE: what do you call a bad european banker that talks gibberish ? someone that makes no cents .\n",
            "GAN:  how can you call actors ba dumds holes on air conditioning has to call it\n",
            "VAE:  what do you call a pound that makes cents ? someone earned .\n",
            "S2S:  what do you call a british british pound ? someone who makes cents .\n",
            "\n",
            "KEYWORDS: win olympics logic chance\n",
            "TRUE: to win the olympics , you must go big or go home . by that logic , the refugee team never had a chance .\n",
            "GAN:  how do you win force your own cream ? the cycle air force\n",
            "VAE:  which logic did the socialist say to win the olympics ? they are a chance to win .\n",
            "S2S:  the man asked me what a chance of the father is logic fetish . enemy .\n",
            "\n",
            "KEYWORDS: frank burn\n",
            "TRUE: why won ' t people let hitler go to the bar bq ? he ' ll just burn the frank ' s\n",
            "GAN:  how should you get sent because he doesn t be frank because of his pride ? not frank\n",
            "VAE:  frank is not frank .\n",
            "S2S:  you know what you are frank ? you burn\n",
            "\n",
            "KEYWORDS: porn disabled\n",
            "TRUE: is all your porn here disabled ? no it is regular porn you sick fuck .\n",
            "GAN:  how has ronald fans bitter weatherfare for the solar eclipse dealership ? because they don t revolve around it\n",
            "VAE:  what is the best part about porn ? porn .\n",
            "S2S:  what porn does porn is disabled people with porn ? the porn trend .\n",
            "\n",
            "KEYWORDS: lazy descirbe\n",
            "TRUE: i can descirbe myself in just two words . lazy .\n",
            "GAN:  notice how a king rides were stealing all his des so lazy , it is too lazy .\n",
            "VAE:  why are lazy metal so lazy ? they are debercis .\n",
            "S2S:  i ' m starting a debecruger . i ' m not lazy .\n",
            "\n",
            "KEYWORDS: wife tequila cliff\n",
            "TRUE: why did the mexican man throw his wife off of a cliff ? tequila\n",
            "GAN:  how do you know who has badies y yts yts ? salt yts\n",
            "VAE:  why did the tequila tequilahhh tequila ? tequila mockingbird\n",
            "S2S:  why did the mexican push his wife off a cliff ? tequila\n",
            "\n",
            "KEYWORDS: nuts heard guy glitter dipped\n",
            "TRUE: have you heard about the guy who dipped his nuts in glitter ? pretty ballsy\n",
            "GAN:  did squirrels do the nuts as far away on duntho tape ? because they have fans air force it only nuts\n",
            "VAE:  have you heard about the guy that is a pretty trend ? pretty nuts are pretty pretty nuts .\n",
            "S2S:  have you heard about the guy going to see a black hat ? he is going around going to see his nuts .\n",
            "\n",
            "KEYWORDS: reason politicians diapers common\n",
            "TRUE: politicians and diapers have one thing in common . they should both be changed regularly , and for the same reason .\n",
            "GAN:  the 10th cycle can and changed the same reason if you are in the playstation otherwise they won\n",
            "VAE:  what does a reason and the same reason what does the same reason in common ? they are both reason .\n",
            "S2S:  what do hotdogs and diapers have in common ? both should be changed regularly .\n",
            "\n",
            "KEYWORDS: married friends\n",
            "TRUE: why couldn ' t stevie wonder see his friends ? because he was married\n",
            "GAN:  democrat richio owned pearl necklace confirm why are it annoying because it was like dressing away on his car dealership\n",
            "VAE:  why are friends so many friends ? because they are married .\n",
            "S2S:  i have been married and i have a few years resolution . i ' m married .\n",
            "\n",
            "KEYWORDS: sex problem given example\n",
            "TRUE: nsfw houston , we have a problem i feel like porn has me given such unrealistic expectations about sex for example , having it with another person .\n",
            "GAN:  ladies rich blub blub isn ' t brush blub blub\n",
            "VAE:  sex is a problem for example . for example , i haven ' t given up having sex .\n",
            "S2S:  having sex is a problem with a problem with a good example for example for example airport security is the problem with a good partner .\n",
            "\n",
            "KEYWORDS: required president know duck\n",
            "TRUE: did you know the secret service is no longer allowed to say get down when the president is getting attacked ? now they are required to say donald ,\n",
            "GAN:  geologist can we know how do you know isn ' t a persian ? are getting extinct . i know why\n",
            "VAE:  you know what is donald trump is favorite kind of duck ? a duck .\n",
            "S2S:  you know why the required is a duck ? because it required the required to the required .\n",
            "\n",
            "KEYWORDS: \n",
            "TRUE: whom did the boston strangler choke last ? the atlanta falcons .\n",
            "GAN:  rich actors when you don ' t finish till they are leaked on\n",
            "VAE:  what is the best part about a gay man ? a little whine\n",
            "S2S:  what did the pirate say to the other ? aye matey\n",
            "\n",
            "KEYWORDS: got friend farm cieio\n",
            "TRUE: my friend just got a new job heading up old macdonald is farm . he is the cieio\n",
            "GAN:  farm if crist , cirie blub blubyou fieio\n",
            "VAE:  i got a friend with a friend of a farm . but i got a cieio .\n",
            "S2S:  friend i got a friend of a farmie . i got a cieioie .\n",
            "\n",
            "KEYWORDS: want library hang\n",
            "TRUE: what is the best part of the library to hang out if you want to get laid ? adult friction .\n",
            "GAN:  how does gaurines blush with the toilet seat ? it is .\n",
            "VAE:  what is the tallest building ? a woman .\n",
            "S2S:  i ' m a library , i ' m a library , i ' m a librarian . i ' m a librarian .\n",
            "\n",
            "KEYWORDS: wife pants morning happy got found\n",
            "TRUE: i got in my wife is pants this morning . she wasn ' t too happy once she found out .\n",
            "GAN:  how do we are happy as happy ? custaches found your wife in the morning .\n",
            "VAE:  i got a wife in my wife . i got a wife in her pants .\n",
            "S2S:  i found out of my wife this morning i got her pants up this morning . i have got a happy meal .\n",
            "\n",
            "KEYWORDS: ex eat asshole\n",
            "TRUE: if you are what you eat then that would explain why my ex is such an asshole .\n",
            "GAN:  moon can t do if they eat on a lower themed than they get juan on\n",
            "VAE:  what do you eat when you eat a black person ? exploits\n",
            "S2S:  what do you eat an asshole ? an asshole .\n",
            "\n",
            "KEYWORDS: call\n",
            "TRUE: what do you call a testicle outside earth ? a space nut\n",
            "GAN:  can you call if baence baff on ba dum tishh has a cycle path\n",
            "VAE:  what do you call a gay man ? a receding hare line\n",
            "S2S:  what do you call a gay midget ? a boo bees\n",
            "\n",
            "KEYWORDS: work used taking fired days couple\n",
            "TRUE: i used to work in a calender factory but i was fired for taking a couple of days off .\n",
            "GAN:  how dairywood has stronger streets isn ' t anymore ? you are fired anymore because you are strawberry blue jam in days\n",
            "VAE:  i was taking a couple of people . i can ' t work .\n",
            "S2S:  taking a couple of these days but i used to work for days . but i ' m not fired .\n",
            "\n",
            "KEYWORDS: plenty percs make\n",
            "TRUE: being a drug dealer is a tough job . but it has plenty of percs to make up for it .\n",
            "GAN:  what when did you call obama , and the t has plenty it . ? very percs\n",
            "VAE:  what is the best part about being percs ? you are percs .\n",
            "S2S:  percsccsulacs are in the streets of ancient insects there are plenty of percs .\n",
            "\n",
            "KEYWORDS: really insomniac hear dyslexic dog agnostic\n",
            "TRUE: did you hear about the dyslexic , agnostic , insomniac ? he was up all night wondering if there really was a dog .\n",
            "GAN:  gypsy honestly peanuts can you hear of his boots that are only because he ' ll\n",
            "VAE:  did you hear about the dyslexic insomniac dyslexic ? he really don ' t hear , there is a dog .\n",
            "S2S:  did you hear about the agnostic insomniac who really likes to get up an agnostic ? he really likes to get up late .\n",
            "\n",
            "KEYWORDS: mum found concieved\n",
            "TRUE: i found i out i was concieved at my grandmothers funeral appearently , my mum was trying comfort him . stupid mourning wood .\n",
            "GAN:  wanna know it when you found it underwater it was a concie ever ? they are in it .\n",
            "VAE:  i found out my mumcieved . i ' m not concieved .\n",
            "S2S:  i found out of my mumced me in a orphanage prescription she was conved .\n",
            "\n",
            "KEYWORDS: ransomware know\n",
            "TRUE: hey officer , how did the hackers escape ? i don ' t know , they just ransomware .\n",
            "GAN:  how does female content isn ' t it ransomware\n",
            "VAE:  how did the mexican chef respond to the other ? ransomware .\n",
            "S2S:  did you know that hitler was ransomware ? he ransomware .\n",
            "\n",
            "KEYWORDS: ridiculous health even bad\n",
            "TRUE: it is ridiculous that there was such a long debate whether smoking would be bad for the health . even the nazis knew it is .\n",
            "GAN:  people know what on the enterprise ? they are on micheal jordan and they can t even finish on\n",
            "VAE:  my doctor told me that is banning people . even i ' m so bad . even that is hers .\n",
            "S2S:  my health is bad forensive to be doing health . even that is bad for health .\n",
            "\n",
            "KEYWORDS: works fertilizer entremanure call\n",
            "TRUE: what do you call a self employed individual who works with fertilizer ? an entremanure .\n",
            "GAN:  why can only t when people don ' t freind ? it is not to\n",
            "VAE:  what do you call a slutty person who works at fertilizer ? engffffffffffff\n",
            "S2S:  what do you call a new fertilizer who works for a fertilizer ? a fertilizer .\n",
            "\n",
            "KEYWORDS: tomorrow tell take ehh change\n",
            "TRUE: how many procrastinators does it take to change a light bulb ? ehh , i ' ll tell you tomorrow .\n",
            "GAN:  how when you chase blondes ? by a dish assistant ? his credit cycleal cycles his wife\n",
            "VAE:  how many freudian do you take to change a light bulb ? ehh , ehh , ehh .\n",
            "S2S:  how many brexiteers does it take to change a light bulb ? i ' ll tell you tomorrow .\n",
            "\n",
            "KEYWORDS: time\n",
            "TRUE: child psychologists hear touching stories from time to time .\n",
            "GAN:  zones has been destroyed the same time in his time he gets stabbed his time\n",
            "VAE:  what time is the time of time ? a little whine\n",
            "S2S:  what time does a mexican is time ? a time\n",
            "\n",
            "KEYWORDS: laptop difference consultant butt\n",
            "TRUE: what is the difference between an it consultant and a catholic priest ? the it consultant is laptop has no butt .\n",
            "GAN:  how many blondes are truly in the pc central 4th of his pc they are in davsas\n",
            "VAE:  what is the difference between a laptop and a laptop ? consantultant when your laptop is butt .\n",
            "S2S:  what is the difference between a laptop and a laptop ? a slight of his butt .\n",
            "\n",
            "KEYWORDS: want sticking means meaning many lot figured\n",
            "TRUE: thanks everyone i want to thank everyone for sticking with me while i figured out the meaning of many . it means a lot .\n",
            "GAN:  wanna hear fad when the election is election ? it is the worst operating system\n",
            "VAE:  i figured out how many people are sticking to the same one of them . it means a lot of many of it .\n",
            "S2S:  i figured out how many people are sticking to dente . it is a lot of many people . that means a lot of many people .\n",
            "\n",
            "KEYWORDS: exactly\n",
            "TRUE: me hey bro someone said you sound like an owl bro who ? me exactly\n",
            "GAN:  why pelvin pele with umbrella comes from . it is exactly .\n",
            "VAE:  what is a good thing about a good joke ? you are a good joke .\n",
            "S2S:  what is the best thing you are exactly like ? exactly . exactly like me skeletons .\n",
            "\n",
            "KEYWORDS: whey claims bodybuilder\n",
            "TRUE: does anyone believe the bodybuilder who claims he never used protein suppliments ? no whey .\n",
            "GAN:  how can you throw goals and if he claims he won ' t worry if he has been to only strawberry\n",
            "VAE:  what does the kurds say to the dairy cheese ? no whey\n",
            "S2S:  what does a bodybuilder say as a bodybuilder ? he is a protein ono .\n",
            "\n",
            "KEYWORDS: \n",
            "TRUE: what do you call 2000 mockingbirds ? 2kilo mocking birds .\n",
            "GAN:  benadad when buh buh b are cycle ? b buh cycle\n",
            "VAE:  what is the best part about a gay man ? a little whine\n",
            "S2S:  what did the pirate say to the other ? aye matey\n",
            "\n",
            "KEYWORDS: masturbate hard easy choose\n",
            "TRUE: we choose to masturbate , not because it is easy , but because it is hard .\n",
            "GAN:  wanna choose choose your condomb which choose the white house ? she has one strawberry fle\n",
            "VAE:  how do you masturbate with a hard time ? easy to masturbate .\n",
            "S2S:  i ' m easy to decide if you are not easy to myself .\n",
            "\n",
            "KEYWORDS: aula\n",
            "TRUE: knock knock who is there ? aula . aula who ? allah huakbar\n",
            "GAN:  why do you celebrate men shells are the best barista ? because they are only halfway\n",
            "VAE:  why did the aulamation go to aulacent exposure ? they are always stalin .\n",
            "S2S:  what did austria say when they are a big fan ? aula vader\n",
            "\n",
            "KEYWORDS: suicide nevermind leave joke hanging ah\n",
            "TRUE: wanna hear a joke about suicide ? ah , nevermind , i ' ll leave you hanging\n",
            "GAN:  physics offensive how do you blame for edts once you are closing away once ed ed ed ed ed ed ed ed rover away ? the opportunity\n",
            "VAE:  how do you leave a joke ? nevermind , they are hanging out .\n",
            "S2S:  have you ever heard about the joke about jeffrey epstein is worst nightmare ? nevermind , it was a lot of the time .\n",
            "\n",
            "KEYWORDS: pirate charge arr\n",
            "TRUE: i ' m not often hired to be a pirate but when i am , i charge by the ' arr '\n",
            "GAN:  did the geologist want on the ninknolds they are not sikh\n",
            "VAE:  why is a pirate is a pirate ? because they were both in charge .\n",
            "S2S:  what is a pirate is favorite letter ? arr dead .\n",
            "\n",
            "KEYWORDS: sleep saw money\n",
            "TRUE: was about to sleep when i saw the robber last night in my house searching for money . i immediately got up . and searched alongside with him\n",
            "GAN:  gotta do crist as it because his own his own tri dad because his own cream day\n",
            "VAE:  i saw a new year old daughter in the sleep . i can sleep with her money .\n",
            "S2S:  i saw a new car that i saw a new iphone x men . i just saw a few days .\n",
            "\n",
            "KEYWORDS: road\n",
            "TRUE: why did the dinosaur cross the road ? what road ?\n",
            "GAN:  why do you call the election b ? because we are so much outside . we don t do it on the weather outside ?\n",
            "VAE:  why did the chicken cross the road ? because he was a little meteor .\n",
            "S2S:  why did the chicken cross the road ? because he was a little meteor .\n",
            "\n",
            "KEYWORDS: vegan proud meals call\n",
            "TRUE: i am proud to call myself a vegan but only in between meals .\n",
            "GAN:  joke dad has been the windmobile repleepe on repleepe\n",
            "VAE:  what do you call a vegan ? a vegan .\n",
            "S2S:  what do you call a proud of meals ? a vegan .\n",
            "\n",
            "KEYWORDS: trying transporting tell package messed mailman joke delivery\n",
            "TRUE: a mailman was trying to tell a joke while transporting a package but he messed up the delivery\n",
            "GAN:  how the you are guys turned on the right leg ? they are trying to screw .\n",
            "VAE:  i ' m trying to tell my delivery but i ' m not sure how i tell delivery , i ' m not a mailman .\n",
            "S2S:  i messed up competitive to the mailman is like the mailman , i messed up when i messed up competitive . but when i messed up with no wonder\n",
            "\n",
            "KEYWORDS: paint\n",
            "TRUE: who is this rorschach guy and why does he paint so many penises ?\n",
            "GAN:  how does the cyclebie do when he paint ed ? they paint the cycleest cycle jar\n",
            "VAE:  how do you paint a french paint ? boo bees .\n",
            "S2S:  why did the paint driver get kicked out of paint ? because he was a little meteor .\n",
            "\n",
            "KEYWORDS: \n",
            "TRUE: how does harry potter order tequila shots ? patron us\n",
            "GAN:  trash do rich people worry if you are on north korea don ' t worry it doesn t be anymore\n",
            "VAE:  what is the best part about a gay man ? a little whine\n",
            "S2S:  what did the pirate say to the other ? aye matey\n",
            "\n",
            "KEYWORDS: wet soft pink hard goes dry comes\n",
            "TRUE: what is pink ? ? ? goes in hard and dry and comes out soft and wet a bubble gum\n",
            "GAN:  how do you call if republicans are angry on the roller it goes away on the strawberry\n",
            "VAE:  what is pink and hard to dry ? soft .\n",
            "S2S:  what is pink and hard and comes out and wet and wet bubble gum out ?\n",
            "\n",
            "KEYWORDS: urination pee land country\n",
            "TRUE: what did the un say to the land of pee when it officially became a country ? urination .\n",
            "GAN:  why are they such studying a school themed crist . it only tells his land .\n",
            "VAE:  what country has the country ? pee .\n",
            "S2S:  if you are fully acting like a lot of peeinations . you are always urination .\n",
            "\n",
            "KEYWORDS: understand told ex\n",
            "TRUE: i told the ambulance guys the wrong blood type for my ex now she should understand what rejection feels like .\n",
            "GAN:  you understand why did there are expnounited in the bible ? he told me\n",
            "VAE:  i told my ex wife she told me she is a good time .\n",
            "S2S:  i told my ex girlfriend for a few weeks ago i told her she was exc .\n",
            "\n",
            "KEYWORDS: thanks see guess booming\n",
            "TRUE: thanks to recent events i guess you could say the pressure cooker business is booming i ' ll see myself out now .\n",
            "GAN:  you drowned often if you see on march on march on march on a boom and boom on the boom you are boom\n",
            "VAE:  i guess you can see a boom bee . i guess you could say i ' ll see myself out .\n",
            "S2S:  i guess that is a booming job . thanks , i guess it is booming\n",
            "\n",
            "KEYWORDS: women way stick like hot em dick\n",
            "TRUE: i like my coffee like i like my women not too hot . that way i can stick my dick in em .\n",
            "GAN:  can you switch the cycle for cycle jacket ? because he is a stick on the way it cycle\n",
            "VAE:  i like my dick in the way to stick my dick up and a stick . it is a stick .\n",
            "S2S:  women are like a dick , but i don ' t like my dick . i just stick it .\n",
            "\n",
            "KEYWORDS: world see need guy collided anymore\n",
            "TRUE: ever since i had that car accident i see the world with different eyes shoutout to the guy i collided with who doesn ' t need them anymore\n",
            "GAN:  how are you only truly holes on his mouth ? a guy trucks duh\n",
            "VAE:  what is the guy who collided in the world ? you need to be anymore .\n",
            "S2S:  what did the guy say to the other who collided with a guy ? i need to see his dick .\n",
            "\n",
            "KEYWORDS: play get\n",
            "TRUE: what do you get when you play a country music record backwards ? you get your wife back , your dog back , your truck back\n",
            "GAN:  can doyou want for ukraine tape factory if they blow it on the cycle\n",
            "VAE:  what do you get when you play a play ? a play .\n",
            "S2S:  what do you get when you play a play with a play with a play ? a rubik is .\n",
            "\n",
            "KEYWORDS: salad man\n",
            "TRUE: an italian man walks into a mental hospital with salad . man it is getting caprese in here\n",
            "GAN:  fun rich windwood has some saladwood jokes you can not do it\n",
            "VAE:  a man is dressing up a man .\n",
            "S2S:  what did the man say to the man with a man with a man ? man , i have a salad dressing .\n",
            "\n",
            "KEYWORDS: night dick black ass\n",
            "TRUE: what is 8 inches long , and black as the night ? the dick up your ass\n",
            "GAN:  how lube do the cycle for cristin repaser ? it\n",
            "VAE:  what is black and black and a dick ? a dick .\n",
            "S2S:  what is black and white and white and black people at night ? a dick\n",
            "\n",
            "KEYWORDS: shot bird\n",
            "TRUE: what did the awkward adolescent say when he shot a bird ? pew birdy puberty\n",
            "GAN:  why do you wanna do with female cars on your cycle path cycle ? they are only on a different cycle path .\n",
            "VAE:  what is the bird is shot ? a bird .\n",
            "S2S:  what is the most unexpected thing about a race ? a bird .\n",
            "\n",
            "KEYWORDS: turned around addicted\n",
            "TRUE: i was addicted to the hokey pokey but , i turned myself around .\n",
            "GAN:  why does moon do the vaseline of hot guys are clean the max ramsay they turned the nuclear men\n",
            "VAE:  i turned my women addicted to a hot tub . i turned myself around .\n",
            "S2S:  i ' m addicted to hokey pokey but i turned it around .\n",
            "\n",
            "KEYWORDS: hell feedback\n",
            "TRUE: what brand microphone did kurt cobain use ? remingtoni head the feedback was hell .\n",
            "GAN:  how hell can t you feed golden movies decoration ? because they are only fake ants .\n",
            "VAE:  what is the best part about a gay man ? a large dog .\n",
            "S2S:  feeds and feeds . feed the hell outback .\n",
            "\n",
            "KEYWORDS: see\n",
            "TRUE: at your next helloween party expect to see the typical costumes . the sexy nurse , the sexy nun and the sexist judge .\n",
            "GAN:  rich people do when they are repoune system ? they are fifteen flavs\n",
            "VAE:  what did the blind man say to the other ? see you see\n",
            "S2S:  what did the vampire say to the other lesbian vampire ? see you see you\n",
            "\n",
            "KEYWORDS: allowed\n",
            "TRUE: i envy women they are allowed to have big titties and i ' m not\n",
            "GAN:  the gay guy pissed his f him the man . he was f him .\n",
            "VAE:  why do you never trust a gay man ? because they are not allowed to get jalapeno\n",
            "S2S:  why did the bicycle fall into a bar ? because he is not allowed to be allowed to be a registered six offender .\n",
            "\n",
            "KEYWORDS: great alright\n",
            "TRUE: i think greta thunberg is alright but dyslexics think she is great\n",
            "GAN:  what can you make sure alright when they are a great rover rover it cycle alright ? alright\n",
            "VAE:  what is great and a gay man ? a left wing .\n",
            "S2S:  what is great about great doctors ? alright , alright , alright , alright , alright , alright , alright , alright .\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test With Some Samples\n",
        "gan_out = []\n",
        "vae_out = []\n",
        "s2s_out = []\n",
        "correct = []\n",
        "kw_list = []\n",
        "\n",
        "for i in range(len(test_seq)):\n",
        "  input = test_seq[i]\n",
        "  kw = test_keywords[i]\n",
        "  true = detokenize(input, tokenizer)\n",
        "  true = ' '.join([x for x in true if x != '[PAD]' and x != '[START]'])\n",
        "  kw2 = detokenize(kw, tokenizer)\n",
        "  kw2 = ' '.join([x for x in kw2 if x != '[PAD]' and x != '[START]'])\n",
        "  print(\"KEYWORDS:\", kw2)\n",
        "  print(\"TRUE:\", true)\n",
        "  gan = generate_joke(kw.reshape(1, maxlen),generator.cpu(), stepper, decoder, tokenizer)\n",
        "  vae = decoder_decode(kw.reshape(1, maxlen), vae_enc, vae_dec, tokenizer)\n",
        "  s2s = decoder_decode(kw.reshape(1, maxlen), s2s_enc, s2s_dec, tokenizer)\n",
        "  print('GAN:',gan)\n",
        "  print('VAE:',vae)\n",
        "  print('S2S:',s2s)\n",
        "  gan_out.append(gan)\n",
        "  vae_out.append(vae)\n",
        "  s2s_out.append(s2s)\n",
        "  correct.append(true)\n",
        "  kw_list.append(kw2)\n",
        "  print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BHvStGVYZ9Vu",
        "outputId": "680b732d-6f25-45e6-bbcc-3882f6b79264"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input Keywords</th>\n",
              "      <th>Original Output</th>\n",
              "      <th>Seq2Seq</th>\n",
              "      <th>VAE</th>\n",
              "      <th>GAN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>switch light arguing</td>\n",
              "      <td>how do you end two deaf persons ' arguing ? sw...</td>\n",
              "      <td>two people are arguing with a light bulb . ju...</td>\n",
              "      <td>if arguing with a switch , 0000 0000 0000 000...</td>\n",
              "      <td>the ambulance has onefullyy so you can switch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>suckin lot lose hurricane house first common b...</td>\n",
              "      <td>what does a blonde have in common with a hurri...</td>\n",
              "      <td>what do a blonde and a lot have in common ? t...</td>\n",
              "      <td>what does a hurricane and a hurricane have in...</td>\n",
              "      <td>howyou can sidesin when the 2016 presidential...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>went floats day circles</td>\n",
              "      <td>i went to a white pride parade the other day ....</td>\n",
              "      <td>i went to the round of the other day i went r...</td>\n",
              "      <td>i went to the other day and a day keeps going...</td>\n",
              "      <td>has you wanna hear 11 drivers ? it went the d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>would neighbor joke home close</td>\n",
              "      <td>i would make a joke about my neighbor . but it...</td>\n",
              "      <td>i would tell a joke about my neighbor is door...</td>\n",
              "      <td>why is the best part about being a joke ? bec...</td>\n",
              "      <td>blondes are confusing till what they are expe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>god everything difference</td>\n",
              "      <td>what is the difference between god and you ex ...</td>\n",
              "      <td>what is the difference between god and god ? ...</td>\n",
              "      <td>what is the difference between god and god ? ...</td>\n",
              "      <td>why did kenk shout in chukh bukh buk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>swear castrate</td>\n",
              "      <td>i swear , i will castrate you do it , you won ...</td>\n",
              "      <td>i swear my actors i have a castrate bridge . ...</td>\n",
              "      <td>what is the easiest way to castrate a boat ? ...</td>\n",
              "      <td>has you can t cast rich content with tristary...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>woman way tits looking eyes checks</td>\n",
              "      <td>the first thing a man notices about a woman is...</td>\n",
              "      <td>i ' m looking for a woman with her tits . she...</td>\n",
              "      <td>i ' m looking for a woman with no eyes i ' m ...</td>\n",
              "      <td>did you want through the eyes ? because it wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>get dead</td>\n",
              "      <td>what is your favourite insult joke ? i will ge...</td>\n",
              "      <td>what do you get when you cross a dead dead mu...</td>\n",
              "      <td>why do you get a pterodactyl laugh ? because ...</td>\n",
              "      <td>can t eat it for eyes but it is the dead tast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>way thought mall harsh</td>\n",
              "      <td>trump hows that mexican mall going ? mall ? we...</td>\n",
              "      <td>i thought that was the same way to be a mall ...</td>\n",
              "      <td>why did the blonde fail algebra ? because she...</td>\n",
              "      <td>wanna hear michael jordan strip compliments s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>anyone</td>\n",
              "      <td>keanu reeves donates so much blood that anyone...</td>\n",
              "      <td>anyone who is a lot like a new year old ? any...</td>\n",
              "      <td>anyone who is the best part about anyone ? an...</td>\n",
              "      <td>you can land with jeff 198 , man ? jeffher da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>sneezes</td>\n",
              "      <td>what does a nut say when he sneezes ? ca shew</td>\n",
              "      <td>what does a fly fly when a fly sneezes ? a de...</td>\n",
              "      <td>what does a nosey pepper sneezes ? a little w...</td>\n",
              "      <td>wanna do rich man vote on his breeze seaweed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>nose man ejaculating arrested</td>\n",
              "      <td>a man was arrested for ejaculating out his nos...</td>\n",
              "      <td>a man was arrested over his nose he was arres...</td>\n",
              "      <td>a man was arrested for a man . he was arreste...</td>\n",
              "      <td>who couldn t you know why forgot the best way...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>write called</td>\n",
              "      <td>my girlfriend asked me to write an inspiration...</td>\n",
              "      <td>what is it called when you write a bladder in...</td>\n",
              "      <td>what is it called when you write a new car ? ...</td>\n",
              "      <td>chuck norris gays rover do condoms on female ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>understand talk heroin</td>\n",
              "      <td>my local police chief does a talk on heroin so...</td>\n",
              "      <td>i don ' t understand my doctor is heroin addi...</td>\n",
              "      <td>i don ' t understand why people talk to the s...</td>\n",
              "      <td>how do you understand emweom , are you not ? ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>used thought think telling look brain</td>\n",
              "      <td>i used to think the brain was the most importa...</td>\n",
              "      <td>i used to look at my brain but i think i woul...</td>\n",
              "      <td>i think i was telling my brain to look for te...</td>\n",
              "      <td>printer obama has been jerking off the cloris...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>tumblr trending saw dashboard</td>\n",
              "      <td>so i saw that princess diana is trending on tu...</td>\n",
              "      <td>i saw on tumblr on tumblr but i saw her with ...</td>\n",
              "      <td>what did the slotan say when he saw the on hi...</td>\n",
              "      <td>moon must use if they expired on the election...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>unless speed multiply light energy</td>\n",
              "      <td>unless you multiply yourself by the speed of l...</td>\n",
              "      <td>life is like speed , then multiply yourself u...</td>\n",
              "      <td>you shouldn ' t multiply your light up and th...</td>\n",
              "      <td>why do blondes go to my light on it ? because...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>hollow hillary head</td>\n",
              "      <td>what is more hollow than donald trump is head ...</td>\n",
              "      <td>why does hillary clinton have longer than a b...</td>\n",
              "      <td>how do monica lewinsky make hillary clinton ?...</td>\n",
              "      <td>chuck norrischesches when you are rain circum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>dog boat</td>\n",
              "      <td>why does a dog on a you boat have a deep bark ...</td>\n",
              "      <td>why did the dog get into the boat ? because h...</td>\n",
              "      <td>what is a dog is favorite kind of boat ? a dog .</td>\n",
              "      <td>wanna hear what the average female brist is b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>reaction</td>\n",
              "      <td>why don ' t people tell chemistry jokes ? beca...</td>\n",
              "      <td>chemistry joke is such a lot like food ? no r...</td>\n",
              "      <td>chemistry jokes are reaction .</td>\n",
              "      <td>how can youadad on ukraine on ukraine ? becau...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       Input Keywords  ...                                                GAN\n",
              "0                                switch light arguing  ...   the ambulance has onefullyy so you can switch...\n",
              "1   suckin lot lose hurricane house first common b...  ...   howyou can sidesin when the 2016 presidential...\n",
              "2                             went floats day circles  ...   has you wanna hear 11 drivers ? it went the d...\n",
              "3                      would neighbor joke home close  ...   blondes are confusing till what they are expe...\n",
              "4                           god everything difference  ...               why did kenk shout in chukh bukh buk\n",
              "5                                      swear castrate  ...   has you can t cast rich content with tristary...\n",
              "6                  woman way tits looking eyes checks  ...   did you want through the eyes ? because it wa...\n",
              "7                                            get dead  ...   can t eat it for eyes but it is the dead tast...\n",
              "8                              way thought mall harsh  ...   wanna hear michael jordan strip compliments s...\n",
              "9                                              anyone  ...   you can land with jeff 198 , man ? jeffher da...\n",
              "10                                            sneezes  ...   wanna do rich man vote on his breeze seaweed ...\n",
              "11                      nose man ejaculating arrested  ...   who couldn t you know why forgot the best way...\n",
              "12                                       write called  ...   chuck norris gays rover do condoms on female ...\n",
              "13                             understand talk heroin  ...   how do you understand emweom , are you not ? ...\n",
              "14              used thought think telling look brain  ...   printer obama has been jerking off the cloris...\n",
              "15                      tumblr trending saw dashboard  ...   moon must use if they expired on the election...\n",
              "16                 unless speed multiply light energy  ...   why do blondes go to my light on it ? because...\n",
              "17                                hollow hillary head  ...   chuck norrischesches when you are rain circum...\n",
              "18                                           dog boat  ...   wanna hear what the average female brist is b...\n",
              "19                                           reaction  ...   how can youadad on ukraine on ukraine ? becau...\n",
              "\n",
              "[20 rows x 5 columns]"
            ]
          },
          "execution_count": 84,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create and save dataframe of results\n",
        "import pandas as pd\n",
        "\n",
        "data = {'Input Keywords':kw_list, \n",
        "        'Original Output':correct, \n",
        "        'Seq2Seq':s2s_out, \n",
        "        'VAE':vae_out, \n",
        "        'GAN':gan_out}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv('results.csv')\n",
        "df.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ql0OBn3Hy0La"
      },
      "outputs": [],
      "source": [
        "# UNIQUE TOKENS\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from nltk import ngrams\n",
        "\n",
        "df = pd.read_csv('/content/results.csv')\n",
        "s2s = \" \".join(list(df['Seq2Seq'])).split(\" \")\n",
        "vae = \" \".join(list(df['VAE'])).split(\" \")\n",
        "gan = ' '.join(str(v) for v in df['GAN']).split(\" \")\n",
        "original = ' '.join(str(v) for v in df['Original Output']).split(\" \")\n",
        "\n",
        "print('UNIQUE TOKENS')\n",
        "print('S2S:', len(set(s2s)))\n",
        "print('VAE:', len(set(vae)))\n",
        "print('GAN:', len(set(gan)))\n",
        "print('TRUE:', len(set(original)))\n",
        "print(\"\")\n",
        "\n",
        "print('UNIQUE BIGRAMS')\n",
        "print('S2S:', len(Counter(ngrams(s2s,2))))\n",
        "print('VAE:', len(Counter(ngrams(vae,2))))\n",
        "print('GAN:', len(Counter(ngrams(gan,2))))\n",
        "print('TRUE:', len(Counter(ngrams(original,2))))\n",
        "print(\"\")\n",
        "\n",
        "print('UNIQUE TRIGRAMS')\n",
        "print('S2S:', len(Counter(ngrams(s2s,3))))\n",
        "print('VAE:', len(Counter(ngrams(vae,3))))\n",
        "print('GAN:', len(Counter(ngrams(gan,3))))\n",
        "print('TRUE:', len(Counter(ngrams(original,3))))\n",
        "print(\"\")\n",
        "\n",
        "print('UNIQUE QUADGRAMS')\n",
        "print('S2S:', len(Counter(ngrams(s2s,4))))\n",
        "print('VAE:', len(Counter(ngrams(vae,4))))\n",
        "print('GAN:', len(Counter(ngrams(gan,4))))\n",
        "print('TRUE:', len(Counter(ngrams(original,4))))\n",
        "print('')\n",
        "\n",
        "print('UNIQUE PENTGRAMS')\n",
        "print('S2S:', len(Counter(ngrams(s2s,5))))\n",
        "print('VAE:', len(Counter(ngrams(vae,5))))\n",
        "print('GAN:', len(Counter(ngrams(gan,5))))\n",
        "print('TRUE:', len(Counter(ngrams(original,5))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ba6qzPcU3Vs0"
      },
      "outputs": [],
      "source": [
        "# Explore frequent phrases of outputs\n",
        "from collections import Counter\n",
        "from nltk import ngrams\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "s2s = \" \".join(list(df['Seq2Seq'])).split(\" \")\n",
        "vae = \" \".join(list(df['VAE'])).split(\" \")\n",
        "gan = ' '.join(str(v) for v in df['GAN']).split(\" \")\n",
        "original = ' '.join(str(v) for v in df['Original Output']).split(\" \")\n",
        "\n",
        "s2s = Counter(ngrams(s2s,5))\n",
        "vae = Counter(ngrams(vae,5))\n",
        "gan = Counter(ngrams(gan,5))\n",
        "original = Counter(ngrams(original,5))\n",
        "\n",
        "# Create data frames for the frequencies\n",
        "#unigrams = pd.DataFrame(unigrams.items(),columns=['word','frequency']).sort_values(by='frequency',ascending=False)\n",
        "s2s = pd.DataFrame(s2s.items(),columns=['S2S','frequency']).sort_values(by='frequency',ascending=False)\n",
        "vae = pd.DataFrame(vae.items(),columns=['VAE','frequency']).sort_values(by='frequency',ascending=False)\n",
        "gan = pd.DataFrame(gan.items(),columns=['GAN','frequency']).sort_values(by='frequency',ascending=False)\n",
        "original = pd.DataFrame(original.items(),columns=['Human','frequency']).sort_values(by='frequency',ascending=False)\n",
        "\n",
        "# create subplot of the different data frames\n",
        "fig, axes = plt.subplots(4,1,figsize=(10,10))\n",
        "sns.barplot(ax=axes[0],x='frequency',y='Human',data=original.head(10), color='green')\n",
        "sns.barplot(ax=axes[1],x='frequency',y='GAN',data=gan.head(10), color='yellow')\n",
        "sns.barplot(ax=axes[2],x='frequency',y='S2S',data=s2s.head(10), color='blue')\n",
        "sns.barplot(ax=axes[3],x='frequency',y='VAE',data=vae.head(10), color='red')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWoImFh-3Lu-"
      },
      "outputs": [],
      "source": [
        "s2s = \" \".join(list(df['Seq2Seq'])).split(\" \")\n",
        "vae = \" \".join(list(df['VAE'])).split(\" \")\n",
        "gan = ' '.join(str(v) for v in df['GAN']).split(\" \")\n",
        "original = ' '.join(str(v) for v in df['Original Output']).split(\" \")\n",
        "\n",
        "\n",
        "s2s = Counter(ngrams(s2s,2))\n",
        "vae = Counter(ngrams(vae,2))\n",
        "gan = Counter(ngrams(gan,2))\n",
        "original = Counter(ngrams(correct,2))\n",
        "\n",
        "s2s = pd.DataFrame(s2s.items(),columns=['S2S','frequency']).sort_values(by='frequency',ascending=False)\n",
        "vae = pd.DataFrame(vae.items(),columns=['VAE','frequency']).sort_values(by='frequency',ascending=False)\n",
        "gan = pd.DataFrame(gan.items(),columns=['GAN','frequency']).sort_values(by='frequency',ascending=False)\n",
        "original = pd.DataFrame(original.items(),columns=['Human','frequency']).sort_values(by='frequency',ascending=False)\n",
        "\n",
        "print(\"Human\")\n",
        "print(original.describe())\n",
        "print(\" \")\n",
        "\n",
        "print(\"GAN\")\n",
        "print(gan.describe())\n",
        "print(\" \")\n",
        "\n",
        "print(\"VAE\")\n",
        "print(vae.describe())\n",
        "print(\" \")\n",
        "\n",
        "print(\"S2S\")\n",
        "print(s2s.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOcnz3WY7XvL",
        "outputId": "211bb7b1-68b4-4e7a-c163-b28325be196f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU\n",
            "s2s: 3.8955895683019466\n",
            "vae: 2.833437267610083\n",
            "gan: 2.4717752741397305\n"
          ]
        }
      ],
      "source": [
        "# BLEU\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "\n",
        "smoothie = SmoothingFunction().method4\n",
        "\n",
        "# Drop rows with empty values\n",
        "dropped = df.dropna()\n",
        "\n",
        "original = [x.split(\" \") for x in dropped['Original Output']]\n",
        "s2s_can = [x.split(\" \") for x in dropped['Seq2Seq']]\n",
        "vae_can = [x.split(\" \") for x in dropped['VAE']]\n",
        "gan_can = [x.split(\" \") for x in dropped['GAN']]\n",
        "\n",
        "# Calculate and print BLEU\n",
        "print('BLEU')\n",
        "print('s2s:', corpus_bleu(original, s2s_can, smoothing_function=smoothie, auto_reweigh=True)*100)\n",
        "print('vae:', corpus_bleu(original, vae_can, smoothing_function=smoothie, auto_reweigh=True)*100)\n",
        "print('gan:', corpus_bleu(original, gan_can, smoothing_function=smoothie, auto_reweigh=True)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kkgd_Zx1X2ky"
      },
      "outputs": [],
      "source": [
        "# BERTSCORE\n",
        "from datasets import load_metric\n",
        "bertscore = load_metric(\"bertscore\")\n",
        "\n",
        "original = dropped['Original Output']\n",
        "s2s_can = dropped['Seq2Seq']\n",
        "vae_can = dropped['VAE']\n",
        "gan_can = dropped['GAN']\n",
        "\n",
        "s2s_score = bertscore.compute(predictions=s2s_can, references=original, lang=\"en\")\n",
        "vae_score = bertscore.compute(predictions=vae_can, references=original, lang=\"en\")\n",
        "gan_score = bertscore.compute(predictions=gan_can, references=original, lang=\"en\")\n",
        "\n",
        "# Calculate and print BLEU\n",
        "print('BERTSCORE')\n",
        "print('s2s precision:', sum(s2s_score['precision'])/len(dropped)*100)\n",
        "print('s2s recall:', sum(s2s_score['recall'])/len(dropped)*100)\n",
        "print('s2s f1:', sum(s2s_score['f1'])/len(dropped)*100)\n",
        "print(\" \")\n",
        "\n",
        "print('vae precision:', sum(vae_score['precision'])/len(dropped)*100)\n",
        "print('vae recall:', sum(vae_score['recall'])/len(dropped)*100)\n",
        "print('vae f1:', sum(vae_score['f1'])/len(dropped)*100)\n",
        "print(\" \")\n",
        "\n",
        "print('gan precision:', sum(gan_score['precision'])/len(dropped)*100)\n",
        "print('gan recall:', sum(gan_score['recall'])/len(dropped)*100)\n",
        "print('gan f1:', sum(gan_score['f1'])/len(dropped)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2XRt3rhcJzbv",
        "outputId": "b69d76cf-a8aa-474b-9e9f-e2cb21e9fe5f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>I would make a joke about my neighbor. But it would be too close to home</th>\n",
              "      <th>Blondes are confusing till what they are expensive till they are the best edest ride they are close at home.</th>\n",
              "      <th>Why is the best part about being a joke? because if it would be home, I can close it home.</th>\n",
              "      <th>I would tell a joke about my neighbor is door. I would be a close to the home.</th>\n",
              "      <th>When Is a door not a door? when it is ajar .</th>\n",
              "      <th>How do repnolds smell like your door? It is heading inside your door.</th>\n",
              "      <th>When is a door not a door ? It is ajar .</th>\n",
              "      <th>When is a door's favorite kind of door? When it is ajar.</th>\n",
              "      <th>What brand microphone did Kurt Cobain use? remingtoni head the feedback was hell.</th>\n",
              "      <th>How hell can't you feed golden movies decoration? because they are only fake ants.</th>\n",
              "      <th>What is the best part about a gay man? a large dog.</th>\n",
              "      <th>Feeds and feeds. Feed the hell outback .</th>\n",
              "      <th>What do you call an immigrant fighting a rapist? alien vs predator</th>\n",
              "      <th>Why do you really hate? Because he has a perfanoxious as the magical machine. Predator coat</th>\n",
              "      <th>What do you call a rapist that gets into a rapist? alien vs predator</th>\n",
              "      <th>What do you call a rapist with a rapist ? alien vs predator</th>\n",
              "      <th>I gave away all of my dead batteries free of charge .</th>\n",
              "      <th>How do you throw 1000 as a careries on particular car? Juan on charge.</th>\n",
              "      <th>Why did the electrons go to charge? because electrons was resisting a charge</th>\n",
              "      <th>Why did the neutron receive a nipple pierced? because of charge.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7/31/2021 17:43:51</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7/31/2021 17:45:41</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7/31/2021 17:47:49</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7/31/2021 17:51:08</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7/31/2021 17:52:51</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>7/31/2021 17:55:50</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7/31/2021 18:10:59</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7/31/2021 18:15:16</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7/31/2021 18:15:32</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7/31/2021 18:15:57</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7/31/2021 18:35:20</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>7/31/2021 18:39:31</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>7/31/2021 18:55:21</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>7/31/2021 20:00:48</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7/31/2021 20:09:07</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>7/31/2021 20:12:33</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>7/31/2021 20:14:05</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>7/31/2021 20:19:55</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>7/31/2021 20:21:32</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>7/31/2021 23:03:19</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>8/1/2021 0:55:17</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>8/1/2021 11:13:58</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>8/1/2021 13:57:40</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>8/1/2021 15:54:39</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>8/1/2021 18:22:47</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>8/1/2021 18:27:54</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>8/1/2021 21:53:06</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>8/2/2021 1:10:13</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Timestamp  ...  Why did the neutron receive a nipple pierced? because of charge.\n",
              "0   7/31/2021 17:43:51  ...                                                  4               \n",
              "1   7/31/2021 17:45:41  ...                                                  5               \n",
              "2   7/31/2021 17:47:49  ...                                                  3               \n",
              "3   7/31/2021 17:51:08  ...                                                  1               \n",
              "4   7/31/2021 17:52:51  ...                                                  2               \n",
              "5   7/31/2021 17:55:50  ...                                                  5               \n",
              "6   7/31/2021 18:10:59  ...                                                  3               \n",
              "7   7/31/2021 18:15:16  ...                                                  4               \n",
              "8   7/31/2021 18:15:32  ...                                                  3               \n",
              "9   7/31/2021 18:15:57  ...                                                  1               \n",
              "10  7/31/2021 18:35:20  ...                                                  2               \n",
              "11  7/31/2021 18:39:31  ...                                                  1               \n",
              "12  7/31/2021 18:55:21  ...                                                  3               \n",
              "13  7/31/2021 20:00:48  ...                                                  1               \n",
              "14  7/31/2021 20:09:07  ...                                                  5               \n",
              "15  7/31/2021 20:12:33  ...                                                  1               \n",
              "16  7/31/2021 20:14:05  ...                                                  4               \n",
              "17  7/31/2021 20:19:55  ...                                                  3               \n",
              "18  7/31/2021 20:21:32  ...                                                  4               \n",
              "19  7/31/2021 23:03:19  ...                                                  2               \n",
              "20    8/1/2021 0:55:17  ...                                                  4               \n",
              "21   8/1/2021 11:13:58  ...                                                  2               \n",
              "22   8/1/2021 13:57:40  ...                                                  3               \n",
              "23   8/1/2021 15:54:39  ...                                                  4               \n",
              "24   8/1/2021 18:22:47  ...                                                  2               \n",
              "25   8/1/2021 18:27:54  ...                                                  4               \n",
              "26   8/1/2021 21:53:06  ...                                                  3               \n",
              "27    8/2/2021 1:10:13  ...                                                  5               \n",
              "\n",
              "[28 rows x 21 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# SUMMARISE HUMAN EVALUATION\n",
        "import pandas as pd\n",
        "\n",
        "# 1= Not Funny, 5=Funny\n",
        "ratings = pd.read_csv('/content/Rate Jokes (Responses) - Form Responses 1.csv')\n",
        "ratings.head(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebzQPg0eddFF"
      },
      "outputs": [],
      "source": [
        "# Extract the jokes into their respective categories\n",
        "original_r = []\n",
        "gan_r = []\n",
        "vae_r = []\n",
        "s2s_r = []\n",
        "\n",
        "for i in range(1,21,4):\n",
        "  original_r += list(ratings.iloc[:,i])\n",
        "  gan_r += list(ratings.iloc[:,i+1])\n",
        "  vae_r += list(ratings.iloc[:,i+2])\n",
        "  s2s_r += list(ratings.iloc[:,i+3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPRHu9rYLsxk",
        "outputId": "e12b8ce9-7ed2-4a58-fd30-f0b38b97b6e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Original Rating: 3.45\n",
            "Average GAN Rating: 2.6142857142857143\n",
            "Average VAE Rating: 2.8857142857142857\n",
            "Average S2S Rating: 2.7214285714285715\n"
          ]
        }
      ],
      "source": [
        "# Average Ratings\n",
        "print('Average Original Rating:', sum(original_r)/140)\n",
        "print('Average GAN Rating:', sum(gan_r)/140)\n",
        "print('Average VAE Rating:', sum(vae_r)/140)\n",
        "print('Average S2S Rating:', sum(s2s_r)/140)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO5uuo0MahDo",
        "outputId": "7d79c018-003e-42fe-c5cd-0f135fa655af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original STD: 1.2723712396264588\n",
            "GAN STD: 1.401966548845454\n",
            "VAE STD: 1.4045116807006235\n",
            "S2S STD: 1.429624611781794\n"
          ]
        }
      ],
      "source": [
        "# Standard deviation of ratings\n",
        "print(\"Original STD:\", np.std(original_r))\n",
        "print(\"GAN STD:\", np.std(gan_r))\n",
        "print(\"VAE STD:\", np.std(vae_r))\n",
        "print(\"S2S STD:\", np.std(s2s_r))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mne0e-PrUyxG",
        "outputId": "ede439ab-5657-4e24-9d23-d183fef91114"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RATE AT WHICH SYNTHETIC JOKES >= HUMAN CURATED\n",
            "GAN: 46.42857142857143\n",
            "VAE: 56.42857142857143\n",
            "S2S: 50.71428571428571\n"
          ]
        }
      ],
      "source": [
        "# Check the rate at which synthethic jokes rank better than the original ones.\n",
        "gan_b = 0\n",
        "vae_b = 0\n",
        "s2s_b = 0\n",
        "\n",
        "for i in range(len(original_r)):\n",
        "  if gan_r[i] >= original_r[i]:\n",
        "    gan_b += 1\n",
        "\n",
        "  if vae_r[i] >= original_r[i]:\n",
        "    vae_b += 1\n",
        "\n",
        "  if s2s_r[i] >= original_r[i]:\n",
        "    s2s_b += 1\n",
        "\n",
        "print(\"RATE AT WHICH SYNTHETIC JOKES >= HUMAN CURATED\")\n",
        "print(\"GAN:\", gan_b/len(original_r)*100)\n",
        "print(\"VAE:\", vae_b/len(original_r)*100)\n",
        "print(\"S2S:\", s2s_b/len(original_r)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H93zfsBKb_Rv"
      },
      "source": [
        "# Free hand test (Run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obBfyEoNb5VD"
      },
      "outputs": [],
      "source": [
        "##################################### LOAD MODELS #######################################\n",
        "n_layers = 5\n",
        "block_dim = 100\n",
        "\n",
        "# Create model and load weights for GAN\n",
        "generator = Generator(n_layers, block_dim)\n",
        "generator.eval()\n",
        "generator.load_state_dict(torch.load('/content/generator.th', map_location='cpu'))\n",
        "model, encoder, stepper, decoder = r_seq2seq(weights='/content/reconstruction_weights.h5')\n",
        "\n",
        "# Load VAE\n",
        "vae_enc, vae_dec = vae(weights_e='/content/vae_enc_weights.h5', \n",
        "                weights_d='/content/vae_dec_weights.h5')\n",
        "\n",
        "# Load Seq2Seq\n",
        "s2s_enc, s2s_dec = seq2seq(weights='/content/seq2seq_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6Yt8lIjXc_k",
        "outputId": "bce4cd66-53d0-46c4-9e56-1704d8809bc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KEYWORDS: play sleep\n",
            "GAN:  why does ireland fall through the toilet seat ? they are not a play by the blavs\n",
            "VAE:  what do you call a play in a sleep ? a good time\n",
            "S2S:  why did the mexican train get to sleep with his sleep ? he couldn t like to get it to sleep .\n"
          ]
        }
      ],
      "source": [
        "############################### FREE HAND TEST INTERFACE ################################\n",
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "prompt = \"play sleep\"\n",
        "tokens = tokenizer.tokenize(prompt)\n",
        "tokens = tf.squeeze(tokens,axis=0)\n",
        "tokens = list(tf.squeeze(tokens, axis=1).numpy())\n",
        "kw = keras.preprocessing.sequence.pad_sequences([tokens], value=0, padding='post', maxlen=maxlen)[0]\n",
        "kw = kw.reshape(1, maxlen)\n",
        "\n",
        "gan = generate_joke(kw,generator.cpu(), stepper, decoder, tokenizer)\n",
        "vae = decoder_decode(kw, vae_enc, vae_dec, tokenizer, top_k=2)\n",
        "s2s = decoder_decode(kw, s2s_enc, s2s_dec, tokenizer, top_k=2)\n",
        "print('KEYWORDS:', prompt)\n",
        "print('GAN:',gan)\n",
        "print('VAE:',vae)\n",
        "print('S2S:',s2s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXaIrFPumVmG",
        "outputId": "217f46cf-9144-45b1-cbfb-700d84069976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KEYWORDS: goat\n",
            "GAN:  what do you call tomato as kleasoy blub cream ? bukak\n",
            "VAE:  what did the muslim say when his goat is ? he is a goat .\n",
            "S2S:  what is the smallest goat is favorite organ ? the goat .\n"
          ]
        }
      ],
      "source": [
        "prompt = \"goat\"\n",
        "tokens = tokenizer.tokenize(prompt)\n",
        "tokens = tf.squeeze(tokens,axis=0)\n",
        "tokens = list(tf.squeeze(tokens, axis=1).numpy())\n",
        "kw = keras.preprocessing.sequence.pad_sequences([tokens], value=0, padding='post', maxlen=maxlen)[0]\n",
        "kw = kw.reshape(1, maxlen)\n",
        "\n",
        "gan = generate_joke(kw,generator.cpu(), stepper, decoder, tokenizer)\n",
        "vae = decoder_decode(kw, vae_enc, vae_dec, tokenizer, top_k=2)\n",
        "s2s = decoder_decode(kw, s2s_enc, s2s_dec, tokenizer, top_k=2)\n",
        "print('KEYWORDS:', prompt)\n",
        "print('GAN:',gan)\n",
        "print('VAE:',vae)\n",
        "print('S2S:',s2s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFJE0lainff3",
        "outputId": "1efe5893-c1a4-4722-dc5e-5acfa1425190"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KEYWORDS: fat mother\n",
            "GAN:  why do you moon has been fat when he does rainy always float ? a blunderman .\n",
            "VAE:  what is your best part about being fat ? your mother\n",
            "S2S:  yo mama so fat she has been fat she has been fat .\n"
          ]
        }
      ],
      "source": [
        "prompt = \"fat mother\"\n",
        "tokens = tokenizer.tokenize(prompt)\n",
        "tokens = tf.squeeze(tokens,axis=0)\n",
        "tokens = list(tf.squeeze(tokens, axis=1).numpy())\n",
        "kw = keras.preprocessing.sequence.pad_sequences([tokens], value=0, padding='post', maxlen=maxlen)[0]\n",
        "kw = kw.reshape(1, maxlen)\n",
        "\n",
        "gan = generate_joke(kw,generator.cpu(), stepper, decoder, tokenizer)\n",
        "vae = decoder_decode(kw, vae_enc, vae_dec, tokenizer, top_k=2)\n",
        "s2s = decoder_decode(kw, s2s_enc, s2s_dec, tokenizer, top_k=2)\n",
        "print('KEYWORDS:', prompt)\n",
        "print('GAN:',gan)\n",
        "print('VAE:',vae)\n",
        "print('S2S:',s2s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1y5ANOtqfBb",
        "outputId": "6edd8b74-9207-4de2-cb74-a5442c1d022a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KEYWORDS: tequila shots\n",
            "GAN:  wanna know why the male husbands rushed to get away ? because they are ed outside your shots .\n",
            "VAE:  why is tequila tequila not tequila ? tequila mockingbird\n",
            "S2S:  why did the mexican man get his shots ? tequila\n"
          ]
        }
      ],
      "source": [
        "prompt = \"tequila shots\"\n",
        "tokens = tokenizer.tokenize(prompt)\n",
        "tokens = tf.squeeze(tokens,axis=0)\n",
        "tokens = list(tf.squeeze(tokens, axis=1).numpy())\n",
        "kw = keras.preprocessing.sequence.pad_sequences([tokens], value=0, padding='post', maxlen=maxlen)[0]\n",
        "kw = kw.reshape(1, maxlen)\n",
        "\n",
        "gan = generate_joke(kw,generator.cpu(), stepper, decoder, tokenizer)\n",
        "vae = decoder_decode(kw, vae_enc, vae_dec, tokenizer, top_k=1)\n",
        "s2s = decoder_decode(kw, s2s_enc, s2s_dec, tokenizer, top_k=1)\n",
        "print('KEYWORDS:', prompt)\n",
        "print('GAN:',gan)\n",
        "print('VAE:',vae)\n",
        "print('S2S:',s2s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biddZNKyn3n4",
        "outputId": "35968eb0-07e2-4bdc-eae0-289af27b3fc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KEYWORDS: dancing clown\n",
            "GAN:  how should they get the worst period of it ? crimea river\n",
            "VAE:  why do you never trust old people at the slaughter ? they are dancing .\n",
            "S2S:  why do sharksters eat a clown ? because it might lead while dancing .\n"
          ]
        }
      ],
      "source": [
        "prompt = \"dancing clown\"\n",
        "tokens = tokenizer.tokenize(prompt)\n",
        "tokens = tf.squeeze(tokens,axis=0)\n",
        "tokens = list(tf.squeeze(tokens, axis=1).numpy())\n",
        "kw = keras.preprocessing.sequence.pad_sequences([tokens], value=0, padding='post', maxlen=maxlen)[0]\n",
        "kw = kw.reshape(1, maxlen)\n",
        "\n",
        "gan = generate_joke(kw,generator.cpu(), stepper, decoder, tokenizer)\n",
        "vae = decoder_decode(kw, vae_enc, vae_dec, tokenizer, top_k=1)\n",
        "s2s = decoder_decode(kw, s2s_enc, s2s_dec, tokenizer, top_k=1)\n",
        "print('Keywords:', prompt)\n",
        "print('GAN:',gan)\n",
        "print('VAE:',vae)\n",
        "print('S2S:',s2s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xg8IE8Raoaa5"
      },
      "outputs": [],
      "source": [
        "prompt = \"clown president\"\n",
        "tokens = tokenizer.tokenize(prompt)\n",
        "tokens = tf.squeeze(tokens,axis=0)\n",
        "tokens = list(tf.squeeze(tokens, axis=1).numpy())\n",
        "kw = keras.preprocessing.sequence.pad_sequences([tokens], value=0, padding='post', maxlen=maxlen)[0]\n",
        "kw = kw.reshape(1, maxlen)\n",
        "\n",
        "gan = generate_joke(kw,generator.cpu(), stepper, decoder, tokenizer)\n",
        "vae = decoder_decode(kw, vae_enc, vae_dec, tokenizer, top_k=1)\n",
        "s2s = decoder_decode(kw, s2s_enc, s2s_dec, tokenizer, top_k=1)\n",
        "print('Keywords:', prompt)\n",
        "print('GAN:',gan)\n",
        "print('VAE:',vae)\n",
        "print('S2S:',s2s)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
